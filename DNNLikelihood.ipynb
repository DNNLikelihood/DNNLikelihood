{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"Source\")\n",
    "\n",
    "from setGPUs import setGPUs\n",
    "GPU_numbers = [0]#[0,1]\n",
    "GPU_names = setGPUs(GPU_numbers)\n",
    "print(GPU_names)\n",
    "\n",
    "import gc\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "\n",
    "import psutil\n",
    "from jupyterthemes import jtplot\n",
    "from scipy import stats\n",
    "\n",
    "import DNNLikelihood\n",
    "import mcmc\n",
    "import toy_likelihood\n",
    "from DNNLikelihood import *\n",
    "from mcmc import *\n",
    "from toy_likelihood import *\n",
    "\n",
    "fig_dir = 'Figures/'\n",
    "jtplot.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unbiased sampling $S_{1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for j in range(11):\n",
    "    NEW_SAMPLING = True\n",
    "    INITIALIZE_IN_BALL = False\n",
    "    logprob_fn = logprob\n",
    "    #sampler = import_sampler('sampling_lik_emcee')\n",
    "    \n",
    "    # sampler inputs\n",
    "    ndim, nwalkers, nsteps = 95, 1000, 1000000\n",
    "    \n",
    "    # Initialize backend\n",
    "    filename = \"Data_samples/likelihood_unbiased_sm_13_\"+str(j)+\".h5\"\n",
    "    chainsname = 'toy_likelihood'\n",
    "    backend = emcee.backends.HDFBackend(filename, name=chainsname)\n",
    "    if NEW_SAMPLING:\n",
    "        # starting value of parameters\n",
    "        if INITIALIZE_IN_BALL:\n",
    "            start = timer()\n",
    "            maxlik = minimize(lambda delta: -logprob(delta), np.full(95,0),method='Powell')\n",
    "            p0 =  [maxlik['x']+0.01*np.insert(np.random.normal(0,1,94),0,np.random.uniform(-1,5)) for i in range(nwalkers)]\n",
    "            end = timer()\n",
    "            print(\"Initialization around maximum likelihood performed in\",end-start,\"s.\")\n",
    "            #print(np.sort([[logprob(x),x[0]] for x in result],axis=0))\n",
    "        else:\n",
    "            p0 = [np.full(95,0)+np.insert(np.random.normal(0,1,94),0,np.random.uniform(-1,5)) for i in range(nwalkers)]\n",
    "        backend.reset(nwalkers, ndim)\n",
    "    else:\n",
    "        p0 = backend.get_last_sample()\n",
    "    print(\"Initial number of steps: {0}\".format(backend.iteration))\n",
    "    \n",
    "    moves = emcee.moves.StretchMove(1.3)\n",
    "    \n",
    "    n_processes = psutil.cpu_count(logical=False)\n",
    "    if NEW_SAMPLING:\n",
    "        for i in range(n_processes,n_processes+1,2):\n",
    "            if __name__ ==  '__main__': \n",
    "                print('Running ', i,' parallel processes.')\n",
    "                start = timer()\n",
    "                with Pool(i) as pool:\n",
    "                    sampler = emcee.EnsembleSampler(nwalkers, ndim, logprob_fn, moves=moves, pool=pool, backend=backend)\n",
    "                    sampler.run_mcmc(p0, nsteps, progress=True)\n",
    "                end = timer()\n",
    "                print('Done in ',end-start,'seconds')\n",
    "    else:\n",
    "        for i in range(n_processes,n_processes+1,2):\n",
    "            if __name__ ==  '__main__': \n",
    "                print('Running ', i,' parallel processes.')\n",
    "                start = timer()\n",
    "                with Pool(i) as pool:\n",
    "                    sampler = emcee.EnsembleSampler(nwalkers, ndim, logprob_fn, moves=moves, pool=pool, backend=backend)\n",
    "                    sampler.run_mcmc(None, nsteps, progress=True)\n",
    "                end = timer()\n",
    "                print('Done in ',end-start,'seconds')\n",
    "    print(\"Final number of steps: {0}\".format(backend.iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start = timer()\n",
    "chains = sampler.get_chain()\n",
    "logprobs = sampler.get_log_prob()\n",
    "res_shape = np.shape(chains)\n",
    "nsteps, nwalkers, ndim = np.shape(chains)\n",
    "end = timer()\n",
    "print('Chains have shape', res_shape,'\\nThere are',res_shape[1],'chains of',res_shape[0],'steps in',res_shape[2],'dimensions.\\nLoaded in',end-start,\"s.\")\n",
    "del(res_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Chains plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start = timer()\n",
    "filename = \"Data_samples/likelihood_unbiased_sm_13_1.h5\"\n",
    "chainsname = 'toy_likelihood'\n",
    "backend = import_sampler(filename,chainsname)\n",
    "f = h5py.File(filename, 'r')[chainsname]\n",
    "nsteps = f.attrs[\"iteration\"]\n",
    "keys = f.keys()\n",
    "chains_samp = f.get(\"chain\")[:,:,0:1]\n",
    "chains_lp = f.get(\"log_prob\")\n",
    "res_shape = np.shape(chains_samp)\n",
    "nsteps, nwalkers, ndim = np.shape(chains_samp)\n",
    "end = timer()\n",
    "print('Chains have shape', res_shape,'\\nThere are',res_shape[1],'chains of',res_shape[0],'steps in',res_shape[2],'dimensions.\\nLoaded in',end-start,\"s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rnd_chains = np.sort(np.random.choice(np.arange(1000),100,replace=False))\n",
    "rnd_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx = np.sort([(i)*(10**j) for i in range(1,11) for j in range(10)])\n",
    "idx = np.unique(idx[idx<len(chains_lp)])\n",
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "plt.plot(idx,-chains_lp[:,rnd_chains][idx], '-', alpha=0.8)\n",
    "plt.grid(linestyle=\"--\", dashes=(5,5))\n",
    "plt.xlabel(r\"step\")\n",
    "plt.ylabel(r\"$-\\log\\mathcal{L}$\")\n",
    "plt.xscale('log')\n",
    "x1,x2,y1,y2 = plt.axis()\n",
    "plt.axis([x1, x2, 295, 505])\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + \"chains_sm_loglik.pdf\",quality=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx = np.sort([(i)*(10**j) for i in range(1,11) for j in range(10)])\n",
    "idx = np.unique(idx[idx<len(chains_samp)])\n",
    "chain = chains_samp[:,:,0]\n",
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "plt.plot(idx,chain[idx][:,rnd_chains], '-', alpha=0.8)\n",
    "plt.grid(linestyle=\"--\", dashes=(5,5))\n",
    "plt.xlabel(r\"step\")\n",
    "plt.ylabel(r\"$\\mu$\")\n",
    "plt.xscale('log')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + \"chains_sm.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Convergence: Integrated Autocorrelation Time (IAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start = timer()\n",
    "filename = \"Data_samples/likelihood_unbiased_sm_13_1.h5\"\n",
    "chainsname = 'toy_likelihood'\n",
    "backend = import_sampler(filename,chainsname)\n",
    "f = h5py.File(filename, 'r')[chainsname]\n",
    "nsteps = f.attrs[\"iteration\"]\n",
    "keys = f.keys()\n",
    "chains_samp = f.get(\"chain\")[:,:,0:1]\n",
    "res_shape = np.shape(chains_samp)\n",
    "nsteps, nwalkers, ndim = np.shape(chains_samp)\n",
    "allsamples = chains_samp.reshape([nsteps*nwalkers,ndim])\n",
    "end = timer()\n",
    "print('Chains have shape', res_shape,'\\nThere are',res_shape[1],'chains of',res_shape[0],'steps in',res_shape[2],'dimensions.\\nLoaded in',end-start,\"s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "start = timer()\n",
    "show_dist_and_autocorr(chains_samp[:,:,:],[0], labels, save=fig_dir+\"figure_autocorr_dist.pdf\", methods=[\"G&W 2010\", \"DFM 2017\"])#'../paper/figs/figure_autocorr.pdf')#'../paper/figs/figure_autocorr.pdf')#'../paper/figs/figure_autocorr.pdf')\n",
    "end = timer()\n",
    "print(\"Distribution and autocorrelation time plots done and saved in\",end-start,\"s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start = timer()\n",
    "chain = chains_samp[:, :, 0].T\n",
    "print([autocorr_gw2010(chain),autocorr_new(chain)])\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Convergence: Gelman-Rubin\n",
    "Before running should run the sampler 50 times with 200 walkers for 30000 steps (use code in Sec. 2.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### From multiple samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rnd_chains = np.sort(np.random.choice(np.arange(200),4,replace=False))\n",
    "rnd_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_global = timer()\n",
    "for n in range(50):\n",
    "    start = timer()\n",
    "    filename = \"Data_samples/likelihood_unbiased_sm_13_gelrub_\"+str(n)+\".h5\"\n",
    "    chainsname = 'toy_likelihood'\n",
    "    f = h5py.File(filename, 'r')[chainsname]\n",
    "    nsteps = f.attrs[\"iteration\"]\n",
    "    keys = f.keys()\n",
    "    if n==0:\n",
    "        chains_samp = f.get(\"chain\")[:,rnd_chains]\n",
    "    if n>0:\n",
    "        chains_samp_tmp = f.get(\"chain\")[:,rnd_chains]\n",
    "        chains_samp = np.concatenate((chains_samp,chains_samp_tmp),axis=1)\n",
    "    res_shape = np.shape(chains_samp)\n",
    "    nsteps, nwalkers, ndim = np.shape(chains_samp)\n",
    "    end = timer()\n",
    "    print('Chains have shape', res_shape,'\\nThere are',res_shape[1],'chains of',res_shape[0],'steps in',res_shape[2],'dimensions.\\nLoaded in',end-start,\"s.\")\n",
    "end_global = timer()\n",
    "print('Chains have shape', res_shape,'\\nThere are',res_shape[1],'chains of',res_shape[0],'steps in',res_shape[2],'dimensions.\\nLoaded in',end_global-start_global,\"s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start = timer()\n",
    "res = gelman_rubin(chains_samp[:,:,0])\n",
    "end = timer()\n",
    "print(end-start)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start = timer()\n",
    "xcoord = np.sort(np.array([[i*10**j for i in range(1,10)] for j in range(2,5)]).flatten())\n",
    "res = [gelman_rubin(chains_samp[0:i,:,:]) for i in xcoord[4:-6]]\n",
    "R = np.array([i[0] for i in res])\n",
    "sqrtVhat = np.sqrt([i[1] for i in res])\n",
    "sqrtW = np.sqrt([i[2] for i in res])\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "plt.grid(linestyle=\"--\", dashes=(5, 5))\n",
    "plt.plot(xcoord[4:-6],R)\n",
    "plt.xlim(500, 30000)\n",
    "plt.xscale('log')\n",
    "plt.xlabel(r\"number of steps, $S$\")\n",
    "plt.ylabel(r\"$\\hat{R}_{c}$\")\n",
    "ax = plt.axes()\n",
    "plt.text(0.5,0.9,\"4 walkers from 50 samplers\", fontsize=22, transform = ax.transAxes, ha='center',ma='left')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + \"Gelman-Rubin_R_many_samplers.pdf\",quality=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "plt.grid(linestyle=\"--\", dashes=(5, 5))\n",
    "plt.plot(xcoord[4:-6],sqrtVhat)\n",
    "plt.xlim(500, 30000)\n",
    "plt.xscale('log')\n",
    "plt.xlabel(r\"number of steps, $S$\")\n",
    "plt.ylabel(r\"$\\sqrt{\\hat{V}}$\")\n",
    "ax = plt.axes()\n",
    "plt.text(0.5,0.65,\"4 walkers from 50 samplers\", fontsize=22, transform = ax.transAxes, ha='center',ma='left')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + \"Gelman-Rubin_Vhat_many_samplers.pdf\",quality=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "plt.grid(linestyle=\"--\", dashes=(5, 5))\n",
    "plt.plot(xcoord[4:-6],sqrtW)\n",
    "plt.xlim(500, 30000)\n",
    "plt.xscale('log')\n",
    "plt.xlabel(r\"number of steps, $S$\")\n",
    "plt.ylabel(r\"$\\sqrt{W}$\")\n",
    "ax = plt.axes()\n",
    "plt.text(0.33,0.9,\"4 walkers from 50 samplers\", fontsize=22, transform = ax.transAxes, ha='center',ma='left')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + \"Gelman-Rubin_W_many_samplers.pdf\",quality=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### From single sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start = timer()\n",
    "filename = \"Data_samples/likelihood_unbiased_sm_13_gelrub_0.h5\"\n",
    "chainsname = 'toy_likelihood'\n",
    "f = h5py.File(filename, 'r')[chainsname]\n",
    "nsteps = f.attrs[\"iteration\"]\n",
    "keys = f.keys()\n",
    "chains_samp_0 = f.get(\"chain\")[:]\n",
    "res_shape = np.shape(chains_samp_0)\n",
    "nsteps, nwalkers, ndim = np.shape(chains_samp_0)\n",
    "end = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start = timer()\n",
    "xcoord = np.sort(np.array([[i*10**j for i in range(1,10)] for j in range(2,5)]).flatten())\n",
    "res = [gelman_rubin(chains_samp_0[0:i,:,:]) for i in xcoord[4:-6]]\n",
    "R = [i[0] for i in res]\n",
    "sqrtVhat = np.sqrt([i[1] for i in res])\n",
    "sqrtW = np.sqrt([i[2] for i in res])\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "plt.grid(linestyle=\"--\", dashes=(5, 5))\n",
    "plt.plot(xcoord[4:-6],R)\n",
    "plt.xlim(500, 30000)\n",
    "plt.xscale('log')\n",
    "plt.xlabel(r\"number of steps, $S$\")\n",
    "plt.ylabel(r\"$\\hat{R}_{c}$\")\n",
    "ax = plt.axes()\n",
    "plt.text(0.5,0.9,\"200 walkers from 1 sampler\", fontsize=22, transform = ax.transAxes, ha='center',ma='left')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + \"Gelman-Rubin_R_one_sampler.pdf\",quality=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "plt.grid(linestyle=\"--\", dashes=(5, 5))\n",
    "plt.plot(xcoord[4:-6],sqrtVhat)\n",
    "plt.xlim(500, 30000)\n",
    "plt.xscale('log')\n",
    "plt.xlabel(r\"number of steps, $S$\")\n",
    "plt.ylabel(r\"$\\sqrt{\\hat{V}}$\")\n",
    "ax = plt.axes()\n",
    "plt.text(0.5,0.5,\"200 walkers from 1 sampler\", fontsize=22, transform = ax.transAxes, ha='center',ma='left')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + \"Gelman-Rubin_Vhat_one_sampler.pdf\",quality=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "plt.grid(linestyle=\"--\", dashes=(5, 5))\n",
    "plt.plot(xcoord[4:-6],sqrtW)\n",
    "plt.xlim(500, 30000)\n",
    "plt.xscale('log')\n",
    "plt.xlabel(r\"number of steps, $S$\")\n",
    "plt.ylabel(r\"$\\sqrt{W}$\")\n",
    "ax = plt.axes()\n",
    "plt.text(0.33,0.9,\"200 walkers from 1 sampler\", fontsize=22, transform = ax.transAxes, ha='center',ma='left')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + \"Gelman-Rubin_W_one_sampler.pdf\",quality=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Extract samples with thin=1000 (independent samples) and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for j in range(11):\n",
    "    \"likelihood_unbiased_sm_13_\"\n",
    "    filename = \"Data_samples/likelihood_unbiased_sm_13_\"+str(j)\".h5\"\n",
    "    chainsname = 'toy_likelihood'\n",
    "    start = timer()\n",
    "    backend = import_sampler(filename,chainsname)\n",
    "    allsamples = backend.get_chain(discard=5000,thin=1000,flat=True)\n",
    "    logprob_values = backend.get_log_prob(discard=5000,thin=1000,flat=True)\n",
    "    end = timer()\n",
    "    print(len(allsamples),\"independent samples extracted in\", end-start, \"s.\")\n",
    "    samples_file = \"Data_samples/likelihood_unbiased_sm_13_\"+str(j)\"_thinned1000.pickle\"\n",
    "    pickle_out = open(samples_file, 'wb')\n",
    "    start = timer()\n",
    "    pickle.dump(allsamples, pickle_out, protocol=4)\n",
    "    pickle.dump(logprob_values, pickle_out, protocol=4)\n",
    "    end = timer()\n",
    "    pickle_out.close()\n",
    "    statinfo = os.stat(samples_file)\n",
    "    print('File saved in ',end-start,' seconds.\\nFile size is ',statinfo.st_size,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#samples_file = '../../bigfiles/likelihood_unbiased_sm_13_11_thinned1000'\n",
    "#pickle_in = open(samples_file,'rb')\n",
    "#start = timer()\n",
    "#statinfo = os.stat(samples_file)\n",
    "#allsamples_train = pickle.load(pickle_in)\n",
    "#logprob_values_train = pickle.load(pickle_in)\n",
    "#end = timer()\n",
    "#pickle_in.close()\n",
    "#print('File loaded in ',end-start,' seconds.\\nFile size is ',statinfo.st_size,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start_global = timer()\n",
    "samples_files = [\"Data_samples/likelihood_unbiased_sm_13_\"+str(j)+\"_thinned1000.pickle\" for j in range(11)]\n",
    "i=1\n",
    "for samples_file in samples_files:\n",
    "    start = timer()\n",
    "    pickle_in = open(samples_file,'rb')\n",
    "    statinfo = os.stat(samples_file)\n",
    "    if i==1:\n",
    "        allsamples = pickle.load(pickle_in)\n",
    "        logprob_values = pickle.load(pickle_in)\n",
    "        end = timer()\n",
    "        print(len(allsamples),\"samples from file\",samples_file,\"loaded in\",end-start,\"seconds. Samples added to array.\")\n",
    "    if i > 1:# and i < len(samples_files):\n",
    "        allsamples_tmp = pickle.load(pickle_in)\n",
    "        logprob_values_tmp = pickle.load(pickle_in)\n",
    "        allsamples = np.concatenate((allsamples,allsamples_tmp))\n",
    "        logprob_values = np.concatenate((logprob_values,logprob_values_tmp))\n",
    "        end = timer()\n",
    "        print(len(allsamples_tmp),\"samples from file\",samples_file,\"loaded in\",end-start,\"seconds. Samples added to array.\")\n",
    "        del(allsamples_tmp,logprob_values_tmp)\n",
    "    i = i+1\n",
    "    pickle_in.close()\n",
    "    end = timer()\n",
    "allsamples_test = allsamples[-1000000:]\n",
    "logprob_values_test = logprob_values[-1000000:]\n",
    "allsamples_train = allsamples[:-1000000]\n",
    "logprob_values_train = logprob_values[:-1000000]\n",
    "end_global = timer()\n",
    "print(len(allsamples_train),\"training samples and\",len(allsamples_test),\"test samples obtained in\",end_global-start_global,\"s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nnn = len(allsamples_train)\n",
    "nnnn = len(allsamples_test)\n",
    "n_processes = psutil.cpu_count(logical=False)\n",
    "if __name__ ==  '__main__': \n",
    "    print('Running ', n_processes,' parallel processes.')\n",
    "    start = timer()\n",
    "    with Pool(n_processes) as pool:\n",
    "        logprior_values_train = np.array(pool.map(logprior,allsamples_train[0:nnn]))\n",
    "        logprior_values_test = np.array(pool.map(logprior,allsamples_test[0:nnnn]))\n",
    "    end = timer()\n",
    "    print(end-start)\n",
    "loglik_values_train = logprob_values_train-logprior_values_train\n",
    "loglik_values_test = logprob_values_test-logprior_values_test\n",
    "## Check\n",
    "if not np.prod(np.isclose(loglik_values_train[0:1000],np.array(list(map(loglik,allsamples_train[0:1000]))),rtol=1e-15,atol=0)):\n",
    "    print(\"There's something wrong with loglik_values_train\")\n",
    "else:\n",
    "    print(\"loglik_values_train correct within numerical relative accuracy (10^-15)\")\n",
    "if not np.prod(np.isclose(loglik_values_test[0:1000],np.array(list(map(loglik,allsamples_test[0:1000]))),rtol=1e-15,atol=0)):\n",
    "    print(\"There's something wrong with loglik_values_train\")\n",
    "else:\n",
    "    print(\"loglik_values_test correct within numerical relative accuracy (10^-15)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "samples_file = \"Data_samples/likelihood_unbiased_sm_13_thinned1000_11M.pickle\"\n",
    "pickle_out = open(samples_file, 'wb')\n",
    "start = timer()\n",
    "pickle.dump(allsamples_train, pickle_out, protocol=4)\n",
    "pickle.dump(logprob_values_train, pickle_out, protocol=4)\n",
    "pickle.dump(loglik_values_train, pickle_out, protocol=4)\n",
    "pickle.dump(logprior_values_train, pickle_out, protocol=4)\n",
    "pickle.dump(allsamples_test, pickle_out, protocol=4)\n",
    "pickle.dump(logprob_values_test, pickle_out, protocol=4)\n",
    "pickle.dump(loglik_values_test, pickle_out, protocol=4)\n",
    "pickle.dump(logprior_values_test, pickle_out, protocol=4)\n",
    "end = timer()\n",
    "pickle_out.close()\n",
    "statinfo = os.stat(samples_file)\n",
    "print('File saved in',end-start,'seconds.\\nFile size is',statinfo.st_size,'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_file = \"Data_samples/likelihood_unbiased_sm_13_thinned1000_11M.pickle\"\n",
    "pickle_in = open(samples_file,'rb')\n",
    "start = timer()\n",
    "statinfo = os.stat(samples_file)\n",
    "allsamples_train = pickle.load(pickle_in)\n",
    "logprob_values_train = pickle.load(pickle_in)\n",
    "_ = pickle.load(pickle_in)\n",
    "_ = pickle.load(pickle_in)\n",
    "allsamples_test = pickle.load(pickle_in)\n",
    "logprob_values_test = pickle.load(pickle_in)\n",
    "_ = pickle.load(pickle_in)\n",
    "_ = pickle.load(pickle_in)\n",
    "end = timer()\n",
    "pickle_in.close()\n",
    "print('File loaded in ',end-start,' seconds.\\nFile size is ',statinfo.st_size,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start= timer()\n",
    "nbins = 50\n",
    "sigma_contours = [1,2,3,4]\n",
    "HPI_intervals1_all = HPD_intervals(allsamples_train[:,0], intervals = get_CI_from_sigma(sigma_contours), weights=None, nbins=nbins, print_hist=False, reduce_binning=True)\n",
    "HPI_intervals1_pos = HPD_intervals(allsamples_train[:,0][allsamples_train[:,0]>0], intervals = get_CI_from_sigma(sigma_contours), weights=None, nbins=nbins, print_hist=False, reduce_binning=True)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Value of mu with highest marginal 1D probability (Bayesian)\n",
    "print(np.mean(allsamples_train[:,0]))\n",
    "#Value of mu in maximum likelihood point (frequentist)\n",
    "print(minimize(minus_logprob,np.full(95,0),method='Powell')['x'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "nnn1 = len(allsamples_train)\n",
    "nnn2 = len(allsamples_test)\n",
    "ilist = [0,3,6,30,61,85]\n",
    "nndim = len(ilist)\n",
    "nbins = 50\n",
    "s1 = allsamples_train\n",
    "s2 = allsamples_test\n",
    "rnd_indices_1 = np.random.choice(np.arange(len(s1)),size=nnn1,replace=False)\n",
    "rnd_indices_2 = np.random.choice(np.arange(len(s2)),size=nnn2,replace=False)\n",
    "samp_1 = s1[rnd_indices_1][:,ilist]\n",
    "samp_2 = s2[rnd_indices_2][:,ilist]\n",
    "ranges = extend_corner_range(s1,s2,ilist,0)\n",
    "sigma_contours = [1,2,3]\n",
    "HPI_intervals1 = [HPD_intervals(samp_1[:,i], intervals = get_CI_from_sigma(sigma_contours), weights=None, nbins=nbins, print_hist=False, reduce_binning=True) for i in range(nndim)]\n",
    "HPI_intervals2 = [HPD_intervals(samp_2[:,i], intervals = get_CI_from_sigma(sigma_contours), weights=None, nbins=nbins, print_hist=False, reduce_binning=True) for i in range(nndim)]\n",
    "levels1 = np.array([[np.sort(HPD_quotas(samp_1[:,[i,j]], nbins=nbins, intervals = get_CI_from_sigma(sigma_contours))).tolist() for j in range(nndim)] for i in range(nndim)])\n",
    "levels2 = np.array([[np.sort(HPD_quotas(samp_2[:,[i,j]], nbins=nbins, intervals = get_CI_from_sigma(sigma_contours), weights=None)).tolist() for j in range(nndim)] for i in range(nndim)])\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_corners(ilist, nbins, samp_1, samp_2, w1=None, w2=None, levels1=levels1, levels2=levels2, HPI_intervals1=HPI_intervals1, HPI_intervals2=HPI_intervals2, \n",
    "             ranges=ranges, title1=\"$68\\%$ HPDI train\", title2=\"$68\\%$ HPDI test\", color1=greens[-9], color2=reds[9], plot_title=\"Train vs test set of $S_{1}$\", \n",
    "             legend_labels = [r\"Train set ($10^{7}$ points)\",r\"Test set ($10^{6}$ points)\",r'$68.27\\%$ HPDI', r'$95.45\\%$ HPDI', r'$99.73\\%$ HPDI'], figdir=fig_dir, figname=\"corner_toy_lik_params.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Bayesian DNNLikelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform training scan and saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_RUNS = 5\n",
    "ACT_FUNC_OUT_LAYER_LIST = ['linear']\n",
    "BATCH_NORM_LIST = [False]\n",
    "CONTINUE_TRAINING = False\n",
    "DROPOUT_RATE_LIST = [0]\n",
    "EARLY_STOPPING = True\n",
    "FILE_SAMPLES_LIST = [\"Data_samples/likelihood_unbiased_sm_13_thinned1000_11M.pickle\"]\n",
    "FOLDER = 'DNNLikelihoods/'\n",
    "FREQUENTISTS_RESULTS = False\n",
    "GENERATE_DATA = True\n",
    "# This also automatically sets GENERATE_DATA = True\n",
    "GENERATE_DATA_ON_THE_FLY = False\n",
    "HID_LAYERS_LIST = [\n",
    "                  [[500, 'selu'], [500, 'selu']],\n",
    "                  [[1000, 'selu'], [1000, 'selu']],\n",
    "                  [[2000, 'selu'], [2000, 'selu']],\n",
    "                  [[5000, 'selu'], [5000, 'selu']]\n",
    "                  ]\n",
    "LABELS = [r\"$\\mu$\"]+[r\"$\\delta_{%d}$\" % i for i in range(1, 95)]\n",
    "LEARNING_RATE_LIST = [10**(-3)]\n",
    "LOAD_MODEL = 'None'\n",
    "LOGPROB_THRESHOLD = -1*np.inf\n",
    "LOSS_LIST = ['mse']\n",
    "METRICS = ['mse', 'mae', 'mape', 'me', 'mpe']\n",
    "MODEL_CHEKPOINT = False\n",
    "MONITORED_METRIC = 'mse'\n",
    "MULTI_GPU = False\n",
    "N_EPOCHS = 15\n",
    "NEVENTS_TRAIN_LIST = [100000,200000,500000]\n",
    "BATCH_SIZE_LIST = [int(closest_power2(x/200)) for x in NEVENTS_TRAIN_LIST]\n",
    "MIN_DELTA_LIST = [1/x for x in NEVENTS_TRAIN_LIST]\n",
    "PARS = [0, 3, 6, 30, 61, 85]\n",
    "PLOTLOSSES = False\n",
    "REDUCE_LR = True\n",
    "REDUCE_LR_PATIENCE_LIST = [40]\n",
    "SCALE_X = False\n",
    "SCALE_Y = True\n",
    "TEST_FRACTION = 0.5\n",
    "VALIDATION_FRACTION = 0.5\n",
    "WEIGHT_SAMPLES_LIST = [False]\n",
    "\n",
    "#From previous run\n",
    "try:\n",
    "    [allsamples_train, logprob_values_train, allsamples_test, logprob_values_test] = [allsamples_train, logprob_values_train, allsamples_test, logprob_values_test]\n",
    "except:\n",
    "    [allsamples_train, logprob_values_train, allsamples_test,logprob_values_test] = ['None', 'None', 'None', 'None']\n",
    "try:\n",
    "    [rnd_indices_train, rnd_indices_val, rnd_indices_test] = [rnd_indices_train, rnd_indices_val, rnd_indices_test]\n",
    "except:\n",
    "    [rnd_indices_train, rnd_indices_val, rnd_indices_test] = ['None', 'None', 'None']\n",
    "try:\n",
    "    LOGPROB_THRESHOLD_INDICES_TRAIN, LOGPROB_THRESHOLD_INDICES_TEST = [LOGPROB_THRESHOLD_INDICES_TRAIN, LOGPROB_THRESHOLD_INDICES_TEST]\n",
    "except:\n",
    "    LOGPROB_THRESHOLD_INDICES_TRAIN, LOGPROB_THRESHOLD_INDICES_TEST = ['None', 'None']\n",
    "try:\n",
    "    [X_train, X_val, X_test, Y_train, Y_val, Y_test, W_train, W_val] = [X_train, X_val, X_test, Y_train, Y_val, Y_test, W_train, W_val]\n",
    "except:\n",
    "    [X_train, X_val, X_test, Y_train, Y_val, Y_test, W_train, W_val] = ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None']\n",
    "try:\n",
    "    [scalerX, scalerY] = [scalerX, scalerY]\n",
    "except:\n",
    "    [scalerX, scalerY] = ['None', 'None']\n",
    "try:\n",
    "    model = model\n",
    "    training_model = training_model\n",
    "except:\n",
    "    model = 'None'\n",
    "    training_model = 'None'\n",
    "try:\n",
    "    summary_log = summary_log\n",
    "    history = history\n",
    "    training_time = training_time\n",
    "except:\n",
    "    summary_log = 'None'\n",
    "    history = 'None'\n",
    "    training_time = 'None'\n",
    "    \n",
    "\n",
    "[allsamples_train, logprob_values_train, allsamples_test, logprob_values_test, LOGPROB_THRESHOLD_INDICES_TRAIN, LOGPROB_THRESHOLD_INDICES_TEST, rnd_indices_train, rnd_indices_val, rnd_indices_test, X_train, X_val, X_test, Y_train, Y_val, Y_test, W_train,\n",
    " W_val, scalerX, scalerY, model, training_model, summary_log, history, training_time] = model_training_scan(N_RUNS, ACT_FUNC_OUT_LAYER_LIST,\n",
    "                                                                                                            BATCH_NORM_LIST, BATCH_SIZE_LIST, CONTINUE_TRAINING, DROPOUT_RATE_LIST, EARLY_STOPPING, FILE_SAMPLES_LIST, FOLDER, FREQUENTISTS_RESULTS, GENERATE_DATA,\n",
    "                                                                                                            GENERATE_DATA_ON_THE_FLY, GPU_names, HID_LAYERS_LIST, LABELS, LEARNING_RATE_LIST, LOAD_MODEL, LOGPROB_THRESHOLD, LOGPROB_THRESHOLD_INDICES_TRAIN, LOGPROB_THRESHOLD_INDICES_TEST, LOSS_LIST, METRICS, MIN_DELTA_LIST, MODEL_CHEKPOINT, MONITORED_METRIC, MULTI_GPU, N_EPOCHS, NEVENTS_TRAIN_LIST,\n",
    "                                                                                                            PARS, PLOTLOSSES, REDUCE_LR, REDUCE_LR_PATIENCE_LIST, SCALE_X, SCALE_Y, TEST_FRACTION, VALIDATION_FRACTION, WEIGHT_SAMPLES_LIST, allsamples_train, logprob_values_train, allsamples_test, logprob_values_test,\n",
    "                                                                                                            rnd_indices_train, rnd_indices_val, rnd_indices_test, X_train, X_val, X_test, Y_train, Y_val, Y_test, W_train, W_val, scalerX, scalerY, model, training_model, summary_log, history, training_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare and choose best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mydataframe = import_results([\"DNNLikelihoods/\"])\n",
    "mydataframe2 = import_model([\"DNNLikelihoods/\"])\n",
    "for key in mydataframe2.keys():\n",
    "    mydataframe[key]=mydataframe2[key]\n",
    "del(mydataframe2)\n",
    "for key in mydataframe.keys():\n",
    "    mydataframe[metric_name_abbreviate(key)] = mydataframe.pop(key)\n",
    "mydataframe = mydataframe.sort_values(by=['test_loss_best'])\n",
    "mydataframe.info()\n",
    "mydataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_print = np.sort(['1$\\sigma$ HPI rel err test', '1$\\sigma$ HPI rel err train',\n",
    "       '1$\\sigma$ HPI rel err train-test', '1$\\sigma$ HPI rel err val',\n",
    "       'AF out', 'Batch size', 'Date time', 'Dropout',\n",
    "       'Early stopping', 'Epochs', 'GPU(s)', 'Hidden layers',\n",
    "       'KS test-pred_train median', 'KS test-pred_val median', 'KS train-test median', \n",
    "       'KS val-pred_test median', 'Min_delta',\n",
    "       'Name', 'Ndim', 'Nevt-train', 'Nevt-val',\n",
    "       'Number', 'Optimizer', 'Params', 'Prediction time',\n",
    "       'Reduce LR patience',\n",
    "       'Trainable params', 'Training time', 'Weighted', 'loss_best',\n",
    "       'loss_best_scaled', 'mae_best', 'mae_best_scaled', 'mape_best',\n",
    "       'mape_best_scaled', 'me_best', 'me_best_scaled', 'mpe_best',\n",
    "       'mpe_best_scaled', 'mse_best','mse_best_scaled', \n",
    "       'test_loss_best', 'test_loss_best_scaled', 'test_mae_best', 'test_mae_best_scaled',\n",
    "       'test_mape_best', 'test_mape_best_scaled', 'test_me_best', 'test_me_best_scaled',\n",
    "       'test_mpe_best', 'test_mpe_best_scaled', 'test_mse_best', 'test_mse_best_scaled',\n",
    "       'val_loss_best', 'val_loss_best_scaled', 'val_mae_best', 'val_mae_best_scaled',\n",
    "       'val_mape_best', 'val_mape_best_scaled', 'val_me_best', 'val_me_best_scaled', \n",
    "       'val_mpe_best', 'val_mpe_best_scaled', 'val_mse_best', 'val_mse_best_scaled'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0100 = DataFrame(mydataframe[mydataframe[\"Nevt-train\"]==100000].reindex(columns=cols_to_print))\n",
    "df0200 = DataFrame(mydataframe[mydataframe[\"Nevt-train\"]==200000].reindex(columns=cols_to_print))\n",
    "df0500 = DataFrame(mydataframe[mydataframe[\"Nevt-train\"]==500000].reindex(columns=cols_to_print))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sortby(df0100,column_max='KS val-pred_test median',color_min='Green',color_max='Red',highlights_min=['loss_best','mse_best', 'mae_best', 'mape_best', 'me_best', 'mpe_best',\n",
    "                           'val_loss_best', 'val_mse_best', 'val_mae_best', 'val_mape_best', 'val_me_best', 'val_mpe_best',\n",
    "                           'test_loss_best', 'test_mse_best', 'test_mae_best', 'test_mape_best', 'test_me_best', 'test_mpe_best'],highlights_max=['KS test-pred_train median',\n",
    "       'KS test-pred_val median', 'KS val-pred_test median', 'KS train-test median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Name:', df0100.iloc[[1]]['Name'].to_numpy()[0])\n",
    "print('Epochs:', df0100.iloc[[1]]['Epochs'].to_numpy()[0])\n",
    "print('Best loss train:', df0100.iloc[[1]]['mse_best'].to_numpy()[0])\n",
    "print('Best loss val:', df0100.iloc[[1]]['val_mse_best'].to_numpy()[0])\n",
    "print('Best loss test:', df0100.iloc[[1]]['test_mse_best'].to_numpy()[0])\n",
    "print('Best ME train:', df0100.iloc[[1]]['me_best'].to_numpy()[0])\n",
    "print('Best ME val:', df0100.iloc[[1]]['val_me_best'].to_numpy()[0])\n",
    "print('Best ME test:', df0100.iloc[[1]]['test_me_best'].to_numpy()[0])\n",
    "print('Median 1D K-S test/pred-train:',df0100.iloc[[1]]['KS test-pred_train median'].to_numpy()[0])\n",
    "print('Median 1D K-S test/pred-val:',df0100.iloc[[1]]['KS test-pred_val median'].to_numpy()[0])\n",
    "print('Median 1D K-S val/pred-test:',df0100.iloc[[1]]['KS val-pred_test median'].to_numpy()[0])\n",
    "print('Training time:',df0100.iloc[[3]]['Training time'].to_numpy()[0])\n",
    "print('Prediction time:',df0100.iloc[[3]]['Prediction time'].to_numpy()[0]/df0100.iloc[[3]]['Nevt-val'].to_numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sortby(df0200,column_max='KS val-pred_test median',color_min='Green',color_max='Red',highlights_min=['loss_best','mse_best', 'mae_best', 'mape_best', 'me_best', 'mpe_best',\n",
    "                           'val_loss_best', 'val_mse_best', 'val_mae_best', 'val_mape_best', 'val_me_best', 'val_mpe_best',\n",
    "                           'test_loss_best', 'test_mse_best', 'test_mae_best', 'test_mape_best', 'test_me_best', 'test_mpe_best'],highlights_max=['KS test-pred_train median',\n",
    "       'KS test-pred_val median', 'KS val-pred_test median', 'KS train-test median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Name:', df0200.iloc[[1]]['Name'].to_numpy()[0])\n",
    "print('Epochs:', df0200.iloc[[0]]['Epochs'].to_numpy()[0])\n",
    "print('Best loss train:', df0200.iloc[[0]]['mse_best'].to_numpy()[0])\n",
    "print('Best loss val:', df0200.iloc[[0]]['val_mse_best'].to_numpy()[0])\n",
    "print('Best loss test:', df0200.iloc[[0]]['test_mse_best'].to_numpy()[0])\n",
    "print('Best ME train:', df0200.iloc[[0]]['me_best'].to_numpy()[0])\n",
    "print('Best ME val:', df0200.iloc[[0]]['val_me_best'].to_numpy()[0])\n",
    "print('Best ME test:', df0200.iloc[[0]]['test_me_best'].to_numpy()[0])\n",
    "print('Median 1D K-S test/pred-train:',df0200.iloc[[0]]['KS test-pred_train median'].to_numpy()[0])\n",
    "print('Median 1D K-S test/pred-val:',df0200.iloc[[0]]['KS test-pred_val median'].to_numpy()[0])\n",
    "print('Median 1D K-S val/pred-test:',df0200.iloc[[0]]['KS val-pred_test median'].to_numpy()[0])\n",
    "print('Training time:',df0200.iloc[[0]]['Training time'].to_numpy()[0])\n",
    "print('Prediction time:',df0200.iloc[[0]]['Prediction time'].to_numpy()[0]/df0200.iloc[[0]]['Nevt-val'].to_numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sortby(df0500,column_max='KS val-pred_test median',color_min='Green',color_max='Red',highlights_min=['loss_best','mse_best', 'mae_best', 'mape_best', 'me_best', 'mpe_best',\n",
    "                           'val_loss_best', 'val_mse_best', 'val_mae_best', 'val_mape_best', 'val_me_best', 'val_mpe_best',\n",
    "                           'test_loss_best', 'test_mse_best', 'test_mae_best', 'test_mape_best', 'test_me_best', 'test_mpe_best'],highlights_max=['KS test-pred_train median',\n",
    "       'KS test-pred_val median', 'KS val-pred_test median', 'KS train-test median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Name:', df0500.iloc[[0]]['Name'].to_numpy()[0])\n",
    "print('Epochs:', df0500.iloc[[0]]['Epochs'].to_numpy()[0])\n",
    "print('Best loss train:', df0500.iloc[[0]]['mse_best'].to_numpy()[0])\n",
    "print('Best loss val:', df0500.iloc[[0]]['val_mse_best'].to_numpy()[0])\n",
    "print('Best loss test:', df0500.iloc[[0]]['test_mse_best'].to_numpy()[0])\n",
    "print('Best ME train:', df0500.iloc[[0]]['me_best'].to_numpy()[0])\n",
    "print('Best ME val:', df0500.iloc[[0]]['val_me_best'].to_numpy()[0])\n",
    "print('Best ME test:', df0500.iloc[[0]]['test_me_best'].to_numpy()[0])\n",
    "print('Median 1D K-S test/pred-train:',df0500.iloc[[0]]['KS test-pred_train median'].to_numpy()[0])\n",
    "print('Median 1D K-S test/pred-val:',df0500.iloc[[0]]['KS test-pred_val median'].to_numpy()[0])\n",
    "print('Median 1D K-S val/pred-test:',df0500.iloc[[0]]['KS val-pred_test median'].to_numpy()[0])\n",
    "print('Training time:',df0500.iloc[[1]]['Training time'].to_numpy()[0])\n",
    "print('Prediction time:',df0500.iloc[[1]]['Prediction time'].to_numpy()[0]/df0500.iloc[[1]]['Nevt-val'].to_numpy()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B1-B3 DNNLikelihoods results\n",
    "Code is present only for model B1. Repeat replacing model B1 with B2 and B3 (also in figures names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfile = \"DNNLikelihoods/B1_model.h5\"\n",
    "with open(modelfile.replace(\"model.h5\",\"model.json\") as json_file: \n",
    "    data = json.load(json_file)\n",
    "    dict1 = {**{'Name': modelfile},**data}\n",
    "with open(modelfile.replace(\"model.h5\",\"history.json\") as json_file: \n",
    "    data = json.load(json_file)\n",
    "    dict2 = {**{'Name': modelfile},**data}\n",
    "summary_log = {**dict1,**dict2}\n",
    "summary_text = generate_summary_text_reduced(summary_log, False)\n",
    "title = generate_title_from_log_reduced(summary_log)\n",
    "print(modelfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metric = \"loss\"\n",
    "val_metric = \"val_\"+metric\n",
    "history = summary_log\n",
    "filename = \"loss_B1.pdf\"\n",
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "plt.plot(history[metric])\n",
    "plt.plot(history[val_metric])\n",
    "plt.yscale(\"log\")\n",
    "plt.grid(linestyle=\"--\", dashes=(5,5))\n",
    "plt.title(r\"%s\"%title,fontsize=18)\n",
    "plt.xlabel(r\"epoch\")\n",
    "plt.ylabel(r\"loss (mse)\")\n",
    "ylable = (metric.replace(\"_\",\"-\"))\n",
    "plt.legend([r\"training\", r\"validation\"])\n",
    "plt.tight_layout()\n",
    "ax = plt.axes()\n",
    "x1,x2,y1,y2 = plt.axis()\n",
    "plt.text(0.35,0.74,r\"Model $B_{1}$\", fontsize=23, ha='right',ma='left',transform = ax.transAxes)\n",
    "plt.text(0.965,0.15,r\"%s\"%summary_text, fontsize=9, bbox=dict(facecolor=\"green\",alpha=0.15, edgecolor='black', boxstyle='round,pad=0.5'), ha='right',ma='left',transform = ax.transAxes)\n",
    "plt.savefig(r\"%s\" % (fig_dir + \"/\" + filename))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load samples and logprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples_file = \"Data_samples/likelihood_unbiased_sm_13_thinned1000_11M.pickle\"\n",
    "pickle_in = open(samples_file,'rb')\n",
    "start = timer()\n",
    "statinfo = os.stat(samples_file)\n",
    "allsamples_train = pickle.load(pickle_in)\n",
    "logprob_values_train = pickle.load(pickle_in)\n",
    "_ = pickle.load(pickle_in)\n",
    "_ = pickle.load(pickle_in)\n",
    "allsamples_test = pickle.load(pickle_in)\n",
    "logprob_values_test = pickle.load(pickle_in)\n",
    "_ = pickle.load(pickle_in)\n",
    "_ = pickle.load(pickle_in)\n",
    "end = timer()\n",
    "pickle_in.close()\n",
    "print('File loaded in ',end-start,' seconds.\\nFile size is ',statinfo.st_size,'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Inference (reweighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfile = \"DNNLikelihoods/B1_model.h5\"\n",
    "model = load_model(modelfile, custom_objects={'R2_metric': R2_metric, 'Rt_metric':Rt_metric})\n",
    "scalerX, scalerY = load_model_scaler(modelfile)\n",
    "[idx_train,idx_val,idx_test] = load_data_indices(modelfile.replace(\"model.h5\",\"samples_indices.pickle\"))\n",
    "threshold=np.min(logprob_values_train[idx_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "nnn = len(allsamples_test)\n",
    "ilist = [0,3,6,30,61,85]\n",
    "nndim = len(ilist)\n",
    "nbins = 50\n",
    "Y_true = logprob_values_test[:nnn]\n",
    "Y_pred = logprob_DNN_multi(allsamples_test[:nnn],model,scalerX,scalerY,batch_size=2048)\n",
    "weights_DNN = np.exp(Y_pred)/np.exp(Y_true)\n",
    "samp_true = allsamples_test[:nnn][:,ilist]\n",
    "samp_DNN_weights = weights_DNN/np.sum(weights_DNN)*len(samp_true)\n",
    "ranges = extend_corner_range(allsamples_test,allsamples_test,ilist,0)\n",
    "sigma_contours = [1,2,3]\n",
    "HPI_intervals1 = [HPD_intervals(samp_true[:,i], intervals = get_CI_from_sigma(sigma_contours), weights=None, nbins=nbins, print_hist=False, reduce_binning=True) for i in range(nndim)]\n",
    "HPI_intervals2 = [HPD_intervals(samp_true[:,i], intervals = get_CI_from_sigma(sigma_contours), weights=samp_DNN_weights, nbins=nbins, print_hist=False, reduce_binning=True) for i in range(nndim)]\n",
    "levels1 = np.array([[np.sort(HPD_quotas(samp_true[:,[i,j]], nbins=nbins, intervals = get_CI_from_sigma(sigma_contours))).tolist() for j in range(nndim)] for i in range(nndim)])\n",
    "levels2 = np.array([[np.sort(HPD_quotas(samp_true[:,[i,j]], nbins=nbins, intervals = get_CI_from_sigma(sigma_contours), weights=samp_DNN_weights)).tolist() for j in range(nndim)] for i in range(nndim)])\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_corners(ilist, nbins, samp_true, samp_true, w1=None, w2=samp_DNN_weights, levels1=levels1, levels2=levels2, HPI_intervals1=HPI_intervals1, HPI_intervals2=HPI_intervals2, \n",
    "             ranges=ranges, title1=\"$68\\%$ HPDI test\", title2=\"$68\\%$ HPDI DNN $B_{1}$\", color1=greens[-9], color2=reds[9], plot_title=\"DNN $B_{1}$ reweighting\", \n",
    "             legend_labels = [r\"Test set ($10^{6}$ points)\",r\"Test set reweighted with DNN $B_{1}$\",r'$68.27\\%$ HPDI', r'$95.45\\%$ HPDI', r'$99.73\\%$ HPDI'], figdir=fig_dir, figname=\"corner_toy_lik_test_vs_DNN_B1_params_reweighting.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start= timer()\n",
    "nbins = 50\n",
    "sigma_contours = [1,2,3]\n",
    "HPI_intervals1_all = HPD_intervals(samp_true[:,0], intervals = get_CI_from_sigma(sigma_contours), weights=samp_DNN_weights, nbins=nbins, print_hist=False, reduce_binning=True)\n",
    "HPI_intervals1_pos = HPD_intervals(samp_true[:,0][samp_true[:,0]>0], intervals = get_CI_from_sigma(sigma_contours), weights=samp_DNN_weights[samp_true[:,0]>0], nbins=nbins, print_hist=False, reduce_binning=True)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HPI_intervals1_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HPI_intervals1_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfile =\"DNNLikelihoods/B1_model.h5\"\n",
    "model = load_model(modelfile, custom_objects={'R2_metric': R2_metric, 'Rt_metric':Rt_metric})\n",
    "scalerX, scalerY = load_model_scaler(modelfile)\n",
    "[idx_train,idx_val,idx_test] = load_data_indices(modelfile.replace(\"model.h5\",\"samples_indices.pickle\"))\n",
    "threshold=np.min(logprob_values_train[idx_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## In my case MULTI_GPU takes a little more than a single GPU, but it may well depend on the hardware architecture\n",
    "# sampler inputs\n",
    "NEW_SAMPLING = True\n",
    "INITIALIZE_IN_BALL = False\n",
    "MULTI_GPU = False\n",
    "logprob_fn = logprob_DNN_multi\n",
    "\n",
    "ndim, nwalkers, nsteps = 95, 1024, 100000\n",
    "\n",
    "if len(K.tensorflow_backend._get_available_gpus()) <= 1:\n",
    "    MULTI_GPU = False\n",
    "\n",
    "if MULTI_GPU:\n",
    "    parallel_model = model_compile(model,model.loss,model.optimizer,model.metrics,True)\n",
    "    args = [parallel_model,scalerX,scalerY,nwalkers,threshold]\n",
    "else:\n",
    "    args = [model,scalerX,scalerY,nwalkers,threshold]\n",
    "    \n",
    "# Initialize backend\n",
    "filename = \"Data_samples/DNNLikelihood_B1_sampling.h5\"\n",
    "chainsname = 'toy_likelihood'\n",
    "backend = emcee.backends.HDFBackend(filename, name=chainsname)\n",
    "if NEW_SAMPLING:\n",
    "    # starting value of parameters\n",
    "    if INITIALIZE_IN_BALL:\n",
    "        start = timer()\n",
    "        maxlik = minimize(lambda delta: -logprob(delta), np.full(95,0),method='Powell')\n",
    "        p0 =  [maxlik['x']+0.01*np.insert(np.random.normal(0,1,94),0,np.random.uniform(-1,5)) for i in range(nwalkers)]\n",
    "        end = timer()\n",
    "        print(\"Initialization around maximum likelihood performed in\",end-start,\"s.\")\n",
    "    else:\n",
    "        p0 = [np.full(95,0)+np.insert(np.random.normal(0,1,94),0,np.random.uniform(-1,5)) for i in range(nwalkers)]\n",
    "    backend.reset(nwalkers, ndim)\n",
    "else:\n",
    "    p0 = backend.get_last_sample()\n",
    "print(\"Initial number of steps: {0}\".format(backend.iteration))\n",
    "\n",
    "moves = emcee.moves.StretchMove(1.3)\n",
    "\n",
    "start = timer()\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, logprob_fn, moves=moves, backend=backend, args=args, vectorize=True)\n",
    "sampler.run_mcmc(p0, nsteps, progress=True)\n",
    "end = timer()\n",
    "print('Done in ',end-start,'seconds')\n",
    "print(\"Final number of steps: {0}\".format(backend.iteration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract samples with thin=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Data_samples/DNNLikelihood_B1_sampling.h5\"\n",
    "chainsname = 'toy_likelihood'\n",
    "start = timer()\n",
    "backend = import_sampler(filename,chainsname)\n",
    "allsamples = backend.get_chain(discard=50000,thin=50,flat=True)\n",
    "logprob_values = backend.get_log_prob(discard=50000,thin=50,flat=True)\n",
    "end = timer()\n",
    "print(len(allsamples),\"independent samples extracted in\", end-start, \"s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logprob_values = logprob_values[allsamples[:,0]>-1][0:1000000]\n",
    "allsamples = allsamples[allsamples[:,0]>-1][0:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnn = len(allsamples)\n",
    "n_processes = psutil.cpu_count(logical=False)\n",
    "if __name__ ==  '__main__': \n",
    "    print('Running ', n_processes,' parallel processes.')\n",
    "    start = timer()\n",
    "    with Pool(n_processes) as pool:\n",
    "        logprior_values = np.array(pool.map(logprior,allsamples[0:nnn]))\n",
    "    end = timer()\n",
    "    print(end-start)\n",
    "loglik_values = logprob_values-logprior_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_file = \"Data_samples/DNNLikelihood_B1.pickle\"\n",
    "pickle_out = open(samples_file, 'wb')\n",
    "start = timer()\n",
    "pickle.dump(allsamples, pickle_out, protocol=4)\n",
    "pickle.dump(logprob_values, pickle_out, protocol=4)\n",
    "pickle.dump(loglik_values, pickle_out, protocol=4)\n",
    "pickle.dump(logprior_values, pickle_out, protocol=4)\n",
    "end = timer()\n",
    "pickle_out.close()\n",
    "statinfo = os.stat(samples_file)\n",
    "print('File saved in',end-start,'seconds.\\nFile size is',statinfo.st_size,'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Inference (resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_file = \"Data_samples/likelihood_unbiased_sm_13_thinned1000_11M.pickle\"\n",
    "pickle_in = open(samples_file,'rb')\n",
    "start = timer()\n",
    "statinfo = os.stat(samples_file)\n",
    "_ = pickle.load(pickle_in)\n",
    "_ = pickle.load(pickle_in)\n",
    "_ = pickle.load(pickle_in)\n",
    "_ = pickle.load(pickle_in)\n",
    "allsamples_test = pickle.load(pickle_in)\n",
    "logprob_values_test = pickle.load(pickle_in)\n",
    "_ = pickle.load(pickle_in)\n",
    "_ = pickle.load(pickle_in)\n",
    "end = timer()\n",
    "pickle_in.close()\n",
    "print('File loaded in ',end-start,' seconds.\\nFile size is ',statinfo.st_size,'.')\n",
    "samples_file = \"Data_samples/DNNLikelihood_B1.pickle\"\n",
    "pickle_in = open(samples_file, 'rb')\n",
    "start = timer()\n",
    "allsamples_DNN_B1 = pickle.load(pickle_in)\n",
    "logprob_values_DNN_B1 = pickle.load(pickle_in)\n",
    "end = timer()\n",
    "pickle_in.close()\n",
    "statinfo = os.stat(samples_file)\n",
    "print('File saved in ',end-start,' seconds.\\nFile size is ',statinfo.st_size,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "nnn1 = len(allsamples_test)\n",
    "nnn2 = len(allsamples_DNN_B1)\n",
    "ilist = [0,3,6,30,61,85]\n",
    "nndim = len(ilist)\n",
    "nbins = 50\n",
    "s1 = allsamples_test\n",
    "s2 = allsamples_DNN_B1\n",
    "rnd_indices_1 = np.random.choice(np.arange(len(s1)),size=nnn1,replace=False)\n",
    "rnd_indices_2 = np.random.choice(np.arange(len(s2)),size=nnn2,replace=False)\n",
    "samp_1 = s1[rnd_indices_1][:,ilist]\n",
    "samp_2 = s2[rnd_indices_2][:,ilist]\n",
    "ranges = extend_corner_range(s1,s1,ilist,0)\n",
    "sigma_contours = [1,2,3]\n",
    "HPI_intervals1 = [HPD_intervals(samp_1[:,i], intervals = get_CI_from_sigma(sigma_contours), weights=None, nbins=nbins, print_hist=False, reduce_binning=True) for i in range(nndim)]\n",
    "HPI_intervals2 = [HPD_intervals(samp_2[:,i], intervals = get_CI_from_sigma(sigma_contours), weights=None, nbins=nbins, print_hist=False, reduce_binning=True) for i in range(nndim)]\n",
    "levels1 = np.array([[np.sort(HPD_quotas(samp_1[:,[i,j]], nbins=nbins, intervals = get_CI_from_sigma(sigma_contours))).tolist() for j in range(nndim)] for i in range(nndim)])\n",
    "levels2 = np.array([[np.sort(HPD_quotas(samp_2[:,[i,j]], nbins=nbins, intervals = get_CI_from_sigma(sigma_contours), weights=None)).tolist() for j in range(nndim)] for i in range(nndim)])\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_corners(ilist, nbins, samp_1, samp_2, w1=None, w2=None, levels1=levels1, levels2=levels2, HPI_intervals1=HPI_intervals1, HPI_intervals2=HPI_intervals2, \n",
    "             ranges=ranges, title1=\"$68\\%$ HPDI test\", title2=\"$68\\%$ HPDI DNN $B_{1}$\", color1=greens[-9], color2=reds[9], plot_title=\"DNN $B_{1}$ sampling\", \n",
    "             legend_labels = [r\"Test set ($10^{6}$ points)\",r\"Sampled DNN $B_{1}$ ($10^{6}$ points)\",r'$68.27\\%$ HPDI', r'$95.45\\%$ HPDI', r'$99.73\\%$ HPDI'], figdir=fig_dir, figname=\"corner_toy_lik_test_vs_DNN_B1_params_resampling.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start= timer()\n",
    "nbins = 50\n",
    "sigma_contours = [1,2,3]\n",
    "HPI_intervals1_all = HPD_intervals(samp_2[:,0], intervals = get_CI_from_sigma(sigma_contours), weights=None, nbins=nbins, print_hist=False, reduce_binning=True)\n",
    "HPI_intervals1_pos = HPD_intervals(samp_2[:,0][samp_2[:,0]>0], intervals = get_CI_from_sigma(sigma_contours), weights=None, nbins=nbins, print_hist=False, reduce_binning=True)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HPI_intervals1_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HPI_intervals1_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biased sampling $S_{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "p0 = list(map(lambda mu: np.concatenate((np.array([mu]),minimize(lambda delta: -logprob(np.concatenate((np.array([mu]),delta))), np.full(94,0),method='Powell')['x'])), np.random.uniform(-1,1,200)))\n",
    "end = timer()\n",
    "print(end-start)\n",
    "print(np.sort([[logprob(x),x[0]] for x in result],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_SAMPLING = True\n",
    "logprob_fn = logprob\n",
    "#sampler = import_sampler('sampling_lik_emcee')\n",
    "\n",
    "# sampler inputs\n",
    "ndim, nwalkers, nsteps = 95, 200, 100000\n",
    "\n",
    "# Initialize backend\n",
    "filename = \"Data_samples/likelihood_biased_gm.h5\"\n",
    "chainsname = 'toy_likelihood_gm'\n",
    "backend = emcee.backends.HDFBackend(filename, name=chainsname)\n",
    "if NEW_SAMPLING:\n",
    "    backend.reset(nwalkers, ndim)\n",
    "print(\"Initial number of steps: {0}\".format(backend.iteration))\n",
    "\n",
    "n_processes = psutil.cpu_count(logical=False)\n",
    "if NEW_SAMPLING:\n",
    "    for i in range(n_processes,n_processes+1,2):\n",
    "        if __name__ ==  '__main__': \n",
    "            print('Running ', i,' parallel processes.')\n",
    "            start = timer()\n",
    "            with Pool(i) as pool:\n",
    "                moves = [(emcee.moves.StretchMove(0.001), 0), (emcee.moves.GaussianMove(0.0005, mode='random', factor=None),1)]\n",
    "                sampler = emcee.EnsembleSampler(nwalkers, ndim, logprob_fn, moves=moves, pool=pool, backend=backend)\n",
    "                sampler.run_mcmc(p0, nsteps, progress=True)\n",
    "            end = timer()\n",
    "            print('Done in ',end-start,'seconds')\n",
    "else:\n",
    "    for i in range(n_processes,n_processes+1,2):\n",
    "        if __name__ ==  '__main__': \n",
    "            print('Running ', i,' parallel processes.')\n",
    "            start = timer()\n",
    "            with Pool(i) as pool:\n",
    "                moves = [(emcee.moves.StretchMove(0.001), 0), (emcee.moves.GaussianMove(0.0005, mode='random', factor=None),1)]\n",
    "                sampler = emcee.EnsembleSampler(nwalkers, ndim, logprob_fn, moves=moves,pool=pool, backend=backend)\n",
    "                sampler.run_mcmc(None, nsteps, progress=True)\n",
    "            end = timer()\n",
    "            print('Done in ',end-start,'seconds')\n",
    "print(\"Final number of steps: {0}\".format(backend.iteration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the backend from the folder '../../bigfiles/'\n",
    "filename = \"Data_samples/likelihood_biased_gm.h5\"\n",
    "chainsname = 'toy_likelihood_gm'\n",
    "start = timer()\n",
    "backend = import_sampler(filename,chainsname)\n",
    "chains = backend.get_chain()\n",
    "logprobs = backend.get_log_prob()\n",
    "print(np.shape(chains))\n",
    "end = timer()\n",
    "print(\"Chains and logprobs loaded in\", end-start, \"s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_shape = np.shape(chains)\n",
    "nsteps, nwalkers, ndim = np.shape(chains)\n",
    "print('Chains have shape', res_shape,'\\nThere are',res_shape[1],'chains of',res_shape[0],'steps in',res_shape[2],'dimensions.')\n",
    "del(res_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Chains plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start = timer()\n",
    "filename = \"Data_samples/likelihood_biased_gm.h5\"\n",
    "chainsname = 'toy_likelihood_gm'\n",
    "backend = import_sampler(filename,chainsname)\n",
    "f = h5py.File(filename, 'r')[chainsname]\n",
    "nsteps = f.attrs[\"iteration\"]\n",
    "keys = f.keys()\n",
    "chains_samp = f.get(\"chain\")[:,:,0:1]\n",
    "chains_lp = f.get(\"log_prob\")\n",
    "res_shape = np.shape(chains_samp)\n",
    "nsteps, nwalkers, ndim = np.shape(chains_samp)\n",
    "end = timer()\n",
    "print('Chains have shape', res_shape,'\\nThere are',res_shape[1],'chains of',res_shape[0],'steps in',res_shape[2],'dimensions.\\nLoaded in',end-start,\"s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rnd_chains = np.sort(np.random.choice(np.arange(200),100,replace=False))\n",
    "rnd_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx = np.sort([(i)*(10**j) for i in range(1,11) for j in range(10)])\n",
    "idx = np.unique(idx[idx<len(chains_lp)])\n",
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "plt.plot(idx,-chains_lp[:,rnd_chains][idx], '-', alpha=0.8)\n",
    "plt.grid(linestyle=\"--\", dashes=(5,5))\n",
    "plt.xlabel(r\"step\")\n",
    "plt.ylabel(r\"$-\\log\\mathcal{L}$\")\n",
    "plt.xscale('log')\n",
    "x1,x2,y1,y2 = plt.axis()\n",
    "plt.axis([x1, x2, 282, 318])\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + \"chains_gm_loglik.pdf\",quality=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx = np.sort([(i)*(10**j) for i in range(1,11) for j in range(10)])\n",
    "idx = np.unique(idx[idx<len(chains_samp)])\n",
    "chain = chains_samp[:,:,0]\n",
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "plt.plot(idx,chain[idx][:,rnd_chains], '-', alpha=0.8)\n",
    "plt.grid(linestyle=\"--\", dashes=(5,5))\n",
    "plt.xlabel(r\"step\")\n",
    "plt.ylabel(r\"$\\mu$\")\n",
    "plt.xscale('log')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + \"chains_gm.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Extract unique samples and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nnn = int(1.1*10**7)\n",
    "acceptance_rate = np.average(backend.accepted/nsteps)\n",
    "burnin = int(nsteps - nnn/nwalkers/acceptance_rate)\n",
    "start = timer()\n",
    "allsamples_tmp = chains[burnin:, :, :].reshape([(nsteps-burnin)*nwalkers, ndim])\n",
    "logprob_values_tmp = logprobs[burnin:, :].reshape((nsteps-burnin)*nwalkers)\n",
    "allsamples_tmp2 = np.transpose(np.append(np.transpose(allsamples_tmp), np.array([logprob_values_tmp]), axis=0))\n",
    "allsamples_tmp2 = allsamples_tmp2[allsamples_tmp2[:, -1] > -np.inf]\n",
    "allsamples_unique = np.unique(allsamples_tmp2, axis=0, return_index=False)\n",
    "indices = np.arange(len(allsamples_unique))\n",
    "rnd_indices = np.random.choice(indices, size=nnn, replace=False)\n",
    "allsamples = allsamples_unique[rnd_indices]\n",
    "logprob_values = allsamples[:, -1]\n",
    "allsamples = allsamples[:, :-1]\n",
    "print(len(logprob_values_tmp), len(allsamples_unique), len(allsamples))\n",
    "end = timer()\n",
    "print(end-start)\n",
    "del(allsamples_tmp,logprob_values_tmp,allsamples_tmp2,allsamples_unique,indices,rnd_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "allsamples_gm_train, allsamples_gm_test = train_test_split(allsamples_gm, test_size=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "check_train = np.unique(allsamples_gm_train, axis=0, return_index=False)\n",
    "check_test = np.unique(allsamples_gm_test, axis=0, return_index=False)\n",
    "print(len(check_train),len(allsamples_gm_train))\n",
    "print(len(check_test),len(allsamples_gm_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_file = \"Data_samples/likelihood_biased_gm_11M.pickle\"\n",
    "pickle_out = open(samples_file, 'wb')\n",
    "start = timer()\n",
    "pickle.dump(allsamples_gm_train, pickle_out, protocol=4)\n",
    "pickle.dump(allsamples_gm_test, pickle_out, protocol=4)\n",
    "end = timer()\n",
    "pickle_out.close()\n",
    "statinfo = os.stat(samples_file)\n",
    "print('File saved in ',end-start,' seconds.\\nFile size is ',statinfo.st_size,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_file = \"Data_samples/likelihood_biased_gm_11M.pickle\"\n",
    "pickle_in = open(samples_file, 'rb')\n",
    "start = timer()\n",
    "allsamples_gm_train = pickle.load(pickle_in)\n",
    "allsamples_gm_test = pickle.load(pickle_in)\n",
    "end = timer()\n",
    "pickle_in.close()\n",
    "statinfo = os.stat(samples_file)\n",
    "print('File saved in ',end-start,' seconds.\\nFile size is ',statinfo.st_size,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nnn = len(allsamples_gm_train)\n",
    "nnnn = len(allsamples_gm_test)\n",
    "n_processes = psutil.cpu_count(logical=False)\n",
    "if __name__ ==  '__main__': \n",
    "    print('Running ', n_processes,' parallel processes.')\n",
    "    start = timer()\n",
    "    with Pool(n_processes) as pool:\n",
    "        loglik_values_gm_train = np.array(pool.map(logprior,allsamples_gm_train[0:nnn]))\n",
    "        loglik_values_gm_test = np.array(pool.map(logprior,allsamples_gm_test[0:nnnn]))\n",
    "    end = timer()\n",
    "    print(end-start)\n",
    "loglik_values_gm_train = logprob_values_gm_train-logprior_values_gm_train\n",
    "loglik_values_gm_test = logprob_values_gm_test-logprior_values_gm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples_file = \"Data_samples/likelihood_biased_gm_11M.pickle\"\n",
    "pickle_out = open(samples_file, 'wb')\n",
    "start = timer()\n",
    "pickle.dump(allsamples_gm_train, pickle_out, protocol=4)\n",
    "pickle.dump(logprob_values_gm_train, pickle_out, protocol=4)\n",
    "pickle.dump(loglik_values_gm_train, pickle_out, protocol=4)\n",
    "pickle.dump(logprior_values_gm_train, pickle_out, protocol=4)\n",
    "pickle.dump(allsamples_gm_test, pickle_out, protocol=4)\n",
    "pickle.dump(logprob_values_gm_test, pickle_out, protocol=4)\n",
    "pickle.dump(loglik_values_gm_test, pickle_out, protocol=4)\n",
    "pickle.dump(logprior_values_gm_test, pickle_out, protocol=4)\n",
    "end = timer()\n",
    "pickle_out.close()\n",
    "statinfo = os.stat(samples_file)\n",
    "print('File saved in',end-start,'seconds.\\nFile size is',statinfo.st_size,'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequentist Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_file = \"Data_samples/likelihood_biased_gm_11M.pickle\"\n",
    "pickle_in = open(samples_file,'rb')\n",
    "start = timer()\n",
    "statinfo = os.stat(samples_file)\n",
    "allsamples_gm_train = pickle.load(pickle_in)\n",
    "logprob_values_gm_train = pickle.load(pickle_in)\n",
    "end = timer()\n",
    "pickle_in.close()\n",
    "print('File loaded in ',end-start,' seconds.\\nFile size is ',statinfo.st_size,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "blst = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "if 'tmuexact' in globals():\n",
    "    pass\n",
    "else:\n",
    "    tmuexact = np.array(list(map(tmu, blst)))\n",
    "cl68 = np.array([[-1,2],[1,1]])\n",
    "cl95 = np.array([[-1,2],[4,4]])\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "blst = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "NEVENTS = 100000\n",
    "indices = np.arange(len(allsamples_gm_train))\n",
    "rnd_indices = np.random.choice(indices, size=NEVENTS,replace=False)\n",
    "if 'tmuexact' in globals():\n",
    "    pass\n",
    "else:\n",
    "    tmuexact = np.array(list(map(tmu, blst)))\n",
    "#tmusample0001 = np.array(list(map(lambda x: tmu_sample(x,allsamples_gm_train[rnd_indices],logprob_values_gm_train[rnd_indices],0.001),blst)))\n",
    "tmusample001 = np.array(list(map(lambda x: tmu_sample(x,allsamples_gm_train[rnd_indices],logprob_values_gm_train[rnd_indices],0.01),blst)))\n",
    "tmusample002 = np.array(list(map(lambda x: tmu_sample(x,allsamples_gm_train[rnd_indices],logprob_values_gm_train[rnd_indices],0.02),blst)))\n",
    "tmusample005 = np.array(list(map(lambda x: tmu_sample(x,allsamples_gm_train[rnd_indices],logprob_values_gm_train[rnd_indices],0.05),blst)))\n",
    "tmusample01 = np.array(list(map(lambda x: tmu_sample(x,allsamples_gm_train[rnd_indices],logprob_values_gm_train[rnd_indices],0.1),blst)))\n",
    "del(blst)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "plt.grid(linestyle=\"--\", dashes=(5,5),alpha=0)\n",
    "plt.plot(tmuexact[:,0],tmuexact[:,-1])\n",
    "plt.plot(tmusample001[:,1],tmusample001[:,-1], linestyle=\"--\", dashes=(3,3))\n",
    "plt.plot(tmusample002[:,1],tmusample002[:,-1], linestyle=\"--\", dashes=(3,3))\n",
    "plt.plot(tmusample005[:,1],tmusample005[:,-1], linestyle=\"--\", dashes=(3,3))\n",
    "plt.plot(tmusample01[:,1],tmusample01[:,-1], linestyle=\"--\", dashes=(3,3))\n",
    "x1,x2,y1,y2 = plt.axis()\n",
    "plt.plot(cl68[0],cl68[1],linestyle=\"--\", dashes=(1,1),color='black',alpha=0.9)\n",
    "plt.plot(cl95[0],cl95[1],linestyle=\"--\", dashes=(1,1),color='black',alpha=0.9)\n",
    "plt.axis([x1, x2, y1, y2])\n",
    "plt.xlabel(r'$\\mu$')\n",
    "plt.ylabel(r'$t_{\\mu}(\\mu)$')\n",
    "plt.legend(['Numerical maximization',r'$S_{2}$ (bin size 0.01)',r'$S_{2}$ (bin size 0.02)',r'$S_{2}$ (bin size 0.05)',r'$S_{2}$ (bin size 0.1)'],fontsize=15)\n",
    "plt.text(0.76,-0.1,r'$10^{5}$ samples from $S_{2}$',fontsize=18, ha='center',ma='center')\n",
    "plt.text(0.9,1.1,r\"Wilks' $68.27\\%$\",fontsize=18, ha='center',ma='center')\n",
    "plt.text(0.5,3.45,r\"Wilks' $95.45\\%$\",fontsize=18, ha='center',ma='center')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + 'tmu_samp2_105.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blst = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "NEVENTS = 1000000\n",
    "indices = np.arange(len(allsamples_gm_train))\n",
    "rnd_indices = np.random.choice(indices, size=NEVENTS,replace=False)\n",
    "if 'tmuexact' in globals():\n",
    "    pass\n",
    "else:\n",
    "    tmuexact = np.array(list(map(tmu, blst)))\n",
    "tmusample001 = np.array(list(map(lambda x: tmu_sample(x,allsamples_gm_train[rnd_indices],logprob_values_gm_train[rnd_indices],0.01),blst)))\n",
    "tmusample002 = np.array(list(map(lambda x: tmu_sample(x,allsamples_gm_train[rnd_indices],logprob_values_gm_train[rnd_indices],0.02),blst)))\n",
    "tmusample005 = np.array(list(map(lambda x: tmu_sample(x,allsamples_gm_train[rnd_indices],logprob_values_gm_train[rnd_indices],0.05),blst)))\n",
    "tmusample01 = np.array(list(map(lambda x: tmu_sample(x,allsamples_gm_train[rnd_indices],logprob_values_gm_train[rnd_indices],0.1),blst)))\n",
    "del(blst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "plt.grid(linestyle=\"--\", dashes=(5,5),alpha=0)\n",
    "plt.plot(tmuexact[:,0],tmuexact[:,-1])\n",
    "plt.plot(tmusample001[:,1],tmusample001[:,-1], linestyle=\"--\", dashes=(3,3))\n",
    "plt.plot(tmusample002[:,1],tmusample002[:,-1], linestyle=\"--\", dashes=(3,3))\n",
    "plt.plot(tmusample005[:,1],tmusample005[:,-1], linestyle=\"--\", dashes=(3,3))\n",
    "plt.plot(tmusample01[:,1],tmusample01[:,-1], linestyle=\"--\", dashes=(3,3))\n",
    "x1,x2,y1,y2 = plt.axis()\n",
    "plt.plot(cl68[0],cl68[1],linestyle=\"--\", dashes=(1,1),color='black',alpha=0.9)\n",
    "plt.plot(cl95[0],cl95[1],linestyle=\"--\", dashes=(1,1),color='black',alpha=0.9)\n",
    "plt.axis([x1, x2, y1, y2])\n",
    "plt.xlabel(r'$\\mu$')\n",
    "plt.ylabel(r'$t_{\\mu}(\\mu)$')\n",
    "plt.legend(['Numerical maximization',r'$S_{2}$ (bin size 0.01)',r'$S_{2}$ (bin size 0.02)',r'$S_{2}$ (bin size 0.05)',r'$S_{2}$ (bin size 0.1)'],fontsize=15)\n",
    "plt.text(0.76,-0.1,r'$10^{6}$ samples from $S_{2}$',fontsize=18, ha='center',ma='center')\n",
    "plt.text(0.9,1.1,r\"Wilks' $68.27\\%$\",fontsize=18, ha='center',ma='center')\n",
    "plt.text(0.5,3.45,r\"Wilks' $95.45\\%$\",fontsize=18, ha='center',ma='center')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + 'tmu_samp2_106.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blst = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "NEVENTS = 10000000\n",
    "indices = np.arange(len(allsamples_gm_train))\n",
    "rnd_indices = np.random.choice(indices, size=NEVENTS,replace=False)\n",
    "if 'tmuexact' in globals():\n",
    "    pass\n",
    "else:\n",
    "    tmuexact = np.array(list(map(tmu, blst)))\n",
    "tmusample001 = np.array(list(map(lambda x: tmu_sample(x,allsamples_gm_train[rnd_indices],logprob_values_gm_train[rnd_indices],0.01),blst)))\n",
    "tmusample002 = np.array(list(map(lambda x: tmu_sample(x,allsamples_gm_train[rnd_indices],logprob_values_gm_train[rnd_indices],0.02),blst)))\n",
    "tmusample005 = np.array(list(map(lambda x: tmu_sample(x,allsamples_gm_train[rnd_indices],logprob_values_gm_train[rnd_indices],0.05),blst)))\n",
    "tmusample01 = np.array(list(map(lambda x: tmu_sample(x,allsamples_gm_train[rnd_indices],logprob_values_gm_train[rnd_indices],0.1),blst)))\n",
    "del(blst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "plt.grid(linestyle=\"--\", dashes=(5,5),alpha=0)\n",
    "plt.plot(tmuexact[:,0],tmuexact[:,-1])\n",
    "plt.plot(tmusample001[:,1],tmusample001[:,-1], linestyle=\"--\", dashes=(3,3))\n",
    "plt.plot(tmusample002[:,1],tmusample002[:,-1], linestyle=\"--\", dashes=(3,3))\n",
    "plt.plot(tmusample005[:,1],tmusample005[:,-1], linestyle=\"--\", dashes=(3,3))\n",
    "plt.plot(tmusample01[:,1],tmusample01[:,-1], linestyle=\"--\", dashes=(3,3))\n",
    "x1,x2,y1,y2 = plt.axis()\n",
    "plt.plot(cl68[0],cl68[1],linestyle=\"--\", dashes=(1,1),color='black',alpha=0.9)\n",
    "plt.plot(cl95[0],cl95[1],linestyle=\"--\", dashes=(1,1),color='black',alpha=0.9)\n",
    "plt.axis([x1, x2, y1, y2])\n",
    "plt.xlabel(r'$\\mu$')\n",
    "plt.ylabel(r'$t_{\\mu}(\\mu)$')\n",
    "plt.legend(['Numerical maximization',r'$S_{2}$ (bin size 0.01)',r'$S_{2}$ (bin size 0.02)',r'$S_{2}$ (bin size 0.05)',r'$S_{2}$ (bin size 0.1)'],fontsize=15)\n",
    "plt.text(0.76,-0.1,r'$10^{7}$ samples from $S_{2}$',fontsize=18, ha='center',ma='center')\n",
    "plt.text(0.9,1.1,r\"Wilks' $68.27\\%$\",fontsize=18, ha='center',ma='center')\n",
    "plt.text(0.5,3.45,r\"Wilks' $95.45\\%$\",fontsize=18, ha='center',ma='center')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + 'tmu_samp2_107.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(allsamples_gm_train[:100000][[i > 0 and i < 1 for i in allsamples_gm_train[:100000][:, 0]]]))\n",
    "print(len(allsamples_gm_train[:1000000][[i > 0 and i < 1 for i in allsamples_gm_train[:1000000][:, 0]]]))\n",
    "print(len(allsamples_gm_train[[i > 0 and i < 1 for i in allsamples_gm_train[:, 0]]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toys marginal model (hybrid freq/bayes approach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make toys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "murange = np.round(np.arange(0,1.1,0.1),2)\n",
    "customfuncdict = dict([[mu,'custom_func'+'{:.2f}'.format(mu).replace(\".\",\"\")] for mu in murange])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "n_pseudo_exp = 10000\n",
    "mean = np.full(94,0)\n",
    "var = np.identity(94)\n",
    "obs_toys_dict = {}\n",
    "for mu in murange:\n",
    "    toys = np.array([np.concatenate((np.array([mu]),x)) for x in np.random.multivariate_normal(mean,var,n_pseudo_exp)])\n",
    "    obs_toys = [np.round(np.random.poisson(expected(t))) for t in toys for q in range(10)]\n",
    "    obs_toys_dict = {**obs_toys_dict, **{mu: obs_toys}} \n",
    "end = timer()\n",
    "del(obs_toys)\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_processes = 44#psutil.cpu_count(logical=False)\n",
    "toys_result = {}\n",
    "if __name__ ==  '__main__': \n",
    "    print('Running ', n_processes,' parallel processes.')\n",
    "    start = timer()\n",
    "    with Pool(n_processes) as pool:\n",
    "        for mu in murange:\n",
    "            startt = timer()\n",
    "            tmp = np.array(pool.map(custom_func_max,obs_toys_dict[mu]))\n",
    "            tmp2 = np.array(pool.map(eval(customfuncdict[mu]),tmp[:,0].tolist()))\n",
    "            toys_result = {**toys_result, **{mu: np.concatenate((tmp,tmp2.reshape(-1,1)),axis=1)}}\n",
    "            endd = timer()\n",
    "            print('mu =','{:.2f}'.format(mu),'done in',endd-startt,'s')                     \n",
    "    del(tmp,tmp2)\n",
    "    end = timer()\n",
    "    print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "blst = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "if 'tmuexact' in globals():\n",
    "    pass\n",
    "else:\n",
    "    tmuexact = np.array(list(map(tmu, blst)))\n",
    "cl68 = np.array([[-1,2],[1,1]])\n",
    "cl95 = np.array([[-1,2],[4,4]])\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "samples_file = \"Data_samples/pseudo_experiments_hybrid.pickle\"\n",
    "pickle_out = open(samples_file, 'wb')\n",
    "start = timer()\n",
    "pickle.dump(obs_toys_dict, pickle_out, protocol=4)\n",
    "pickle.dump(toys_result, pickle_out, protocol=4)\n",
    "pickle.dump(tmuexact, pickle_out, protocol=4)\n",
    "end = timer()\n",
    "pickle_out.close()\n",
    "statinfo = os.stat(samples_file)\n",
    "print('File saved in',end-start,'seconds.\\nFile size is',statinfo.st_size,'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "murange = np.round(np.arange(0,1.1,0.1),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_file = \"Data_samples/pseudo_experiments_hybrid.pickle\"\n",
    "pickle_in = open(samples_file,'rb')\n",
    "start = timer()\n",
    "statinfo = os.stat(samples_file)\n",
    "obs_toys_dict = pickle.load(pickle_in)\n",
    "toys_result_40K = pickle.load(pickle_in)\n",
    "tmuexact = pickle.load(pickle_in)\n",
    "end = timer()\n",
    "pickle_in.close()\n",
    "print('File loaded in ',end-start,' seconds.\\nFile size is ',statinfo.st_size,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "\n",
    "x = np.linspace(0, 10, 10000)\n",
    "for mu in [i/10 for i in range(0,6)]:\n",
    "    counts, bins = np.histogram(-2*(toys_result[mu][:,3]-toys_result[mu][:,2]),50,density=True)\n",
    "    integral = 1\n",
    "    plt.grid(linestyle=\"--\", dashes=(5,5))\n",
    "    plt.step(bins[:-1], counts/integral, where='post')\n",
    "    x1,x2,y1,y2 = plt.axis()\n",
    "plt.plot(x,stats.chi2.pdf(x, 1))\n",
    "plt.axis([-0.05, 8,-0.05,3])\n",
    "plt.legend(np.append(np.array([r'$\\mu = '+str(mu)+'$' for mu in [i/10 for i in range(0,6)]]),r'$\\chi^{2}_{1}$'))\n",
    "plt.xlabel(r'$t_{\\mu}$')\n",
    "plt.ylabel(r'$f(t_{\\mu}|\\mu)$')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + 'coverage_toy_1_hybrid.pdf')\n",
    "plt.show()\n",
    "\n",
    "for mu in [i/10 for i in range(6,11)]:\n",
    "    counts, bins = np.histogram(-2*(toys_result[mu][:,3]-toys_result[mu][:,2]),50,density=True)\n",
    "    integral = 1\n",
    "    plt.grid(linestyle=\"--\", dashes=(5,5))\n",
    "    plt.step(bins[:-1], counts/integral, where='post')\n",
    "    x1,x2,y1,y2 = plt.axis()\n",
    "plt.plot(x,stats.chi2.pdf(x, 1))\n",
    "plt.axis([-0.05, 8,-0.05,1.3])\n",
    "plt.legend(np.append(np.array([r'$\\mu = '+str(mu)+'$' for mu in [i/10 for i in range(6,11)]]),r'$\\chi^{2}_{1}$'))\n",
    "plt.xlabel(r'$t_{\\mu}$')\n",
    "plt.ylabel(r'$f(t_{\\mu}|\\mu)$')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + 'coverage_toy_2_hybrid.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "solutions = {r'$\\mu$': [r'$t_{\\mu}$',r'coverage']}\n",
    "for i in range(len(murange)):\n",
    "    mu = murange[i]\n",
    "    data = np.sort((-2*(toys_result[mu][:,3]-toys_result[mu][:,2])))\n",
    "    data = data[data>0]\n",
    "    p = np.transpose([data, 1. * np.arange(len(data)) / (len(data) - 1)])\n",
    "    np.amin(np.abs(p[:,0]-tmuexact[1,3]))\n",
    "    res = np.round(p[np.where(np.abs(p[:,0]-tmuexact[i,3]) == np.amin(np.abs(p[:,0]-tmuexact[i,3])))[0][0]].astype(np.double),2)\n",
    "    solutions = {**solutions, **{mu: list(res)}}\n",
    "pd.DataFrame.from_dict(solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[['CL','$\\mu$'],[0.6827,np.interp(0.6827, np.array(list(solutions.values())[1:])[:,1], np.array([float(i) for i in list(solutions.keys())[1:]]))],\n",
    " [0.9545,np.interp(0.9545, np.array(list(solutions.values())[1:])[:,1], np.array([float(i) for i in list(solutions.keys())[1:]]))],\n",
    " [0.9973,np.interp(0.9973, np.array(list(solutions.values())[1:])[:,1], np.array([float(i) for i in list(solutions.keys())[1:]]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[['CL','$t_{\\mu}$'],[0.6827,np.interp(0.6827, np.array(list(solutions.values())[1:])[:,1], np.array(list(solutions.values())[1:])[:,0])],\n",
    " [0.9545,np.interp(0.9545, np.array(list(solutions.values())[1:])[:,1], np.array(list(solutions.values())[1:])[:,0])],\n",
    " [0.9973,np.interp(0.9973, np.array(list(solutions.values())[1:])[:,1], np.array(list(solutions.values())[1:])[:,0])]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[['$t_{\\mu}$','CL'],[1,np.interp(1, np.array(list(solutions.values())[1:])[:,0], np.array(list(solutions.values())[1:])[:,1])],\n",
    " [4,np.interp(4, np.array(list(solutions.values())[1:])[:,0], np.array(list(solutions.values())[1:])[:,1])],\n",
    " [9,np.interp(9, np.array(list(solutions.values())[1:])[:,0], np.array(list(solutions.values())[1:])[:,1])]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.interp(1, np.array(list(solutions.values())[1:])[:,0], np.array(list(solutions.values())[1:])[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toys profile construction (frequentist maxLik approach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make toys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "murange = np.round(np.arange(0,1.1,0.1),2)\n",
    "customfuncdict = dict([[mu,'custom_func'+'{:.2f}'.format(mu).replace(\".\",\"\")] for mu in murange])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "ml_dict = {}\n",
    "for mu in murange:\n",
    "    ml = minimize(lambda x: -logprob(np.concatenate((np.array([mu]), x))), np.full(94, 0), method='Powell')['x']\n",
    "    ml_dict = {**ml_dict, **{mu: np.concatenate((np.array([mu]),ml))}}\n",
    "end = timer()\n",
    "del(ml)\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pseudo_exp = 50000\n",
    "start = timer()\n",
    "obs_toys_dict = {}\n",
    "for mu in murange:\n",
    "    obs_toys = [np.round(np.random.poisson(expected(ml_dict[mu]))) for q in range(n_pseudo_exp)]\n",
    "    obs_toys_dict = {**obs_toys_dict, **{mu: obs_toys}} \n",
    "end = timer()\n",
    "del(obs_toys)\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_processes = 44#psutil.cpu_count(logical=False)\n",
    "toys_result = {}\n",
    "if __name__ ==  '__main__': \n",
    "    print('Running ', n_processes,' parallel processes.')\n",
    "    start = timer()\n",
    "    with Pool(n_processes) as pool:\n",
    "        for mu in murange:\n",
    "            startt = timer()\n",
    "            tmp = np.array(pool.map(custom_func_max,obs_toys_dict[mu]))\n",
    "            tmp2 = np.array(pool.map(eval(customfuncdict[mu]),tmp[:,0].tolist()))\n",
    "            toys_result = {**toys_result, **{mu: np.concatenate((tmp,tmp2.reshape(-1,1)),axis=1)}}\n",
    "            endd = timer()\n",
    "            print('mu =','{:.2f}'.format(mu),'done in',endd-startt,'s')                     \n",
    "    del(tmp,tmp2)\n",
    "    end = timer()\n",
    "    print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "if 'tmuexact' in globals():\n",
    "    pass\n",
    "else:\n",
    "    tmuexact = np.array(list(map(tmu, murange)))\n",
    "cl68 = np.array([[-1,2],[1,1]])\n",
    "cl95 = np.array([[-1,2],[4,4]])\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "samples_file = \"Data_samples/pseudo_experiments_profile.pickle\"\n",
    "pickle_out = open(samples_file, 'wb')\n",
    "start = timer()\n",
    "pickle.dump(ml_dict, pickle_out, protocol=4)\n",
    "pickle.dump(obs_toys_dict, pickle_out, protocol=4)\n",
    "pickle.dump(toys_result, pickle_out, protocol=4)\n",
    "pickle.dump(tmuexact, pickle_out, protocol=4)\n",
    "end = timer()\n",
    "pickle_out.close()\n",
    "statinfo = os.stat(samples_file)\n",
    "print('File saved in',end-start,'seconds.\\nFile size is',statinfo.st_size,'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "murange = np.round(np.arange(0,1.1,0.1),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_file = \"Data_samples/pseudo_experiments_profile.pickle\"\n",
    "pickle_in = open(samples_file,'rb')\n",
    "start = timer()\n",
    "statinfo = os.stat(samples_file)\n",
    "ml_dict = pickle.load(pickle_in)\n",
    "obs_toys_dict = pickle.load(pickle_in)\n",
    "toys_result_40K = pickle.load(pickle_in)\n",
    "tmuexact = pickle.load(pickle_in)\n",
    "end = timer()\n",
    "pickle_in.close()\n",
    "print('File loaded in ',end-start,' seconds.\\nFile size is ',statinfo.st_size,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "\n",
    "x = np.linspace(0, 10, 10000)\n",
    "for mu in [i/10 for i in range(0,6)]:\n",
    "    counts, bins = np.histogram(-2*(toys_result[mu][:,3]-toys_result[mu][:,2]),50,density=True)\n",
    "    integral = 1\n",
    "    plt.grid(linestyle=\"--\", dashes=(5,5))\n",
    "    plt.step(bins[:-1], counts/integral, where='post')\n",
    "    x1,x2,y1,y2 = plt.axis()\n",
    "plt.plot(x,stats.chi2.pdf(x, 1))\n",
    "plt.axis([-0.05, 8,-0.05,3])\n",
    "plt.legend(np.append(np.array([r'$\\mu = '+str(mu)+'$' for mu in [i/10 for i in range(0,6)]]),r'$\\chi^{2}_{1}$'))\n",
    "plt.xlabel(r'$t_{\\mu}$')\n",
    "plt.ylabel(r'$f(t_{\\mu}|\\mu)$')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + 'coverage_toy_1_profile.pdf')\n",
    "plt.show()\n",
    "\n",
    "for mu in [i/10 for i in range(6,11)]:\n",
    "    counts, bins = np.histogram(-2*(toys_result[mu][:,3]-toys_result[mu][:,2]),50,density=True)\n",
    "    integral = 1#counts.sum()\n",
    "    plt.grid(linestyle=\"--\", dashes=(5,5))\n",
    "    plt.step(bins[:-1], counts/integral, where='post')\n",
    "    x1,x2,y1,y2 = plt.axis()\n",
    "plt.plot(x,stats.chi2.pdf(x, 1))\n",
    "plt.axis([-0.05, 8,-0.05,1.3])\n",
    "plt.legend(np.append(np.array([r'$\\mu = '+str(mu)+'$' for mu in [i/10 for i in range(6,11)]]),r'$\\chi^{2}_{1}$'))\n",
    "plt.xlabel(r'$t_{\\mu}$')\n",
    "plt.ylabel(r'$f(t_{\\mu}|\\mu)$')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + 'coverage_toy_2_profile.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "solutions = {r'$\\mu$': [r'$t_{\\mu}$',r'coverage']}\n",
    "for i in range(len(murange)):\n",
    "    mu = murange[i]\n",
    "    data = np.sort((-2*(toys_result[mu][:,3]-toys_result[mu][:,2])))\n",
    "    data = data[data>0]\n",
    "    p = np.transpose([data, 1. * np.arange(len(data)) / (len(data) - 1)])\n",
    "    np.amin(np.abs(p[:,0]-tmuexact[1,3]))\n",
    "    res = np.round(p[np.where(np.abs(p[:,0]-tmuexact[i,3]) == np.amin(np.abs(p[:,0]-tmuexact[i,3])))[0][0]].astype(np.double),2)\n",
    "    solutions = {**solutions, **{mu: list(res)}}\n",
    "pd.DataFrame.from_dict(solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[['CL','$\\mu$'],[0.6827,np.interp(0.6827, np.array(list(solutions.values())[1:])[:,1], np.array([float(i) for i in list(solutions.keys())[1:]]))],\n",
    " [0.9545,np.interp(0.9545, np.array(list(solutions.values())[1:])[:,1], np.array([float(i) for i in list(solutions.keys())[1:]]))],\n",
    " [0.9973,np.interp(0.9973, np.array(list(solutions.values())[1:])[:,1], np.array([float(i) for i in list(solutions.keys())[1:]]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[['CL','$t_{\\mu}$'],[0.6827,np.interp(0.6827, np.array(list(solutions.values())[1:])[:,1], np.array(list(solutions.values())[1:])[:,0])],\n",
    " [0.9545,np.interp(0.9545, np.array(list(solutions.values())[1:])[:,1], np.array(list(solutions.values())[1:])[:,0])],\n",
    " [0.9973,np.interp(0.9973, np.array(list(solutions.values())[1:])[:,1], np.array(list(solutions.values())[1:])[:,0])]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[['$t_{\\mu}$','CL'],[1,np.interp(1, np.array(list(solutions.values())[1:])[:,0], np.array(list(solutions.values())[1:])[:,1])],\n",
    " [4,np.interp(4, np.array(list(solutions.values())[1:])[:,0], np.array(list(solutions.values())[1:])[:,1])],\n",
    " [9,np.interp(9, np.array(list(solutions.values())[1:])[:,0], np.array(list(solutions.values())[1:])[:,1])]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.interp(1, np.array(list(solutions.values())[1:])[:,0], np.array(list(solutions.values())[1:])[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result for $\\chi^{2}_{1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = {r'$\\mu$': [r'$t_{\\mu}$',r'coverage']}\n",
    "dict_chi2={i[0]: [round(i[3],2),round(stats.chi2.cdf(i[3],1),2)] for i in tmuexact}\n",
    "solutions = {**solutions, **dict_chi2}\n",
    "pd.DataFrame.from_dict(solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[['CL','$t_{\\mu}$','$\\mu$']]+[[i,stats.chi2.ppf(i,1),np.interp(stats.chi2.ppf(i,1),tmuexact[:,3],tmuexact[:,0])] for i in [0.6827,0.8282,0.9545,0.9944,0.9973]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Toys (hybrid freq/bayes approach: http://inspirehep.net/record/1196797)\n",
    "\n",
    "#### Make toys\n",
    "\n",
    "start = timer()\n",
    "n_pseudo_exp = 1000\n",
    "mean = np.full(94,0)\n",
    "var = np.identity(94)\n",
    "samples_dict = {}\n",
    "obs_toys_dict = {}\n",
    "for mu in range(11):\n",
    "    mu = mu/10\n",
    "    toys = np.array([np.concatenate((np.array([mu]),x)) for x in np.random.multivariate_normal(mean,var,n_pseudo_exp)])\n",
    "    obs_toys = [np.round(np.random.poisson(expected(t))) for t in toys for q in range(10)]\n",
    "    obs_toys_dict = {**obs_toys_dict, **{str(mu): obs_toys}} \n",
    "    #original_logprob = samples_logprob[rnd_indices]\n",
    "end = timer()\n",
    "del(obs_toys)\n",
    "print(end-start)\n",
    "\n",
    "n_processes = 44#psutil.cpu_count(logical=False)\n",
    "if __name__ ==  '__main__': \n",
    "    print('Running ', n_processes,' parallel processes.')\n",
    "    start = timer()\n",
    "    with Pool(n_processes) as pool:\n",
    "        startt = timer()\n",
    "        maxlogliktoys = {'0.0': np.array(pool.map(custom_func,obs_toys_dict['0.0']))}\n",
    "        maxloglikproftoys = {'0.0': np.array(pool.map(custom_func00,obs_toys_dict['0.0']))}\n",
    "        endd = timer()\n",
    "        print('mu = 0.0 done in',endd-startt,'s')\n",
    "        for mu in range(1,11):\n",
    "            mu = mu/10\n",
    "            startt = timer()\n",
    "            maxlogliktoys = {**maxlogliktoys, **{str(mu): np.array(pool.map(custom_func,obs_toys_dict[str(mu)]))}}\n",
    "            maxloglikproftoys = {**maxloglikproftoys, **{str(mu): np.array(pool.map(eval('custom_func'+str(mu).replace('.','')),obs_toys_dict[str(mu)]))}}\n",
    "            endd = timer()\n",
    "            print('mu = ',str(mu),' done in',endd-startt,'s')                     \n",
    "    end = timer()\n",
    "    print(end-start)\n",
    "\n",
    "obs_toys_dict[\"0.1\"][0]\n",
    "\n",
    "maxloglikproftoys[\"0.1\"][0]\n",
    "\n",
    "start = timer()\n",
    "blst = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "if 'tmuexact' in globals():\n",
    "    pass\n",
    "else:\n",
    "    tmuexact = np.array(list(map(tmu, blst)))\n",
    "cl68 = np.array([[-1,2],[1,1]])\n",
    "cl95 = np.array([[-1,2],[4,4]])\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "samples_file = '../bigfiles/toys_hybrid'\n",
    "pickle_out = open(samples_file, 'wb')\n",
    "start = timer()\n",
    "pickle.dump(tmuexact, pickle_out, protocol=4)\n",
    "pickle.dump(maxlogliktoys, pickle_out, protocol=4)\n",
    "pickle.dump(maxloglikproftoys, pickle_out, protocol=4)\n",
    "end = timer()\n",
    "pickle_out.close()\n",
    "statinfo = os.stat(samples_file)\n",
    "print('File saved in',end-start,'seconds.\\nFile size is',statinfo.st_size,'.')\n",
    "\n",
    "#### Results\n",
    "\n",
    "samples_file = '../bigfiles/toys_hybrid'\n",
    "pickle_in = open(samples_file,'rb')\n",
    "start = timer()\n",
    "statinfo = os.stat(samples_file)\n",
    "tmuexact = pickle.load(pickle_in)\n",
    "maxlogliktoys = pickle.load(pickle_in)\n",
    "maxloglikproftoys = pickle.load(pickle_in)\n",
    "end = timer()\n",
    "pickle_in.close()\n",
    "print('File loaded in ',end-start,' seconds.\\nFile size is ',statinfo.st_size,'.')\n",
    "\n",
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "\n",
    "x = np.linspace(0, 10, 10000)\n",
    "#chi2 = np.array([[a/100,stats.chi2.pdf(a/100, 1)] for a in range(200)])\n",
    "for mu in [i/10 for i in range(0,6)]:\n",
    "    counts, bins = np.histogram(-2*(maxloglikproftoys[str(mu)]-maxlogliktoys[str(mu)]),50,density=True)\n",
    "    integral = 1#counts.sum()\n",
    "    plt.grid(linestyle=\"--\", dashes=(5,5))\n",
    "    plt.step(bins[:-1], counts/integral, where='post')\n",
    "    #plt.plot(bins[:-1], counts/integral)\n",
    "    x1,x2,y1,y2 = plt.axis()\n",
    "    #plt.plot(chi2[:,0],chi2[:,1])\n",
    "    #plt.yscale('log')\n",
    "    #plt.xlabel(r\"$\\log\\mathcal{L}$\")\n",
    "    #plt.ylabel(r\"$p(\\log\\mathcal{L})$\")\n",
    "plt.plot(x,stats.chi2.pdf(x, 1))\n",
    "plt.axis([-0.05, 8,-0.05,3])\n",
    "plt.legend(np.append(np.array([r'$\\mu = '+str(mu)+'$' for mu in [i/10 for i in range(0,6)]]),r'$\\chi^{2}_{0}$'))\n",
    "plt.xlabel(r'$t_{\\mu}$')\n",
    "plt.ylabel(r'$f(t_{\\mu}|\\mu)$')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + 'coverage_toy_1_hyb.pdf')\n",
    "plt.show()\n",
    "\n",
    "for mu in [i/10 for i in range(6,11)]:\n",
    "    counts, bins = np.histogram(-2*(maxloglikproftoys[str(mu)]-maxlogliktoys[str(mu)]),50,density=True)\n",
    "    integral = 1#counts.sum()\n",
    "    plt.grid(linestyle=\"--\", dashes=(5,5))\n",
    "    plt.step(bins[:-1], counts/integral, where='post')\n",
    "    #plt.plot(bins[:-1], counts/integral)\n",
    "    x1,x2,y1,y2 = plt.axis()\n",
    "    #plt.plot(chi2[:,0],chi2[:,1])\n",
    "    #plt.yscale('log')\n",
    "    #plt.xlabel(r\"$\\log\\mathcal{L}$\")\n",
    "    #plt.ylabel(r\"$p(\\log\\mathcal{L})$\")\n",
    "plt.plot(x,stats.chi2.pdf(x, 1))\n",
    "plt.axis([-0.05, 8,-0.05,1.3])\n",
    "plt.legend(np.append(np.array([r'$\\mu = '+str(mu)+'$' for mu in [i/10 for i in range(6,11)]]),r'$\\chi^{2}_{0}$'))\n",
    "plt.xlabel(r'$t_{\\mu}$')\n",
    "plt.ylabel(r'$f(t_{\\mu}|\\mu)$')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + 'coverage_toy_2_hyb.pdf')\n",
    "plt.show()\n",
    "\n",
    "solutions = {r'$\\mu$': [r'$t_{\\mu}$',r'coverage']}\n",
    "for point in range(11):\n",
    "    point = point/10\n",
    "    data = np.sort((-2*(maxloglikproftoys[str(point)]-maxlogliktoys[str(point)])))\n",
    "    data = data[data>0]\n",
    "    p = np.transpose([data, 1. * np.arange(len(data)) / (len(data) - 1)])\n",
    "    np.amin(np.abs(p[:,0]-tmuexact[1,3]))\n",
    "    # Get the indices of minimum element in numpy array\n",
    "    res = np.round(p[np.where(np.abs(p[:,0]-tmuexact[int(10*point),3]) == np.amin(np.abs(p[:,0]-tmuexact[int(10*point),3])))[0][0]],2)\n",
    "    solutions = {**solutions, **{str(point): list(res)}}\n",
    "pd.DataFrame.from_dict(solutions)\n",
    "\n",
    "print(pd.DataFrame.from_dict(solutions).to_latex())\n",
    "\n",
    "[['CL','$\\mu$'],[0.6827,np.interp(0.6827, np.array(list(solutions.values())[1:])[:,1], np.array([float(i) for i in list(solutions.keys())[1:]]))],\n",
    " [0.8282,np.interp(0.8282, np.array(list(solutions.values())[1:])[:,1], np.array([float(i) for i in list(solutions.keys())[1:]]))],\n",
    " [0.9545,np.interp(0.9545, np.array(list(solutions.values())[1:])[:,1], np.array([float(i) for i in list(solutions.keys())[1:]]))],\n",
    " [0.9944,np.interp(0.9944, np.array(list(solutions.values())[1:])[:,1], np.array([float(i) for i in list(solutions.keys())[1:]]))],\n",
    " [0.9973,np.interp(0.9973, np.array(list(solutions.values())[1:])[:,1], np.array([float(i) for i in list(solutions.keys())[1:]]))]]\n",
    "\n",
    "[['CL','$t_{\\mu}$'],[0.6827,np.interp(0.6827, np.array(list(solutions.values())[1:])[:,1], np.array(list(solutions.values())[1:])[:,0])],\n",
    " [0.8282,np.interp(0.8282, np.array(list(solutions.values())[1:])[:,1], np.array(list(solutions.values())[1:])[:,0])],\n",
    " [0.9545,np.interp(0.9545, np.array(list(solutions.values())[1:])[:,1], np.array(list(solutions.values())[1:])[:,0])],\n",
    " [0.9944,np.interp(0.9944, np.array(list(solutions.values())[1:])[:,1], np.array(list(solutions.values())[1:])[:,0])],\n",
    " [0.9973,np.interp(0.9973, np.array(list(solutions.values())[1:])[:,1], np.array(list(solutions.values())[1:])[:,0])]]\n",
    "\n",
    "[['$t_{\\mu}$','CL'],[1,np.interp(1, np.array(list(solutions.values())[1:])[:,0], np.array(list(solutions.values())[1:])[:,1])],\n",
    " [4,np.interp(4, np.array(list(solutions.values())[1:])[:,0], np.array(list(solutions.values())[1:])[:,1])],\n",
    " [9,np.interp(9, np.array(list(solutions.values())[1:])[:,0], np.array(list(solutions.values())[1:])[:,1])]]\n",
    "\n",
    "[['$t_{\\mu}$','CL'],[1,np.interp(1, np.array(list(solutions.values())[1:])[:,0], np.array(list(solutions.values())[1:])[:,1])],\n",
    " [4,np.interp(4, np.array(list(solutions.values())[1:])[:,0], np.array(list(solutions.values())[1:])[:,1])],\n",
    " [9,np.interp(9, np.array(list(solutions.values())[1:])[:,0], np.array(list(solutions.values())[1:])[:,1])]]\n",
    "\n",
    "np.interp(1, np.array(list(solutions.values())[1:])[:,0], np.array(list(solutions.values())[1:])[:,1])\n",
    "\n",
    "### Toys (pure frequentist approach (MaxLik): http://inspirehep.net/record/1196797)\n",
    "\n",
    "#### Make toys\n",
    "\n",
    "murange = np.round(np.arange(0,1.1,0.1),2)\n",
    "customfuncdict = dict([[mu,'custom_func'+'{:.2f}'.format(mu).replace(\".\",\"\")] for mu in murange])\n",
    "murange\n",
    "\n",
    "start = timer()\n",
    "ml_dict = {}\n",
    "for mu in murange:\n",
    "    ml = minimize(lambda x: -logprob(np.concatenate((np.array([mu]), x))), np.full(94, 0), method='Powell')['x']\n",
    "    ml_dict = {**ml_dict, **{mu: np.concatenate((np.array([mu]),ml))}}\n",
    "end = timer()\n",
    "del(ml)\n",
    "print(end-start)\n",
    "\n",
    "start = timer()\n",
    "obs_toys_dict = {}\n",
    "for mu in murange:\n",
    "    n_pseudo_exp = 30000#int(50/mu)\n",
    "    obs_toys = [np.round(np.random.poisson(expected(ml_dict[mu]))) for q in range(n_pseudo_exp)]\n",
    "    obs_toys_dict = {**obs_toys_dict, **{mu: obs_toys}} \n",
    "    #original_logprob = samples_logprob[rnd_indices]\n",
    "end = timer()\n",
    "del(obs_toys)\n",
    "print(end-start)\n",
    "\n",
    "samples_file = '../bigfiles/toys_maxlik'\n",
    "pickle_out = open(samples_file, 'wb')\n",
    "start = timer()\n",
    "pickle.dump(ml_dict, pickle_out, protocol=4)\n",
    "pickle.dump(obs_toys_dict, pickle_out, protocol=4)\n",
    "end = timer()\n",
    "pickle_out.close()\n",
    "statinfo = os.stat(samples_file)\n",
    "print('File saved in',end-start,'seconds.\\nFile size is',statinfo.st_size,'.')\n",
    "\n",
    "samples_file = '../bigfiles/toys_maxlik'\n",
    "pickle_in = open(samples_file,'rb')\n",
    "start = timer()\n",
    "statinfo = os.stat(samples_file)\n",
    "ml_dict = pickle.load(pickle_in)\n",
    "obs_toys_dict = pickle.load(pickle_in)\n",
    "end = timer()\n",
    "pickle_in.close()\n",
    "print('File loaded in ',end-start,' seconds.\\nFile size is ',statinfo.st_size,'.')\n",
    "\n",
    "n_processes = 44#psutil.cpu_count(logical=False)\n",
    "toys_result = {}\n",
    "if __name__ ==  '__main__': \n",
    "    print('Running ', n_processes,' parallel processes.')\n",
    "    start = timer()\n",
    "    with Pool(n_processes) as pool:\n",
    "        for mu in murange:\n",
    "            startt = timer()\n",
    "            tmp = np.array(pool.map(custom_func_max,obs_toys_dict[mu]))\n",
    "            #tmp = tmp[np.logical_and(tmp[:,1]>0,tmp[:,1]<mu)]\n",
    "            tmp2 = np.array(pool.map(eval(customfuncdict[mu]),tmp[:,0].tolist()))\n",
    "            toys_result = {**toys_result, **{mu: np.concatenate((tmp,tmp2.reshape(-1,1)),axis=1)}}\n",
    "            endd = timer()\n",
    "            print('mu =','{:.2f}'.format(mu),'done in',endd-startt,'s')                     \n",
    "    del(tmp,tmp2)\n",
    "    end = timer()\n",
    "    print(end-start)\n",
    "\n",
    "start = timer()\n",
    "if 'tmuexact' in globals():\n",
    "    pass\n",
    "else:\n",
    "    tmuexact = np.array(list(map(tmu, murange)))\n",
    "cl68 = np.array([[-1,2],[1,1]])\n",
    "cl95 = np.array([[-1,2],[4,4]])\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "samples_file = '../bigfiles/toys_maxlik_30K'\n",
    "pickle_out = open(samples_file, 'wb')\n",
    "start = timer()\n",
    "pickle.dump(ml_dict, pickle_out, protocol=4)\n",
    "pickle.dump(obs_toys_dict, pickle_out, protocol=4)\n",
    "pickle.dump(toys_result, pickle_out, protocol=4)\n",
    "pickle.dump(tmuexact, pickle_out, protocol=4)\n",
    "end = timer()\n",
    "pickle_out.close()\n",
    "statinfo = os.stat(samples_file)\n",
    "print('File saved in',end-start,'seconds.\\nFile size is',statinfo.st_size,'.')\n",
    "\n",
    "samples_file = '../bigfiles/toys_maxlik_30K'\n",
    "pickle_in = open(samples_file,'rb')\n",
    "start = timer()\n",
    "statinfo = os.stat(samples_file)\n",
    "_ = pickle.load(pickle_in)\n",
    "_ = pickle.load(pickle_in)\n",
    "toys_result_30K = pickle.load(pickle_in)\n",
    "_ = pickle.load(pickle_in)\n",
    "end = timer()\n",
    "pickle_in.close()\n",
    "print('File loaded in ',end-start,' seconds.\\nFile size is ',statinfo.st_size,'.')\n",
    "samples_file = '../bigfiles/toys_maxlik_10K'\n",
    "pickle_in = open(samples_file,'rb')\n",
    "start = timer()\n",
    "statinfo = os.stat(samples_file)\n",
    "_ = pickle.load(pickle_in)\n",
    "_ = pickle.load(pickle_in)\n",
    "toys_result_10K = pickle.load(pickle_in)\n",
    "tmuexact = pickle.load(pickle_in)\n",
    "end = timer()\n",
    "pickle_in.close()\n",
    "print('File loaded in ',end-start,' seconds.\\nFile size is ',statinfo.st_size,'.')\n",
    "\n",
    "start = timer()\n",
    "ds = [toys_result_10K, toys_result_30K]\n",
    "toys_result = {}\n",
    "for k in toys_result_10K.keys():\n",
    "    toys_result[k] = np.concatenate(list(d[k] for d in ds))\n",
    "end = timer()\n",
    "print(end-start)\n",
    "\n",
    "samples_file = '../bigfiles/toys_maxlik_40K'\n",
    "pickle_out = open(samples_file, 'wb')\n",
    "start = timer()\n",
    "pickle.dump(ml_dict, pickle_out, protocol=4)\n",
    "pickle.dump(obs_toys_dict, pickle_out, protocol=4)\n",
    "pickle.dump(toys_result, pickle_out, protocol=4)\n",
    "pickle.dump(, pickle_out, protocol=4)\n",
    "end = timer()\n",
    "pickle_out.close()\n",
    "statinfo = os.stat(samples_file)\n",
    "print('File saved in',end-start,'seconds.\\nFile size is',statinfo.st_size,'.')\n",
    "\n",
    "#### Results\n",
    "\n",
    "murange = np.round(np.arange(0,1.1,0.1),2)\n",
    "\n",
    "samples_file = '../bigfiles/toys_maxlik_40K'\n",
    "pickle_in = open(samples_file,'rb')\n",
    "start = timer()\n",
    "statinfo = os.stat(samples_file)\n",
    "ml_dict = pickle.load(pickle_in)\n",
    "obs_toys_dict = pickle.load(pickle_in)\n",
    "toys_result_40K = pickle.load(pickle_in)\n",
    "tmuexact = pickle.load(pickle_in)\n",
    "end = timer()\n",
    "pickle_in.close()\n",
    "print('File loaded in ',end-start,' seconds.\\nFile size is ',statinfo.st_size,'.')\n",
    "\n",
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "\n",
    "x = np.linspace(0, 10, 10000)\n",
    "#chi2 = np.array([[a/100,stats.chi2.pdf(a/100, 1)] for a in range(200)])\n",
    "for mu in [i/10 for i in range(0,6)]:\n",
    "    counts, bins = np.histogram(-2*(toys_result[mu][:,3]-toys_result[mu][:,2]),50,density=True)\n",
    "    integral = 1#counts.sum()\n",
    "    plt.grid(linestyle=\"--\", dashes=(5,5))\n",
    "    plt.step(bins[:-1], counts/integral, where='post')\n",
    "    #plt.plot(bins[:-1], counts/integral)\n",
    "    x1,x2,y1,y2 = plt.axis()\n",
    "    #plt.plot(chi2[:,0],chi2[:,1])\n",
    "    #plt.yscale('log')\n",
    "    #plt.xlabel(r\"$\\log\\mathcal{L}$\")\n",
    "    #plt.ylabel(r\"$p(\\log\\mathcal{L})$\")\n",
    "plt.plot(x,stats.chi2.pdf(x, 1))\n",
    "plt.axis([-0.05, 8,-0.05,3])\n",
    "plt.legend(np.append(np.array([r'$\\mu = '+str(mu)+'$' for mu in [i/10 for i in range(0,6)]]),r'$\\chi^{2}_{1}$'))\n",
    "plt.xlabel(r'$t_{\\mu}$')\n",
    "plt.ylabel(r'$f(t_{\\mu}|\\mu)$')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + 'coverage_toy_1_freq.pdf')\n",
    "plt.show()\n",
    "\n",
    "for mu in [i/10 for i in range(6,11)]:\n",
    "    counts, bins = np.histogram(-2*(toys_result[mu][:,3]-toys_result[mu][:,2]),50,density=True)\n",
    "    integral = 1#counts.sum()\n",
    "    plt.grid(linestyle=\"--\", dashes=(5,5))\n",
    "    plt.step(bins[:-1], counts/integral, where='post')\n",
    "    #plt.plot(bins[:-1], counts/integral)\n",
    "    x1,x2,y1,y2 = plt.axis()\n",
    "    #plt.plot(chi2[:,0],chi2[:,1])\n",
    "    #plt.yscale('log')\n",
    "    #plt.xlabel(r\"$\\log\\mathcal{L}$\")\n",
    "    #plt.ylabel(r\"$p(\\log\\mathcal{L})$\")\n",
    "plt.plot(x,stats.chi2.pdf(x, 1))\n",
    "plt.axis([-0.05, 8,-0.05,1.3])\n",
    "plt.legend(np.append(np.array([r'$\\mu = '+str(mu)+'$' for mu in [i/10 for i in range(6,11)]]),r'$\\chi^{2}_{1}$'))\n",
    "plt.xlabel(r'$t_{\\mu}$')\n",
    "plt.ylabel(r'$f(t_{\\mu}|\\mu)$')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + 'coverage_toy_2_freq.pdf')\n",
    "plt.show()\n",
    "\n",
    "solutions = {r'$\\mu$': [r'$t_{\\mu}$',r'coverage']}\n",
    "for i in range(len(murange)):\n",
    "    mu = murange[i]\n",
    "    data = np.sort((-2*(toys_result[mu][:,3]-toys_result[mu][:,2])))\n",
    "    data = data[data>0]\n",
    "    p = np.transpose([data, 1. * np.arange(len(data)) / (len(data) - 1)])\n",
    "    np.amin(np.abs(p[:,0]-tmuexact[1,3]))\n",
    "    # Get the indices of minimum element in numpy array\n",
    "    res = np.round(p[np.where(np.abs(p[:,0]-tmuexact[i,3]) == np.amin(np.abs(p[:,0]-tmuexact[i,3])))[0][0]].astype(np.double),2)\n",
    "    solutions = {**solutions, **{mu: list(res)}}\n",
    "pd.DataFrame.from_dict(solutions)\n",
    "\n",
    "[['CL','$\\mu$'],[0.6827,np.interp(0.6827, np.array(list(solutions.values())[1:])[:,1], np.array([float(i) for i in list(solutions.keys())[1:]]))],\n",
    " [0.8282,np.interp(0.8282, np.array(list(solutions.values())[1:])[:,1], np.array([float(i) for i in list(solutions.keys())[1:]]))],\n",
    " [0.9545,np.interp(0.9545, np.array(list(solutions.values())[1:])[:,1], np.array([float(i) for i in list(solutions.keys())[1:]]))],\n",
    " [0.9944,np.interp(0.9944, np.array(list(solutions.values())[1:])[:,1], np.array([float(i) for i in list(solutions.keys())[1:]]))],\n",
    " [0.9973,np.interp(0.9973, np.array(list(solutions.values())[1:])[:,1], np.array([float(i) for i in list(solutions.keys())[1:]]))]]\n",
    "\n",
    "[['CL','$t_{\\mu}$'],[0.6827,np.interp(0.6827, np.array(list(solutions.values())[1:])[:,1], np.array(list(solutions.values())[1:])[:,0])],\n",
    " [0.8282,np.interp(0.8282, np.array(list(solutions.values())[1:])[:,1], np.array(list(solutions.values())[1:])[:,0])],\n",
    " [0.9545,np.interp(0.9545, np.array(list(solutions.values())[1:])[:,1], np.array(list(solutions.values())[1:])[:,0])],\n",
    " [0.9944,np.interp(0.9944, np.array(list(solutions.values())[1:])[:,1], np.array(list(solutions.values())[1:])[:,0])],\n",
    " [0.9973,np.interp(0.9973, np.array(list(solutions.values())[1:])[:,1], np.array(list(solutions.values())[1:])[:,0])]]\n",
    "\n",
    "[['$t_{\\mu}$','CL'],[1,np.interp(1, np.array(list(solutions.values())[1:])[:,0], np.array(list(solutions.values())[1:])[:,1])],\n",
    " [4,np.interp(4, np.array(list(solutions.values())[1:])[:,0], np.array(list(solutions.values())[1:])[:,1])],\n",
    " [9,np.interp(9, np.array(list(solutions.values())[1:])[:,0], np.array(list(solutions.values())[1:])[:,1])]]\n",
    "\n",
    "np.interp(1, np.array(list(solutions.values())[1:])[:,0], np.array(list(solutions.values())[1:])[:,1])\n",
    "\n",
    "### Result for $\\chi^{2}_{1}$\n",
    "\n",
    "#solutions = {r'$\\mu$': [r'$t_{\\mu}$',r'coverage']}\n",
    "#x = np.random.chisquare(1,10000)\n",
    "#for i in range(len(murange)):\n",
    "#    mu = murange[i]\n",
    "#    data = np.sort(x)\n",
    "#    data = data[data>0]\n",
    "#    p = np.transpose([data, 1. * np.arange(len(data)) / (len(data) - 1)])\n",
    "#    np.amin(np.abs(p[:,0]-tmuexact[1,3]))\n",
    "#    # Get the indices of minimum element in numpy array\n",
    "#    res = np.round(p[np.where(np.abs(p[:,0]-tmuexact[i,3]) == np.amin(np.abs(p[:,0]-tmuexact[i,3])))[0][0]].astype(np.double),2)\n",
    "#    solutions = {**solutions, **{mu: list(res)}}\n",
    "#pd.DataFrame.from_dict(solutions)\n",
    "\n",
    "solutions = {r'$\\mu$': [r'$t_{\\mu}$',r'coverage']}\n",
    "dict_chi2={i[0]: [round(i[3],2),round(stats.chi2.cdf(i[3],1),2)] for i in tmuexact}\n",
    "solutions = {**solutions, **dict_chi2}\n",
    "pd.DataFrame.from_dict(solutions)\n",
    "\n",
    "[['CL','$t_{\\mu}$','$\\mu$']]+[[i,stats.chi2.ppf(i,1),np.interp(stats.chi2.ppf(i,1),tmuexact[:,3],tmuexact[:,0])] for i in [0.6827,0.8282,0.9545,0.9944,0.9973]]\n",
    "\n",
    "1-0.8282"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toys, coverage, and correct frequentist result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make toys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "n_pseudo_exp = 10000\n",
    "mean = np.full(94,0)\n",
    "var = np.identity(94)\n",
    "samples_dict = {}\n",
    "obs_toys_dict = {}\n",
    "for mu in range(11):\n",
    "    mu = mu/10\n",
    "    toys = np.array([np.concatenate((np.array([mu]),x)) for x in np.random.multivariate_normal(mean,var,n_pseudo_exp)])\n",
    "    obs_toys = [np.round(expected(t)) for t in toys]\n",
    "    obs_toys_dict = {**obs_toys_dict, **{str(mu): obs_toys}} \n",
    "end = timer()\n",
    "del(obs_toys)\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_processes = psutil.cpu_count(logical=False)\n",
    "if __name__ ==  '__main__': \n",
    "    print('Running ', n_processes,' parallel processes.')\n",
    "    start = timer()\n",
    "    with Pool(n_processes) as pool:\n",
    "        startt = timer()\n",
    "        maxlogliktoys = {'0.0': np.array(pool.map(custom_func,obs_toys_dict['0.0']))}\n",
    "        maxloglikproftoys = {'0.0': np.array(pool.map(custom_func00,obs_toys_dict['0.0']))}\n",
    "        endd = timer()\n",
    "        print('mu = 0.0 done in',endd-startt,'s')\n",
    "        for mu in range(1,11):\n",
    "            mu = mu/10\n",
    "            startt = timer()\n",
    "            maxlogliktoys = {**maxlogliktoys, **{str(mu): np.array(pool.map(custom_func,obs_toys_dict[str(mu)]))}}\n",
    "            maxloglikproftoys = {**maxloglikproftoys, **{str(mu): np.array(pool.map(eval('custom_func'+str(mu).replace('.','')),obs_toys_dict[str(mu)]))}}\n",
    "            endd = timer()\n",
    "            print('mu = ',str(mu),' done in',endd-startt,'s')                     \n",
    "    end = timer()\n",
    "    print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "blst = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "if 'tmuexact' in globals():\n",
    "    pass\n",
    "else:\n",
    "    tmuexact = np.array(list(map(tmu, blst)))\n",
    "cl68 = np.array([[-1,2],[1,1]])\n",
    "cl95 = np.array([[-1,2],[3.86,3.86]])\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_file = \"Data_samples/pseudo_experiments_1000.pickle\"\n",
    "pickle_out = open(samples_file, 'wb')\n",
    "start = timer()\n",
    "pickle.dump(tmuexact, pickle_out, protocol=4)\n",
    "pickle.dump(maxlogliktoys, pickle_out, protocol=4)\n",
    "pickle.dump(maxloglikproftoys, pickle_out, protocol=4)\n",
    "end = timer()\n",
    "pickle_out.close()\n",
    "statinfo = os.stat(samples_file)\n",
    "print('File saved in',end-start,'seconds.\\nFile size is',statinfo.st_size,'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_file = \"Data_samples/pseudo_experiments_1000.pickle\"\n",
    "pickle_in = open(samples_file,'rb')\n",
    "start = timer()\n",
    "statinfo = os.stat(samples_file)\n",
    "tmuexact = pickle.load(pickle_in)\n",
    "maxlogliktoys = pickle.load(pickle_in)\n",
    "maxloglikproftoys = pickle.load(pickle_in)\n",
    "end = timer()\n",
    "pickle_in.close()\n",
    "print('File loaded in ',end-start,' seconds.\\nFile size is ',statinfo.st_size,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "\n",
    "x = np.linspace(0, 10, 10000)\n",
    "for mu in [i/10 for i in range(0,6)]:\n",
    "    counts, bins = np.histogram(-2*(maxloglikproftoys[str(mu)]-maxlogliktoys[str(mu)]),50,density=True)\n",
    "    integral = 1\n",
    "    plt.grid(linestyle=\"--\", dashes=(5,5))\n",
    "    plt.step(bins[:-1], counts/integral, where='post')\n",
    "    x1,x2,y1,y2 = plt.axis()\n",
    "plt.plot(x,stats.chi2.pdf(x, 1))\n",
    "plt.axis([-0.05, 8,-0.05,3])\n",
    "plt.legend(np.append(np.array([r'$\\mu = '+str(mu)+'$' for mu in [i/10 for i in range(0,6)]]),r'$\\chi^{2}_{0}$'))\n",
    "plt.xlabel(r'$t_{\\mu}$')\n",
    "plt.ylabel(r'$p(t_{\\mu})$')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + 'coverage_toy_1.pdf')\n",
    "plt.show()\n",
    "\n",
    "for mu in [i/10 for i in range(6,11)]:\n",
    "    counts, bins = np.histogram(-2*(maxloglikproftoys[str(mu)]-maxlogliktoys[str(mu)]),50,density=True)\n",
    "    integral = 1\n",
    "    plt.grid(linestyle=\"--\", dashes=(5,5))\n",
    "    plt.step(bins[:-1], counts/integral, where='post')\n",
    "    x1,x2,y1,y2 = plt.axis()\n",
    "plt.plot(x,stats.chi2.pdf(x, 1))\n",
    "plt.axis([-0.05, 8,-0.05,1.3])\n",
    "plt.legend(np.append(np.array([r'$\\mu = '+str(mu)+'$' for mu in [i/10 for i in range(6,11)]]),r'$\\chi^{2}_{0}$'))\n",
    "plt.xlabel(r'$t_{\\mu}$')\n",
    "plt.ylabel(r'$p(t_{\\mu})$')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + 'coverage_toy_2.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = {r'$\\mu$': [r'$t_{\\mu}$',r'coverage']}\n",
    "for point in range(11):\n",
    "    point = point/10\n",
    "    data = np.sort((-2*(maxloglikproftoys[str(point)]-maxlogliktoys[str(point)])))\n",
    "    data = data[data>0]\n",
    "    p = np.transpose([data, 1. * np.arange(len(data)) / (len(data) - 1)])\n",
    "    np.amin(np.abs(p[:,0]-tmuexact[1,3]))\n",
    "    res = np.round(p[np.where(np.abs(p[:,0]-tmuexact[int(10*point),3]) == np.amin(np.abs(p[:,0]-tmuexact[int(10*point),3])))[0][0]],2)\n",
    "    solutions = {**solutions, **{str(point): list(res)}}\n",
    "pd.DataFrame.from_dict(solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame.from_dict(solutions).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[['CL','$\\mu$'],[0.6827,np.interp(0.6827, np.array(list(solutions.values())[1:])[:,1], np.array([float(i) for i in list(solutions.keys())[1:]]))],\n",
    " [0.8282,np.interp(0.8282, np.array(list(solutions.values())[1:])[:,1], np.array([float(i) for i in list(solutions.keys())[1:]]))],\n",
    " [0.9545,np.interp(0.9545, np.array(list(solutions.values())[1:])[:,1], np.array([float(i) for i in list(solutions.keys())[1:]]))],\n",
    " [0.9944,np.interp(0.9944, np.array(list(solutions.values())[1:])[:,1], np.array([float(i) for i in list(solutions.keys())[1:]]))],\n",
    " [0.9973,np.interp(0.9973, np.array(list(solutions.values())[1:])[:,1], np.array([float(i) for i in list(solutions.keys())[1:]]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "[['CL','$t_{\\mu}$'],[0.6827,np.interp(0.6827, np.array(list(solutions.values())[1:])[:,1], np.array(list(solutions.values())[1:])[:,0])],\n",
    " [0.8282,np.interp(0.8282, np.array(list(solutions.values())[1:])[:,1], np.array(list(solutions.values())[1:])[:,0])],\n",
    " [0.9545,np.interp(0.9545, np.array(list(solutions.values())[1:])[:,1], np.array(list(solutions.values())[1:])[:,0])],\n",
    " [0.9944,np.interp(0.9944, np.array(list(solutions.values())[1:])[:,1], np.array(list(solutions.values())[1:])[:,0])],\n",
    " [0.9973,np.interp(0.9973, np.array(list(solutions.values())[1:])[:,1], np.array(list(solutions.values())[1:])[:,0])]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[['$t_{\\mu}$','CL'],[1,np.interp(1, np.array(list(solutions.values())[1:])[:,0], np.array(list(solutions.values())[1:])[:,1])],\n",
    " [4,np.interp(4, np.array(list(solutions.values())[1:])[:,0], np.array(list(solutions.values())[1:])[:,1])],\n",
    " [9,np.interp(9, np.array(list(solutions.values())[1:])[:,0], np.array(list(solutions.values())[1:])[:,1])]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[['CL','$\\mu$'],[0.82816,np.interp([0.82816, np.array(list(solutions.values())[1:])[:,1], np.array([float(i) for i in list(solutions.keys())[1:]]))],\n",
    " [0.9545,np.interp(0.9545, np.array(list(solutions.values())[1:])[:,1], np.array([float(i) for i in list(solutions.keys())[1:]]))],\n",
    " [0.9973,np.interp(0.9973, np.array(list(solutions.values())[1:])[:,1], np.array([float(i) for i in list(solutions.keys())[1:]]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.interp(1, np.array(list(solutions.values())[1:])[:,0], np.array(list(solutions.values())[1:])[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixed Sampling $S_{3}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make and save mixed sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_file = \"Data_samples/likelihood_unbiased_sm_13_thinned1000_11M.pickle\"\n",
    "pickle_in = open(samples_file,'rb')\n",
    "start = timer()\n",
    "statinfo = os.stat(samples_file)\n",
    "allsamples_train = pickle.load(pickle_in)\n",
    "logprob_values_train = pickle.load(pickle_in)\n",
    "loglik_values_train = pickle.load(pickle_in)\n",
    "logprior_values_train = pickle.load(pickle_in)\n",
    "allsamples_test = pickle.load(pickle_in)\n",
    "logprob_values_test = pickle.load(pickle_in)\n",
    "loglik_values_test = pickle.load(pickle_in)\n",
    "logprior_values_test = pickle.load(pickle_in)\n",
    "end = timer()\n",
    "pickle_in.close()\n",
    "print('File loaded in ',end-start,' seconds.\\nFile size is ',statinfo.st_size,'.')\n",
    "samples_file = \"Data_samples/likelihood_biased_gm_11M.pickle\"\n",
    "pickle_in = open(samples_file,'rb')\n",
    "start = timer()\n",
    "statinfo = os.stat(samples_file)\n",
    "allsamples_gm_train = pickle.load(pickle_in)\n",
    "logprob_values_gm_train = pickle.load(pickle_in)\n",
    "loglik_values_gm_train = pickle.load(pickle_in)\n",
    "logprior_values_gm_train = pickle.load(pickle_in)\n",
    "allsamples_gm_test = pickle.load(pickle_in)\n",
    "logprob_values_gm_test = pickle.load(pickle_in)\n",
    "loglik_values_gm_test = pickle.load(pickle_in)\n",
    "logprior_values_gm_test = pickle.load(pickle_in)\n",
    "end = timer()\n",
    "pickle_in.close()\n",
    "print('File loaded in ',end-start,' seconds.\\nFile size is ',statinfo.st_size,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_points = 300000\n",
    "\n",
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "plt.grid(linestyle=\"--\", dashes=(5,5))\n",
    "\n",
    "counts, bins = np.histogram(np.concatenate((logprob_values_train[:show_points],logprob_values_gm_train[:show_points])), 100)\n",
    "\n",
    "for frac1 in [5000000,6000000,7000000,8000000]:\n",
    "    frac2 = round((len(logprob_values_train)-frac1-np.count_nonzero(logprob_values_gm_train>-290)))\n",
    "    rnd_indices = np.arange(len(logprob_values_train))\n",
    "    np.random.shuffle(rnd_indices)\n",
    "    logprob_values_mixed_train = np.concatenate((logprob_values_train[:frac1],logprob_values_gm_train[logprob_values_gm_train<-290][:frac2],logprob_values_gm_train[logprob_values_gm_train>-290]))[rnd_indices]\n",
    "    len(logprob_values_mixed_train)\n",
    "    counts, _ = np.histogram(logprob_values_mixed_train[:show_points], bins)\n",
    "    integral = 1#counts.sum()\n",
    "    plt.step(bins[:-1], counts/integral, where='post')\n",
    "plt.xlabel(r\"$\\log\\mathcal{L}$\")\n",
    "plt.ylabel(r\"$p(\\log\\mathcal{L})$\")\n",
    "plt.tight_layout()\n",
    "plt.legend(['5','6','7','8'])\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "for frac1 in [5000000,6000000,7000000,8000000]:\n",
    "    frac2 = round((len(logprob_values_train)-frac1-np.count_nonzero(logprob_values_gm_train>-290)))\n",
    "    rnd_indices = np.arange(len(logprob_values_train))\n",
    "    np.random.shuffle(rnd_indices)\n",
    "    logprob_values_mixed_train = np.concatenate((logprob_values_train[:frac1],logprob_values_gm_train[logprob_values_gm_train<-290][:frac2],logprob_values_gm_train[logprob_values_gm_train>-290]))[rnd_indices]\n",
    "    len(logprob_values_mixed_train)\n",
    "    counts, _ = np.histogram(logprob_values_mixed_train[:show_points], bins)\n",
    "    integral = 1#counts.sum()\n",
    "    plt.step(bins[:-1], counts/integral, where='post')\n",
    "plt.xlabel(r\"$\\log\\mathcal{L}$\")\n",
    "plt.ylabel(r\"$p(\\log\\mathcal{L})$\")\n",
    "plt.tight_layout()\n",
    "plt.legend(['5','6','7','8'])\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(logprob_values_gm_train>-290)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac1 = 7000000\n",
    "frac2 = round((len(logprob_values_train)-frac1-np.count_nonzero(logprob_values_gm_train>-290)))\n",
    "rnd_indices = np.arange(len(logprob_values_train))\n",
    "np.random.shuffle(rnd_indices)\n",
    "allsamples_mixed_train = np.concatenate((allsamples_train[:frac1],allsamples_gm_train[logprob_values_gm_train<-290][:frac2],allsamples_gm_train[logprob_values_gm_train>-290]))[rnd_indices]\n",
    "logprob_values_mixed_train = np.concatenate((logprob_values_train[:frac1],logprob_values_gm_train[logprob_values_gm_train<-290][:frac2],logprob_values_gm_train[logprob_values_gm_train>-290]))[rnd_indices]\n",
    "loglik_values_mixed_train = np.concatenate((loglik_values_train[:frac1],loglik_values_gm_train[logprob_values_gm_train<-290][:frac2],loglik_values_gm_train[logprob_values_gm_train>-290]))[rnd_indices]\n",
    "logprior_values_mixed_train = np.concatenate((logprior_values_train[:frac1],logprior_values_gm_train[logprob_values_gm_train<-290][:frac2],logprior_values_gm_train[logprob_values_gm_train>-290]))[rnd_indices]\n",
    "len(allsamples_mixed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac1 = 700000\n",
    "frac2 = round((len(logprob_values_test)-frac1-np.count_nonzero(logprob_values_gm_test>-290)))\n",
    "rnd_indices = np.arange(len(logprob_values_test))\n",
    "np.random.shuffle(rnd_indices)\n",
    "allsamples_mixed_test = np.concatenate((allsamples_test[:frac1],allsamples_gm_test[logprob_values_gm_test<-290][:frac2],allsamples_gm_test[logprob_values_gm_test>-290]))[rnd_indices]\n",
    "logprob_values_mixed_test = np.concatenate((logprob_values_test[:frac1],logprob_values_gm_test[logprob_values_gm_test<-290][:frac2],logprob_values_gm_test[logprob_values_gm_test>-290]))[rnd_indices]\n",
    "loglik_values_mixed_test = np.concatenate((loglik_values_test[:frac1],loglik_values_gm_test[logprob_values_gm_test<-290][:frac2],loglik_values_gm_test[logprob_values_gm_test>-290]))[rnd_indices]\n",
    "logprior_values_mixed_test = np.concatenate((logprior_values_test[:frac1],logprior_values_gm_test[logprob_values_gm_test<-290][:frac2],logprior_values_gm_test[logprob_values_gm_test>-290]))[rnd_indices]\n",
    "len(allsamples_mixed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "samples_file = \"Data_samples/likelihood_mixed_sm_13_thinned1000_11M.pickle\"\n",
    "pickle_out = open(samples_file, 'wb')\n",
    "start = timer()\n",
    "pickle.dump(allsamples_mixed_train, pickle_out, protocol=4)\n",
    "pickle.dump(logprob_values_mixed_train, pickle_out, protocol=4)\n",
    "pickle.dump(loglik_values_mixed_train, pickle_out, protocol=4)\n",
    "pickle.dump(logprior_values_mixed_train, pickle_out, protocol=4)\n",
    "pickle.dump(allsamples_mixed_test, pickle_out, protocol=4)\n",
    "pickle.dump(logprob_values_mixed_test, pickle_out, protocol=4)\n",
    "pickle.dump(loglik_values_mixed_test, pickle_out, protocol=4)\n",
    "pickle.dump(logprior_values_mixed_test, pickle_out, protocol=4)\n",
    "end = timer()\n",
    "pickle_out.close()\n",
    "statinfo = os.stat(samples_file)\n",
    "print('File saved in',end-start,'seconds.\\nFile size is',statinfo.st_size,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dof = 1\n",
    "[ \n",
    "  ['CL',r'$\\Delta\\chi^{2}=2\\Delta\\log\\mathcal{L}$'],\n",
    "  [r'$0.995\\sigma (68\\%$)',get_delta_chi2_from_CI(0.68,dof)],\n",
    "  [r'$1\\sigma$',get_delta_chi2_from_CI(get_CI_from_sigma(1),dof)],\n",
    "  [r'$1.96\\sigma$ ($95%$)',get_delta_chi2_from_CI(0.95,dof)],\n",
    "  [r'$2\\sigma$',get_delta_chi2_from_CI(get_CI_from_sigma(2),dof)],\n",
    "  [r'$1.96\\sigma$ ($99%$)',get_delta_chi2_from_CI(0.95,dof)],\n",
    "  [r'$3\\sigma$',get_delta_chi2_from_CI(get_CI_from_sigma(3),dof)],\n",
    "  [r'$4\\sigma$',get_delta_chi2_from_CI(get_CI_from_sigma(4),dof)],\n",
    "  [r'$5\\sigma$',get_delta_chi2_from_CI(get_CI_from_sigma(5),dof)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_points = 10000000\n",
    "\n",
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "plt.grid(linestyle=\"--\", dashes=(5,5))\n",
    "\n",
    "counts, bins = np.histogram(np.concatenate((logprob_values_train[:show_points],logprob_values_gm_train[:show_points])), 100)\n",
    "\n",
    "counts, _ = np.histogram(logprob_values_train[:show_points], bins)\n",
    "integral = 1#counts.sum()\n",
    "plt.step(bins[:-1], counts/integral, where='post',color = 'green')\n",
    "counts, _ = np.histogram(logprob_values_gm_train[:show_points], bins)\n",
    "integral = 1#counts.sum()\n",
    "plt.step(bins[:-1], counts/integral, where='post',color = 'red')\n",
    "counts, _ = np.histogram(logprob_values_mixed_train[:show_points], bins)\n",
    "integral = 1#counts.sum()\n",
    "plt.step(bins[:-1], counts/integral, where='post',color = 'blue')\n",
    "plt.xlabel(r\"$\\log\\mathcal{L}$\")\n",
    "plt.ylabel(r\"number of samples/bin\")\n",
    "x1,x2,y1,y2 = plt.axis()\n",
    "plt.axis([-390, -280, y1, y2])\n",
    "plt.tight_layout()\n",
    "plt.legend([r'$S_{1}$',r'$S_{2}$',r'$S_{3}$'])\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "counts, _ = np.histogram(logprob_values_train[:show_points], bins)\n",
    "integral = 1#counts.sum()\n",
    "plt.step(bins[:-1], counts/integral, where='post',color = 'green')\n",
    "counts, _ = np.histogram(logprob_values_gm_train[:show_points], bins)\n",
    "integral = 1#counts.sum()\n",
    "plt.step(bins[:-1], counts/integral, where='post',color = 'red')\n",
    "counts, _ = np.histogram(logprob_values_mixed_train[:show_points], bins)\n",
    "integral = 1#counts.sum()\n",
    "plt.step(bins[:-1], counts/integral, where='post',color = 'blue')\n",
    "plt.xlabel(r\"$\\log\\mathcal{L}$\")\n",
    "plt.ylabel(r\"number of samples/bin\")\n",
    "plt.legend([r'$S_{1}$',r'$S_{2}$',r'$S_{3}$'])#, bbox_to_anchor=(0.4, 0.35))#, bbox_to_anchor=(0.3, 1), fontsize=15)#, bbox_transform=plt.gcf().transFigure)#, loc='upper right')\n",
    "plt.yscale('log')\n",
    "x1,x2,y1,y2 = plt.axis()\n",
    "plt.axis([-390, -280, y1, y2])\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + 'distr_toy_lik_sm_vs_gm_vs_mixed.pdf')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequentist Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_file = \"Data_samples/likelihood_mixed_sm_13_thinned1000_11M.pickle\"\n",
    "pickle_in = open(samples_file,'rb')\n",
    "start = timer()\n",
    "statinfo = os.stat(samples_file)\n",
    "allsamples_mixed_train = pickle.load(pickle_in)\n",
    "logprob_values_mixed_train = pickle.load(pickle_in)\n",
    "end = timer()\n",
    "pickle_in.close()\n",
    "print('File loaded in ',end-start,' seconds.\\nFile size is ',statinfo.st_size,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "blst = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "if 'tmuexact' in globals():\n",
    "    pass\n",
    "else:\n",
    "    tmuexact = np.array(list(map(tmu, blst)))\n",
    "cl68 = np.array([[-1,2],[1,1]])\n",
    "cl95 = np.array([[-1,2],[4,4]])\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blst = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "NEVENTS = 100000\n",
    "indices = np.arange(len(allsamples_mixed_train))\n",
    "rnd_indices = np.random.choice(indices, size=NEVENTS,replace=False)\n",
    "if 'tmuexact' in globals():\n",
    "    pass\n",
    "else:\n",
    "    tmuexact = np.array(list(map(tmu, blst)))\n",
    "tmusample001 = np.array(list(map(lambda x: tmu_sample(x,allsamples_mixed_train[rnd_indices],logprob_values_mixed_train[rnd_indices],0.01),blst)))\n",
    "tmusample002 = np.array(list(map(lambda x: tmu_sample(x,allsamples_mixed_train[rnd_indices],logprob_values_mixed_train[rnd_indices],0.02),blst)))\n",
    "tmusample005 = np.array(list(map(lambda x: tmu_sample(x,allsamples_mixed_train[rnd_indices],logprob_values_mixed_train[rnd_indices],0.05),blst)))\n",
    "tmusample01 = np.array(list(map(lambda x: tmu_sample(x,allsamples_mixed_train[rnd_indices],logprob_values_mixed_train[rnd_indices],0.1),blst)))\n",
    "del(blst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blst = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "[[mu,len(allsamples_mixed_train[rnd_indices][[i > mu-0.001/2 and i < mu+0.001/2 for i in allsamples_gm_train[rnd_indices][:, 0]]])] for mu in blst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "plt.grid(linestyle=\"--\", dashes=(5,5),alpha=0)\n",
    "plt.plot(tmuexact[:,0],tmuexact[:,-1])\n",
    "plt.plot(tmusample001[:,1],tmusample001[:,-1], linestyle=\"--\", dashes=(3,3))\n",
    "plt.plot(tmusample002[:,1],tmusample002[:,-1], linestyle=\"--\", dashes=(3,3))\n",
    "plt.plot(tmusample005[:,1],tmusample005[:,-1], linestyle=\"--\", dashes=(3,3))\n",
    "plt.plot(tmusample01[:,1],tmusample01[:,-1], linestyle=\"--\", dashes=(3,3))\n",
    "x1,x2,y1,y2 = plt.axis()\n",
    "plt.plot(cl68[0],cl68[1],linestyle=\"--\", dashes=(1,1),color='black',alpha=0.9)\n",
    "plt.plot(cl95[0],cl95[1],linestyle=\"--\", dashes=(1,1),color='black',alpha=0.9)\n",
    "plt.axis([x1, x2, y1, y2])\n",
    "plt.xlabel(r'$\\mu$')\n",
    "plt.ylabel(r'$t_{\\mu}(\\mu)$')\n",
    "plt.legend(['Numerical maximization','Sample 2 (bin size 0.01)','Sample 2 (bin size 0.02)','Sample 2 (bin size 0.05)','Sample 2 (bin size 0.1)'],fontsize=15)\n",
    "plt.text(0.76,-0.1,r'$10^{5}$ samples from Sample 2',fontsize=18, ha='center',ma='center')\n",
    "plt.text(0.9,1.1,r'$68\\%$',fontsize=18, ha='center',ma='center')\n",
    "plt.text(0.9,4.1,r'$95\\%$',fontsize=18, ha='center',ma='center')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + 'tmu_samp3_105.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blst = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "NEVENTS = 1000000\n",
    "indices = np.arange(len(allsamples_mixed_train))\n",
    "rnd_indices = np.random.choice(indices, size=NEVENTS,replace=False)\n",
    "if 'tmuexact' in globals():\n",
    "    pass\n",
    "else:\n",
    "    tmuexact = np.array(list(map(tmu, blst)))\n",
    "tmusample001 = np.array(list(map(lambda x: tmu_sample(x,allsamples_mixed_train[rnd_indices],logprob_values_mixed_train[rnd_indices],0.01),blst)))\n",
    "tmusample002 = np.array(list(map(lambda x: tmu_sample(x,allsamples_mixed_train[rnd_indices],logprob_values_mixed_train[rnd_indices],0.02),blst)))\n",
    "tmusample005 = np.array(list(map(lambda x: tmu_sample(x,allsamples_mixed_train[rnd_indices],logprob_values_mixed_train[rnd_indices],0.05),blst)))\n",
    "tmusample01 = np.array(list(map(lambda x: tmu_sample(x,allsamples_mixed_train[rnd_indices],logprob_values_mixed_train[rnd_indices],0.1),blst)))\n",
    "del(blst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "plt.grid(linestyle=\"--\", dashes=(5,5),alpha=0)\n",
    "plt.plot(tmuexact[:,0],tmuexact[:,-1])\n",
    "plt.plot(tmusample001[:,1],tmusample001[:,-1], linestyle=\"--\", dashes=(3,3))\n",
    "plt.plot(tmusample002[:,1],tmusample002[:,-1], linestyle=\"--\", dashes=(3,3))\n",
    "plt.plot(tmusample005[:,1],tmusample005[:,-1], linestyle=\"--\", dashes=(3,3))\n",
    "plt.plot(tmusample01[:,1],tmusample01[:,-1], linestyle=\"--\", dashes=(3,3))\n",
    "x1,x2,y1,y2 = plt.axis()\n",
    "plt.plot(cl68[0],cl68[1],linestyle=\"--\", dashes=(1,1),color='black',alpha=0.9)\n",
    "plt.plot(cl95[0],cl95[1],linestyle=\"--\", dashes=(1,1),color='black',alpha=0.9)\n",
    "plt.axis([x1, x2, y1, y2])\n",
    "plt.xlabel(r'$\\mu$')\n",
    "plt.ylabel(r'$t_{\\mu}(\\mu)$')\n",
    "plt.legend(['Numerical maximization','Sample 2 (bin size 0.01)','Sample 2 (bin size 0.02)','Sample 2 (bin size 0.05)','Sample 2 (bin size 0.1)'],fontsize=15)\n",
    "plt.text(0.76,-0.1,r'$10^{6}$ samples from Sample 2',fontsize=18, ha='center',ma='center')\n",
    "plt.text(0.9,1.1,r'$68\\%$',fontsize=18, ha='center',ma='center')\n",
    "plt.text(0.9,4.1,r'$95\\%$',fontsize=18, ha='center',ma='center')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + 'tmu_samp3_106.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blst = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "NEVENTS = 10000000#len(allsamples_mixed)\n",
    "indices = np.arange(len(allsamples_mixed_train))\n",
    "rnd_indices = np.random.choice(indices, size=NEVENTS,replace=False)\n",
    "if 'tmuexact' in globals():\n",
    "    pass\n",
    "else:\n",
    "    tmuexact = np.array(list(map(tmu, blst)))\n",
    "tmusample001 = np.array(list(map(lambda x: tmu_sample(x,allsamples_mixed_train[rnd_indices],logprob_values_mixed_train[rnd_indices],0.01),blst)))\n",
    "tmusample002 = np.array(list(map(lambda x: tmu_sample(x,allsamples_mixed_train[rnd_indices],logprob_values_mixed_train[rnd_indices],0.02),blst)))\n",
    "tmusample005 = np.array(list(map(lambda x: tmu_sample(x,allsamples_mixed_train[rnd_indices],logprob_values_mixed_train[rnd_indices],0.05),blst)))\n",
    "tmusample01 = np.array(list(map(lambda x: tmu_sample(x,allsamples_mixed_train[rnd_indices],logprob_values_mixed_train[rnd_indices],0.1),blst)))\n",
    "del(blst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "plt.grid(linestyle=\"--\", dashes=(5,5),alpha=0)\n",
    "plt.plot(tmuexact[:,0],tmuexact[:,-1])\n",
    "plt.plot(tmusample001[:,1],tmusample001[:,-1], linestyle=\"--\", dashes=(3,3))\n",
    "plt.plot(tmusample002[:,1],tmusample002[:,-1], linestyle=\"--\", dashes=(3,3))\n",
    "plt.plot(tmusample005[:,1],tmusample005[:,-1], linestyle=\"--\", dashes=(3,3))\n",
    "plt.plot(tmusample01[:,1],tmusample01[:,-1], linestyle=\"--\", dashes=(3,3))\n",
    "x1,x2,y1,y2 = plt.axis()\n",
    "plt.plot(cl68[0],cl68[1],linestyle=\"--\", dashes=(1,1),color='black',alpha=0.9)\n",
    "plt.plot(cl95[0],cl95[1],linestyle=\"--\", dashes=(1,1),color='black',alpha=0.9)\n",
    "plt.axis([x1, x2, y1, y2])\n",
    "plt.xlabel(r'$\\mu$')\n",
    "plt.ylabel(r'$t_{\\mu}(\\mu)$')\n",
    "plt.legend(['Numerical maximization','Sample 2 (bin size 0.01)','Sample 2 (bin size 0.02)','Sample 2 (bin size 0.05)','Sample 2 (bin size 0.1)'],fontsize=15)\n",
    "plt.text(0.76,-0.1,r'$10^{7}$ samples from Sample 2',fontsize=18, ha='center',ma='center')\n",
    "plt.text(0.9,1.1,r'$68\\%$',fontsize=18, ha='center',ma='center')\n",
    "plt.text(0.9,4.1,r'$95\\%$',fontsize=18, ha='center',ma='center')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + 'tmu_samp3_107.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(allsamples_gm_train[:100000][[i > 0 and i < 1 for i in allsamples_gm_train[:100000][:, 0]]]))\n",
    "print(len(allsamples_gm_train[:1000000][[i > 0 and i < 1 for i in allsamples_gm_train[:1000000][:, 0]]]))\n",
    "print(len(allsamples_gm_train[[i > 0 and i < 1 for i in allsamples_gm_train[:, 0]]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Full DNNLikelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load samples and logprob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform training scan and saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_RUNS = 5\n",
    "ACT_FUNC_OUT_LAYER_LIST = ['linear']\n",
    "BATCH_NORM_LIST = [False]\n",
    "CONTINUE_TRAINING = False\n",
    "DROPOUT_RATE_LIST = [0]\n",
    "EARLY_STOPPING = True\n",
    "FILE_SAMPLES_LIST = [\"Data_samples/likelihood_mixed_sm_13_thinned1000_11M.pickle\"]\n",
    "FOLDER = 'DNNLikelihoods/'\n",
    "FREQUENTISTS_RESULTS = True\n",
    "GENERATE_DATA = True\n",
    "# This also automatically sets GENERATE_DATA = True\n",
    "GENERATE_DATA_ON_THE_FLY = False\n",
    "HID_LAYERS_LIST = [\n",
    "                  [[500, 'selu'], [500, 'selu']],\n",
    "                  [[1000, 'selu'], [1000, 'selu']],\n",
    "                  [[2000, 'selu'], [2000, 'selu']],\n",
    "                  [[5000, 'selu'], [5000, 'selu']]\n",
    "                  ]\n",
    "LABELS = [r\"$\\mu$\"]+[r\"$\\delta_{%d}$\" % i for i in range(1, 95)]\n",
    "LEARNING_RATE_LIST = [10**(-3)]\n",
    "LOAD_MODEL = 'None'\n",
    "LOGPROB_THRESHOLD = -1*np.inf\n",
    "LOSS_LIST = ['mse']\n",
    "METRICS = ['mse', 'mae', 'mape', 'me', 'mpe']\n",
    "MODEL_CHEKPOINT = False\n",
    "MONITORED_METRIC = 'mse'\n",
    "MULTI_GPU = False\n",
    "N_EPOCHS = 15\n",
    "NEVENTS_TRAIN_LIST = [100000,200000,500000]\n",
    "BATCH_SIZE_LIST = [int(closest_power2(x/200)) for x in NEVENTS_TRAIN_LIST]\n",
    "MIN_DELTA_LIST = [1/x for x in NEVENTS_TRAIN_LIST]\n",
    "PARS = [0, 3, 6, 30, 61, 85]\n",
    "PLOTLOSSES = False\n",
    "REDUCE_LR = True\n",
    "REDUCE_LR_PATIENCE_LIST = [40]\n",
    "SCALE_X = False\n",
    "SCALE_Y = True\n",
    "TEST_FRACTION = 0.5\n",
    "VALIDATION_FRACTION = 0.5\n",
    "WEIGHT_SAMPLES_LIST = [False]\n",
    "\n",
    "#From previous run\n",
    "try:\n",
    "    [allsamples_train, logprob_values_train, allsamples_test, logprob_values_test] = [allsamples_train, logprob_values_train, allsamples_test, logprob_values_test]\n",
    "except:\n",
    "    [allsamples_train, logprob_values_train, allsamples_test,logprob_values_test] = ['None', 'None', 'None', 'None']\n",
    "try:\n",
    "    [rnd_indices_train, rnd_indices_val, rnd_indices_test] = [rnd_indices_train, rnd_indices_val, rnd_indices_test]\n",
    "except:\n",
    "    [rnd_indices_train, rnd_indices_val, rnd_indices_test] = ['None', 'None', 'None']\n",
    "try:\n",
    "    LOGPROB_THRESHOLD_INDICES_TRAIN, LOGPROB_THRESHOLD_INDICES_TEST = [LOGPROB_THRESHOLD_INDICES_TRAIN, LOGPROB_THRESHOLD_INDICES_TEST]\n",
    "except:\n",
    "    LOGPROB_THRESHOLD_INDICES_TRAIN, LOGPROB_THRESHOLD_INDICES_TEST = ['None', 'None']\n",
    "try:\n",
    "    [X_train, X_val, X_test, Y_train, Y_val, Y_test, W_train, W_val] = [X_train, X_val, X_test, Y_train, Y_val, Y_test, W_train, W_val]\n",
    "except:\n",
    "    [X_train, X_val, X_test, Y_train, Y_val, Y_test, W_train, W_val] = ['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None']\n",
    "try:\n",
    "    [scalerX, scalerY] = [scalerX, scalerY]\n",
    "except:\n",
    "    [scalerX, scalerY] = ['None', 'None']\n",
    "try:\n",
    "    model = model\n",
    "    training_model = training_model\n",
    "except:\n",
    "    model = 'None'\n",
    "    training_model = 'None'\n",
    "try:\n",
    "    summary_log = summary_log\n",
    "    history = history\n",
    "    training_time = training_time\n",
    "except:\n",
    "    summary_log = 'None'\n",
    "    history = 'None'\n",
    "    training_time = 'None'\n",
    "    \n",
    "\n",
    "[allsamples_train, logprob_values_train, allsamples_test, logprob_values_test, LOGPROB_THRESHOLD_INDICES_TRAIN, LOGPROB_THRESHOLD_INDICES_TEST, rnd_indices_train, rnd_indices_val, rnd_indices_test, X_train, X_val, X_test, Y_train, Y_val, Y_test, W_train,\n",
    " W_val, scalerX, scalerY, model, training_model, summary_log, history, training_time] = model_training_scan(N_RUNS, ACT_FUNC_OUT_LAYER_LIST,\n",
    "                                                                                                            BATCH_NORM_LIST, BATCH_SIZE_LIST, CONTINUE_TRAINING, DROPOUT_RATE_LIST, EARLY_STOPPING, FILE_SAMPLES_LIST, FOLDER, FREQUENTISTS_RESULTS, GENERATE_DATA,\n",
    "                                                                                                            GENERATE_DATA_ON_THE_FLY, GPU_names, HID_LAYERS_LIST, LABELS, LEARNING_RATE_LIST, LOAD_MODEL, LOGPROB_THRESHOLD, LOGPROB_THRESHOLD_INDICES_TRAIN, LOGPROB_THRESHOLD_INDICES_TEST, LOSS_LIST, METRICS, MIN_DELTA_LIST, MODEL_CHEKPOINT, MONITORED_METRIC, MULTI_GPU, N_EPOCHS, NEVENTS_TRAIN_LIST,\n",
    "                                                                                                            PARS, PLOTLOSSES, REDUCE_LR, REDUCE_LR_PATIENCE_LIST, SCALE_X, SCALE_Y, TEST_FRACTION, VALIDATION_FRACTION, WEIGHT_SAMPLES_LIST, allsamples_train, logprob_values_train, allsamples_test, logprob_values_test,\n",
    "                                                                                                            rnd_indices_train, rnd_indices_val, rnd_indices_test, X_train, X_val, X_test, Y_train, Y_val, Y_test, W_train, W_val, scalerX, scalerY, model, training_model, summary_log, history, training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "plt.grid(linestyle=\"--\", dashes=(5,5))\n",
    "\n",
    "counts, bins = np.histogram(Y_train_log[:1000000], 100)\n",
    "integral = 1#counts.sum()\n",
    "plt.step(bins[:-1], counts/integral, where='post',color='green')\n",
    "counts, bins = np.histogram(Y_train_log[:1000000], 100,weights=W_train)\n",
    "integral = 1#counts.sum()\n",
    "plt.step(bins[:-1], counts/integral, where='post',color='blue')\n",
    "plt.xlabel(r\"$\\log\\mathcal{L}$\")\n",
    "plt.ylabel(r\"$p(\\log\\mathcal{L})$\")\n",
    "plt.tight_layout()\n",
    "plt.legend(['True','Mixed'])\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "plt.grid(linestyle=\"--\", dashes=(5,5))\n",
    "\n",
    "counts, bins = np.histogram(Y_train_log_standardized[:1000000], 100)\n",
    "integral = 1#counts.sum()\n",
    "plt.step(bins[:-1], counts/integral, where='post',color='green')\n",
    "counts, bins = np.histogram(Y_train_log_standardized[:1000000], 100,weights=W_train)\n",
    "integral = 1#counts.sum()\n",
    "plt.step(bins[:-1], counts/integral, where='post',color='blue')\n",
    "plt.xlabel(r\"$\\log\\mathcal{L}$\")\n",
    "plt.ylabel(r\"$p(\\log\\mathcal{L})$\")\n",
    "plt.tight_layout()\n",
    "plt.legend(['True','Mixed'])\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "plt.grid(linestyle=\"--\", dashes=(5,5))\n",
    "\n",
    "counts, bins = np.histogram(Y_train_log_standardized[:1000000], 100)\n",
    "integral = 1#counts.sum()\n",
    "plt.step(bins[:-1], counts/integral, where='post',color='green')\n",
    "counts, bins = np.histogram(Y_train_log_standardized[:1000000], 100,weights=W_train)\n",
    "integral = 1#counts.sum()\n",
    "plt.step(bins[:-1], counts/integral, where='post',color='blue')\n",
    "plt.xlabel(r\"$\\log\\mathcal{L}$\")\n",
    "plt.ylabel(r\"$p(\\log\\mathcal{L})$\")\n",
    "plt.tight_layout()\n",
    "plt.legend(['True','Mixed'])\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = timer()\n",
    "overall_progress = widgets.FloatProgress(value=0.0, min=0.0, max=1.0, layout={'width': '500px', 'height': '14px', 'padding': '0px', 'margin': '-5px 0px -20px 0px'})\n",
    "display(overall_progress)\n",
    "iterator = 0\n",
    "#NN parameters\n",
    "RUNS = 5\n",
    "\n",
    "for run in range(RUNS): \n",
    "    NEVENTS_LIST = [200000]#,200000]#,500000]#,1000000]\n",
    "    MULTI_GPU = True\n",
    "    HID_LAYERS_LIST = [\n",
    "                      #[[200,'selu'],[200,'selu']],              \n",
    "                      #[[200,'selu'],[200,'selu'],[200,'selu']],\n",
    "                      #[[200,'selu'],[200,'selu'],[200,'selu'],[200,'selu']],\n",
    "                      [[500,'selu'],[500,'selu']]#,              \n",
    "                      #[[500,'selu'],[500,'selu'],[500,'selu']],\n",
    "                      #[[500,'selu'],[500,'selu'],[500,'selu'],[500,'selu']],\n",
    "                      #[[1000,'selu'],[1000,'selu']],             \n",
    "                      ##[[1000,'selu'],[1000,'selu'],[1000,'selu']],\n",
    "                      #[[1000,'selu'],[1000,'selu'],[1000,'selu'],[1000,'selu']],\n",
    "                      #[[2000,'selu'],[2000,'selu']]   \n",
    "                     ]\n",
    "    ACT_FUNC_OUT_LAYER_LIST = ['linear']\n",
    "    DROPOUT_RATE_LIST = [0]#, 0.1, 0.4]\n",
    "    BATCH_NORM_LIST = [False]#, True]\n",
    "    #Model compilation parameters\n",
    "    if MULTI_GPU:\n",
    "        NUM_GPUS = len(K.tensorflow_backend._get_available_gpus())\n",
    "    else:\n",
    "        if len(K.tensorflow_backend._get_available_gpus()) == 0:\n",
    "            NUM_GPUS = 0\n",
    "        else:\n",
    "            NUM_GPUS = 1\n",
    "    BATCH_SIZE_LIST = [int(512)]#,int(512),int(2048)]\n",
    "    if NUM_GPUS != 0:\n",
    "        BATCH_SIZE_LIST = [i*2 for i in BATCH_SIZE_LIST]\n",
    "    LOSS = 'mae'\n",
    "    METRICS = ['mape','mse','msle','mae','kullback_leibler_divergence', R2_metric, Rt_metric]\n",
    "    LEARNING_RATE_LIST = [10**(-3)]#,0.0001]\n",
    "    NEW_TRAIN = True\n",
    "    SCALE_Y = True\n",
    "    if SCALE_Y:\n",
    "        folder = 'results_DNNLik_ensemble_samemodel_diffdata/'\n",
    "    else:\n",
    "        folder = 'results_DNNLik_ensemble_samemodel_diffdata/'\n",
    "    print('Preparing data')\n",
    "    LOAD_MODEL = 'None'\n",
    "    WEIGHT_SAMPLES_LIST = [False]\n",
    "    LOGPROB_THRESHOLD = -400\n",
    "    for NEVENTS in NEVENTS_LIST:\n",
    "        indices = np.arange(len(allsamples_mixed[logprob_values_mixed>LOGPROB_THRESHOLD]))\n",
    "        rnd_indices = np.random.choice(indices, size=3*NEVENTS)\n",
    "        #sample = [allsamples_mixed[rnd_indices], logprob_values_mixed[rnd_indices], nbI_values_mixed[rnd_indices],sample_weights]\n",
    "        sample = [allsamples_mixed[logprob_values_mixed>LOGPROB_THRESHOLD][rnd_indices], logprob_values_mixed[logprob_values_mixed>LOGPROB_THRESHOLD][rnd_indices], nbI_values_mixed[logprob_values_mixed>LOGPROB_THRESHOLD][rnd_indices]]\n",
    "        for WEIGHT_SAMPLES in WEIGHT_SAMPLES_LIST:\n",
    "            if WEIGHT_SAMPLES:\n",
    "                sample_weights = compute_sample_weights(sample[1],500,power=1/1.3)\n",
    "            else:\n",
    "                sample_weights = np.full(len(rnd_indices),1)\n",
    "            sample = [sample[0], sample[1], sample[2], sample_weights]\n",
    "            NDIM = list(np.shape(sample[0]))[1]\n",
    "            if NEW_TRAIN:\n",
    "                [X_train, X_test_val, Y_train_log, Y_test_val_log, nbI_values_train, nbI_values_test_val, W_train, W_test_val] = train_test_split(sample[0], sample[1], sample[2], sample[3], test_size=2/3, random_state=seed)\n",
    "                [X_val, X_test, Y_val_log, Y_test_log, nbI_values_val, nbI_values_test, W_val, W_test] = train_test_split(X_test_val, Y_test_val_log, nbI_values_test_val, W_test_val, test_size=0.5, random_state=seed)\n",
    "                if SCALE_Y:\n",
    "                    scaler = StandardScaler()\n",
    "                    scaler.fit(Y_train_log.reshape(-1, 1))\n",
    "                    Y_train_log_standardized = scaler.transform(Y_train_log.reshape(-1, 1)).reshape(len(Y_train_log))\n",
    "                    Y_val_log_standardized = scaler.transform(Y_val_log.reshape(-1, 1)).reshape(len(Y_test_log))\n",
    "                    Y_test_log_standardized = scaler.transform(Y_test_log.reshape(-1, 1)).reshape(len(Y_test_log))\n",
    "                    print('Min and max log-lik in train/val/test:')\n",
    "                    print([np.amin(Y_train_log),np.amax(Y_train_log)])\n",
    "                    print([np.amin(Y_val_log),np.amax(Y_val_log)])\n",
    "                    print([np.amin(Y_test_log),np.amax(Y_test_log)])\n",
    "                else:\n",
    "                    scaler = 'None'\n",
    "            #LOAD_MODEL = 'results_DNNLik_2/model_checkpoint.h5'\n",
    "            #'results_DNNLik_3/2019-07-06--11-30-34 - Data_Normal - Ndim_97 - Nevt_2E06 - Loss_mape_model.h5'\n",
    "            #K.set_epsilon(min(Y_train)/2)\n",
    "            #K.set_epsilon(10**(-15))\n",
    "            #model.load_weight('results_DNNLik_2/2019-07-05--07-56-34 - Data_Normal - Ndim_97 - Nevt_1E06 - Loss_mape_weights.h5')\n",
    "            for HID_LAYERS in HID_LAYERS_LIST:\n",
    "                for ACT_FUNC_OUT_LAYER in ACT_FUNC_OUT_LAYER_LIST:\n",
    "                    for DROPOUT_RATE in DROPOUT_RATE_LIST:\n",
    "                        for BATCH_SIZE in BATCH_SIZE_LIST:\n",
    "                            for BATCH_NORM in BATCH_NORM_LIST:\n",
    "                                for LEARNING_RATE in LEARNING_RATE_LIST:\n",
    "                                    N_EPOCHS = 1000\n",
    "                                    OPTIMIZER = optimizers.Adam(lr=LEARNING_RATE, beta_1=0.95, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "                                    #OPTIMIZER = AdaBound(lr=LEARNING_RATE, final_lr=0.1, sgamma=1e-03, weight_decay=0., amsbound=False)\n",
    "                                    #OPTIMIZER = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "                                    if NEW_TRAIN:\n",
    "                                        #Model definition\n",
    "                                        model = model_define(NDIM,HID_LAYERS,DROPOUT_RATE,ACT_FUNC_OUT_LAYER,BATCH_NORM,verbose=1)\n",
    "                                        #Model compilation\n",
    "                                        history = {}\n",
    "                                        training_time = 0\n",
    "                                    #Model title\n",
    "                                    now = datetime.now().strftime('%Y-%m-%d--%H-%M-%S')\n",
    "                                    title = str(now) + \" - \"\n",
    "                                    title = title + \"Data: Normal - \"\n",
    "                                    title = title + \"Ndim: \" + str(NDIM) + \" - \"\n",
    "                                    title = title + \"Nevt: \" + '%.E' % Decimal(str(NEVENTS)) + \" - \"\n",
    "                                    title = title + \"Weighted: \" + str(WEIGHT_SAMPLES) + \" - \"\n",
    "                                    title = title.replace(\"+\",\"\") + \"Loss: \" + str(LOSS)\n",
    "                                    #Summary\n",
    "                                    summary_text = \"Layers: \" + str(HID_LAYERS) + \"\\n\"\n",
    "                                    summary_text = summary_text + \"Pars: \" + str(model_params(model)) + \"\\n\"\n",
    "                                    summary_text = summary_text + \"Trainable pars: \" + str(model_trainable_params(model)) + \"\\n\"\n",
    "                                    summary_text = summary_text + \"Non-trainable pars: \" + str(model_non_trainable_params(model)) + \"\\n\"\n",
    "                                    summary_text = summary_text + \"Dropout: \" + str(DROPOUT_RATE) + \"\\n\"\n",
    "                                    summary_text = summary_text + \"AF out: \" + str(ACT_FUNC_OUT_LAYER) + \"\\n\"\n",
    "                                    summary_text = summary_text + \"Batch norm: \" + str(BATCH_NORM) + \"\\n\"\n",
    "                                    summary_text = summary_text + \"Loss: \" + str(LOSS) + \"\\n\"\n",
    "                                    summary_text = summary_text + \"Optimizer: Adam (LR\" + str(LEARNING_RATE) + \")\\n\"\n",
    "                                    summary_text = summary_text + \"Batch size: \" + str(BATCH_SIZE) + \"\\n\"\n",
    "                                    #Model training\n",
    "                                    model = model_compile(model,LOSS,OPTIMIZER,METRICS,MULTI_GPU)\n",
    "                                    if LOAD_MODEL != 'None':\n",
    "                                        if SCALE_Y:\n",
    "                                            model_fit(model,X_train,Y_train_log_standardized,X_val,Y_val_log_standardized,1,BATCH_SIZE,sample_weights=W_train,verbose=True)\n",
    "                                        else:\n",
    "                                            model_fit(model,X_train,Y_train_log,X_val,Y_val_log,1,BATCH_SIZE,sample_weights=W_train,verbose=True)\n",
    "                                        model = load_model(LOAD_MODEL, custom_objects={'R2_metric': R2_metric, 'Rt_metric':Rt_metric})\n",
    "                                        #scaler = load_model_scaler(LOAD_MODEL.replace('_model.h5','_scaler.jlib'))\n",
    "                                        LOAD_MODEL = False\n",
    "                                    if NEW_TRAIN:\n",
    "                                        print('Start training of new model')\n",
    "                                    else:\n",
    "                                        print('Continue training of loaded model')\n",
    "                                    if SCALE_Y:\n",
    "                                        [h_run, training_time_run] = model_fit(model,X_train,Y_train_log_standardized,X_val,Y_val_log_standardized,N_EPOCHS,BATCH_SIZE,sample_weights=W_train,early_stopping=True,verbose=2)\n",
    "                                    else:\n",
    "                                        [h_run, training_time_run] = model_fit(model,X_train,Y_train_log,X_val,Y_val_log,N_EPOCHS,BATCH_SIZE,sample_weights=W_train,early_stopping=True,verbose=2)\n",
    "                                    if NEW_TRAIN:\n",
    "                                        training_time = training_time_run\n",
    "                                        history = h_run.history\n",
    "                                    else:\n",
    "                                        training_time = training_time + training_time_run\n",
    "                                        history_full = {}\n",
    "                                        history_run = h_run.history\n",
    "                                        for key in history_run.keys():\n",
    "                                            history_full[key] = history[key] + history_run[key]\n",
    "                                        history = history_full\n",
    "                                        del(history_full,history_run)\n",
    "                                    print('Computing predictions')\n",
    "                                    nnn = int(NEVENTS/10)\n",
    "                                    idx_val = np.random.choice(np.arange(len(X_val)), nnn, replace=False)\n",
    "                                    idx_test = np.random.choice(np.arange(len(X_test)), nnn, replace=False)\n",
    "                                    pred_val, prediction_time_val = model_predict(model,X_val[idx_val],batch_size=BATCH_SIZE)\n",
    "                                    pred_test, prediction_time_test = model_predict(model,X_test[idx_test],batch_size=BATCH_SIZE)\n",
    "                                    prediction_time = (prediction_time_val+prediction_time_test)/2\n",
    "                                    if SCALE_Y:\n",
    "                                        Y_pred_val_log_standardized_inverse = scaler.inverse_transform(pred_val).reshape(nnn)\n",
    "                                        Y_pred_val_log_standardized_inverse_exp = np.exp(Y_pred_val_log_standardized_inverse)\n",
    "                                        Y_val_log_exp = np.exp(Y_val_log[idx_val])\n",
    "                                        mape_on_exp_val = 100/nnn*np.sum(np.abs(Y_pred_val_log_standardized_inverse_exp-Y_val_log_exp)/Y_val_log_exp)\n",
    "                                        Y_pred_test_log_standardized_inverse = scaler.inverse_transform(pred_test).reshape(nnn)\n",
    "                                        Y_pred_test_log_standardized_inverse_exp = np.exp(Y_pred_test_log_standardized_inverse)\n",
    "                                        Y_test_log_exp = np.exp(Y_test_log[idx_test])\n",
    "                                        mape_on_exp_test = 100/nnn*np.sum(np.abs(Y_pred_test_log_standardized_inverse_exp-Y_test_log_exp)/Y_test_log_exp)\n",
    "                                        print('Predicted MAPE on exp validation:',mape_on_exp_val)\n",
    "                                        print('Predicted MAPE on exp test:',mape_on_exp_test)\n",
    "                                        print('Estimating frequentist inference')\n",
    "                                        start_tmu = timer()\n",
    "                                        blst = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "                                        tmuexact = np.array(list(map(tmu, blst)))\n",
    "                                        tmuDNN = np.array(list(map(lambda x: tmu_DNN(x,model,scaler), blst)))\n",
    "                                        tmusample001 = np.array(list(map(lambda x: tmu_sample(x,X_train,Y_train_log,0.01),blst)))\n",
    "                                        tmusample005 = np.array(list(map(lambda x: tmu_sample(x,X_train,Y_train_log,0.05),blst)))\n",
    "                                        tmusample01 = np.array(list(map(lambda x: tmu_sample(x,X_train,Y_train_log,0.1),blst)))\n",
    "                                        tmusample02 = np.array(list(map(lambda x: tmu_sample(x,X_train,Y_train_log,0.2),blst)))\n",
    "                                        tmu_err_mean = np.mean(np.abs(tmuexact[:,-1]-tmuDNN[:,-1]))\n",
    "                                        freq_tmu = [tmuexact,tmuDNN,tmusample001,tmusample005,tmusample01,tmusample02]\n",
    "                                        end_tmu = timer()\n",
    "                                        print('t_mu computed in:',end_tmu-start_tmu,'s')\n",
    "                                        print('Mean error on tmu:',tmu_err_mean)\n",
    "                                    else:\n",
    "                                        Y_pred_val_log_exp = np.exp(pred_val)\n",
    "                                        Y_val_log_exp = np.exp(Y_val_log[idx_val])\n",
    "                                        mape_on_exp_test = 100/nnn*np.sum(np.abs(Y_pred_val_log_exp-Y_val_log_exp)/Y_val_log_exp)\n",
    "                                        Y_pred_test_log_exp = np.exp(pred_test)\n",
    "                                        Y_test_log_exp = np.exp(Y_test_log[idx_test])\n",
    "                                        mape_on_exp_test = 100/nnn*np.sum(np.abs(Y_pred_test_log_exp-Y_test_log_exp)/Y_test_log_exp)\n",
    "                                        print('Predicted MAPE on exp validation:',mape_on_exp_val)\n",
    "                                        print('Predicted MAPE on exp test:',mape_on_exp_test)\n",
    "                                    #pred_loss = metrics.mean_absolute_percentage_error(Y_train[0:nnn], prediction)\n",
    "                                    #pred_loss = 100/nnn*np.sum(np.abs(prediction-Y_train[0:nnn])/Y_train[0:nnn])\n",
    "                                    #pred_loss = metrics.mean_absolute_percentage_error(Y_train[0:nnn], prediction)\n",
    "                                    #pred_loss = 100/nnn*np.sum(np.abs(prediction-Y_train[0:nnn])/Y_train[0:nnn])\n",
    "                                    del(idx_test,idx_val,pred_test,pred_val)\n",
    "                                    #for EPOCH in range(N_EPOCHS):\n",
    "                                    #    progress.value = float(EPOCH+1)/N_EPOCHS\n",
    "                                    #    [h, tt] = model_fit(model,X_train,Y_train,X_test,Y_test,1,BATCH_SIZE)\n",
    "                                    #    if history == {}:\n",
    "                                    #        history = h.history\n",
    "                                    #    else:\n",
    "                                    #        for k in history.keys():\n",
    "                                    #            history[k] = history[k] + h.history[k]\n",
    "                                    #    training_time = training_time + tt\n",
    "                                    EXACT_EPOCHS = len(history['loss'])\n",
    "                                    summary_text = summary_text + \"Epochs: \" + str(EXACT_EPOCHS) + \"\\n\"\n",
    "                                    summary_text = summary_text + \"GPUs: \" + str(NUM_GPUS) + \"\\n\"\n",
    "                                    summary_text = summary_text + \"Min loss: \"+ '{0:1.2e}'.format(min(history['loss'])) + \"\\n\"\n",
    "                                    summary_text = summary_text + \"Min val-loss: \"+ '{0:1.2e}'.format(min(history['val_loss'])) + \"\\n\"\n",
    "                                    summary_text = summary_text + \"Est pred-mape on exp val: \"+ '{0:1.2e}'.format(mape_on_exp_val) + \"\\n\"\n",
    "                                    summary_text = summary_text + \"Est pred-mape on exp test: \"+ '{0:1.2e}'.format(mape_on_exp_test) + \"\\n\"\n",
    "                                    summary_text = summary_text + \"Mean error on tmu: \"+ str(tmu_err_mean) + \"\\n\"\n",
    "                                    summary_text = summary_text + \"Train time: \" + str(int(training_time)) + \"s\" + \"\\n\"\n",
    "                                    summary_text = summary_text + \"Pred time: \" + str(int(prediction_time)) + \"s\"\n",
    "                                    summary_log = {}\n",
    "                                    summary_log['Date time'] = str(now)\n",
    "                                    summary_log['Data'] = 'Normal distribution'\n",
    "                                    summary_log['Ndim'] = NDIM\n",
    "                                    summary_log['Nevt'] = NEVENTS\n",
    "                                    summary_log['Weighted'] = WEIGHT_SAMPLES\n",
    "                                    summary_log['Loss'] = LOSS\n",
    "                                    summary_log['Hidden layers'] = HID_LAYERS\n",
    "                                    summary_log['Params'] = model_params(model)\n",
    "                                    summary_log['Trainable params'] = model_trainable_params(model)\n",
    "                                    summary_log['Non-trainable params'] = model_non_trainable_params(model)\n",
    "                                    summary_log['Params'] = model_params(model)\n",
    "                                    summary_log['Dropout'] = DROPOUT_RATE\n",
    "                                    summary_log['AF out'] = ACT_FUNC_OUT_LAYER\n",
    "                                    summary_log['Batch norm'] = BATCH_NORM\n",
    "                                    summary_log['Optimizer'] = 'Adam (LR' + str(LEARNING_RATE)+')'\n",
    "            #                        summary_log['Optimizer'] = \"Adam lr=0.1\"\n",
    "                                    summary_log['Batch size'] = BATCH_SIZE\n",
    "                                    summary_log['Epochs'] = EXACT_EPOCHS\n",
    "                                    summary_log['GPUs'] = NUM_GPUS\n",
    "                                    summary_log['Training time'] = training_time\n",
    "                                    summary_log['Est pred-mape on exp val'] = mape_on_exp_val\n",
    "                                    summary_log['Est pred-mape on exp test'] = mape_on_exp_test\n",
    "                                    summary_log['Prediction time'] = prediction_time\n",
    "                                    summary_log['Frequentist tmu exact'] = tmuexact.tolist()\n",
    "                                    summary_log['Frequentist tmu DNN'] = tmuDNN.tolist()\n",
    "                                    summary_log['Frequentist tmu sample 0.01'] = tmusample001.tolist()\n",
    "                                    summary_log['Frequentist tmu sample 0.05'] = tmusample005.tolist()\n",
    "                                    summary_log['Frequentist tmu sample 0.1'] = tmusample01.tolist()\n",
    "                                    summary_log['Frequentist tmu sample 0.2'] = tmusample02.tolist()\n",
    "                                    summary_log['Frequentist mean error on tmu'] = tmu_err_mean.tolist()\n",
    "                                    #Summary figure saving \n",
    "                                    print('Saving model, results, plots')\n",
    "                                    model_save_fig(folder,history,title,summary_text,metric='mean_absolute_error',yscale='log')\n",
    "                                    model_store(folder,model,scaler,history,title,summary_log)\n",
    "                                    if SCALE_Y:\n",
    "                                        save_results(folder,model,scaler,title,summary_text,X_train,X_val,Y_train_log_standardized,Y_val_log_standardized,nbI_values_train,nbI_values_val,observed,freq_tmu,pars=[0,9,39,69,94])\n",
    "                                    else:\n",
    "                                        save_results(folder,model,scaler,title,summary_text,X_train,X_val,Y_train_log,Y_val_log,nbI_values_train,nbI_values_val,observed,freq_tmu,pars=[0,9,39,69,94])\n",
    "                                    iterator = iterator + 1\n",
    "                                    overall_progress.value = float(iterator)/(len(NEVENTS_LIST)*len(LEARNING_RATE_LIST)*len(BATCH_NORM_LIST)*len(HID_LAYERS_LIST)*len(ACT_FUNC_OUT_LAYER_LIST)*len(DROPOUT_RATE_LIST)*len(BATCH_SIZE_LIST)*RUNS)\n",
    "                                    print(\"Processed NN:\" + summary_text.replace(\"\\n\",\" / \"))\n",
    "                                    #del history\n",
    "                                    #del model\n",
    "                                    #gc.collect()\n",
    "                                    #K.clear_sesssion()\n",
    "end = timer()\n",
    "print(\"Processed \" + str(len(NEVENTS_LIST)*len(LEARNING_RATE_LIST)*len(BATCH_NORM_LIST)*len(HID_LAYERS_LIST)*len(ACT_FUNC_OUT_LAYER_LIST)*len(DROPOUT_RATE_LIST)*len(BATCH_SIZE_LIST)*RUNS) + \" models in \" + str(int(end-start)) + \" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = np.array([-287,-290,-300,-310,-320,-330])\n",
    "scaledvalue = scaler.transform(value.reshape(-1,1))\n",
    "scaledvaluepmerror = [scaledvalue - 0.0196, scaledvalue + 0.0196]\n",
    "interval = [value-scaler.inverse_transform(scaledvaluepmerror[0].reshape(-1,1)).reshape(len(value)),scaler.inverse_transform(scaledvaluepmerror[1].reshape(-1,1)).reshape(len(value))-value]\n",
    "interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "value = np.array([-287,-290,-300,-310,-320,-330])\n",
    "scaledvalue = scaler.transform(value.reshape(-1,1))\n",
    "scaledvaluepmerror = [scaledvalue - 0.0243, scaledvalue + 0.0243]\n",
    "interval = [value-scaler.inverse_transform(scaledvaluepmerror[0].reshape(-1,1)).reshape(len(value)),scaler.inverse_transform(scaledvaluepmerror[1].reshape(-1,1)).reshape(len(value))-value]\n",
    "interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(allsamples_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "#model = load_model('results_DNNLik_Log_mixed/2019-08-14--16-31-10 - Data_Normal - Ndim_95 - Nevt_2E05 - Loss_mae_model.h5', custom_objects={'R2_metric': R2_metric, 'Rt_metric':Rt_metric})\n",
    "#scaler = joblib.load('results_DNNLik_Log_mixed/2019-08-14--16-31-10 - Data_Normal - Ndim_95 - Nevt_2E05 - Loss_mae_scaler.jlib') \n",
    "logprob_values_DNN = logprob_DNN_multi(allsamples[:1000000],model,scaler,batch_size=2048)\n",
    "logprob_values_DNN_mixed = logprob_DNN_multi(allsamples_mixed,model,scaler,batch_size=2048)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "plt.grid(linestyle=\"--\", dashes=(5,5))\n",
    "\n",
    "counts, bins = np.histogram(logprob_values_mixed, 100)\n",
    "integral = counts.sum()\n",
    "plt.step(bins[:-1], counts/integral, where='post',color='green')\n",
    "counts, bins = np.histogram(logprob_values_DNN_mixed, 100)\n",
    "integral = counts.sum()\n",
    "plt.step(bins[:-1], counts/integral, where='post',color='red')\n",
    "plt.yscale('log')\n",
    "plt.xlabel(r\"$\\log\\mathcal{L}$\")\n",
    "plt.ylabel(r\"$p(\\log\\mathcal{L})$\")\n",
    "plt.tight_layout()\n",
    "plt.legend(['Mixed','DNN-Mixed'])\n",
    "#if type(save) == bool:\n",
    "#    if save:\n",
    "#        title_time = timer()\n",
    "#        plt.savefig('../paper/figs/figure_autocorr_dist_'+str(par)+'_'+str(title_time)+'.pdf')\n",
    "#elif type(save) == str:\n",
    "#    save = save.replace('.pdf','_')\n",
    "#    title_time = timer()\n",
    "plt.savefig(fig_dir + \"distr_toy_lik_mixed_vs_DNN.pdf\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "plt.grid(linestyle=\"--\", dashes=(5,5))\n",
    "\n",
    "counts, bins = np.histogram(logprob_values[:1000000], 100)\n",
    "integral = counts.sum()\n",
    "plt.step(bins[:-1], counts/integral, where='post',color='green')\n",
    "counts, bins = np.histogram(logprob_values_DNN[:1000000], 100)\n",
    "integral = counts.sum()\n",
    "plt.step(bins[:-1], counts/integral, where='post',color='red')\n",
    "plt.yscale('log')\n",
    "plt.xlabel(r\"$\\log\\mathcal{L}$\")\n",
    "plt.ylabel(r\"$p(\\log\\mathcal{L})$\")\n",
    "plt.tight_layout()\n",
    "plt.legend(['True','DNN'])\n",
    "#if type(save) == bool:\n",
    "#    if save:\n",
    "#        title_time = timer()\n",
    "#        plt.savefig('../paper/figs/figure_autocorr_dist_'+str(par)+'_'+str(title_time)+'.pdf')\n",
    "#elif type(save) == str:\n",
    "#    save = save.replace('.pdf','_')\n",
    "#    title_time = timer()\n",
    "plt.savefig(fig_dir + \"distr_toy_lik_mixed_vs_DNN.pdf\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare and choose best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mydataframe = import_results([\"DNNLikelihoods/\"])\n",
    "mydataframe2 = import_model([\"DNNLikelihoods/\"])\n",
    "for key in mydataframe2.keys():\n",
    "    mydataframe[key]=mydataframe2[key]\n",
    "del(mydataframe2)\n",
    "for key in mydataframe.keys():\n",
    "    mydataframe[metric_name_abbreviate(key)] = mydataframe.pop(key)\n",
    "mydataframe = mydataframe.sort_values(by=['test_loss_best'])\n",
    "mydataframe.info()\n",
    "mydataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_print = np.sort(['1$\\sigma$ HPI rel err test', '1$\\sigma$ HPI rel err train',\n",
    "       '1$\\sigma$ HPI rel err train-test', '1$\\sigma$ HPI rel err val',\n",
    "       'AF out', 'Batch size', 'Date time', 'Dropout',\n",
    "       'Early stopping', 'Epochs', 'Frequentist mean error on tmu', 'Frequentist tmu DNN', 'Frequentist tmu exact',\n",
    "       'GPU(s)', 'Hidden layers',\n",
    "       'KS test-pred_train median', 'KS test-pred_val median', 'KS train-test median', \n",
    "       'KS val-pred_test median', 'Min_delta',\n",
    "       'Name', 'Ndim', 'Nevt-train', 'Nevt-val',\n",
    "       'Number', 'Optimizer', 'Params', 'Prediction time',\n",
    "       'Reduce LR patience',\n",
    "       'Trainable params', 'Training time', 'Weighted', 'loss_best',\n",
    "       'loss_best_scaled', 'mae_best', 'mae_best_scaled', 'mape_best',\n",
    "       'mape_best_scaled', 'me_best', 'me_best_scaled', 'mpe_best',\n",
    "       'mpe_best_scaled', 'mse_best','mse_best_scaled', \n",
    "       'test_loss_best', 'test_loss_best_scaled', 'test_mae_best', 'test_mae_best_scaled',\n",
    "       'test_mape_best', 'test_mape_best_scaled', 'test_me_best', 'test_me_best_scaled',\n",
    "       'test_mpe_best', 'test_mpe_best_scaled', 'test_mse_best', 'test_mse_best_scaled',\n",
    "       'val_loss_best', 'val_loss_best_scaled', 'val_mae_best', 'val_mae_best_scaled',\n",
    "       'val_mape_best', 'val_mape_best_scaled', 'val_me_best', 'val_me_best_scaled', \n",
    "       'val_mpe_best', 'val_mpe_best_scaled', 'val_mse_best', 'val_mse_best_scaled'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0100 = DataFrame(mydataframe[mydataframe[\"Nevt-train\"]==100000].reindex(columns=cols_to_print))\n",
    "df0200 = DataFrame(mydataframe[mydataframe[\"Nevt-train\"]==200000].reindex(columns=cols_to_print))\n",
    "df0500 = DataFrame(mydataframe[mydataframe[\"Nevt-train\"]==500000].reindex(columns=cols_to_print))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sortby(df0100,column_max='KS val-pred_test median',color_min='Green',color_max='Red',highlights_min=['loss_best','mse_best', 'mae_best', 'mape_best', 'me_best', 'mpe_best',\n",
    "                           'val_loss_best', 'val_mse_best', 'val_mae_best', 'val_mape_best', 'val_me_best', 'val_mpe_best',\n",
    "                           'test_loss_best', 'test_mse_best', 'test_mae_best', 'test_mape_best', 'test_me_best', 'test_mpe_best','Frequentist mean error on tmu'],highlights_max=['KS test-pred_train median',\n",
    "       'KS test-pred_val median', 'KS val-pred_test median', 'KS train-test median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortby(df0100,column_min='Frequentist mean error on tmu',color_min='Green',color_max='Red',highlights_min=['loss_best','mse_best', 'mae_best', 'mape_best', 'me_best', 'mpe_best',\n",
    "                           'val_loss_best', 'val_mse_best', 'val_mae_best', 'val_mape_best', 'val_me_best', 'val_mpe_best',\n",
    "                           'test_loss_best', 'test_mse_best', 'test_mae_best', 'test_mape_best', 'test_me_best', 'test_mpe_best','Frequentist mean error on tmu'],highlights_max=['KS test-pred_train median',\n",
    "       'KS test-pred_val median', 'KS val-pred_test median', 'KS train-test median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Name:', df0100.iloc[[1]]['Name'].to_numpy()[0])\n",
    "print('Epochs:', df0100.iloc[[1]]['Epochs'].to_numpy()[0])\n",
    "print('Best loss train:', df0100.iloc[[1]]['mse_best'].to_numpy()[0])\n",
    "print('Best loss val:', df0100.iloc[[1]]['val_mse_best'].to_numpy()[0])\n",
    "print('Best loss test:', df0100.iloc[[1]]['test_mse_best'].to_numpy()[0])\n",
    "print('Best ME train:', df0100.iloc[[1]]['me_best'].to_numpy()[0])\n",
    "print('Best ME val:', df0100.iloc[[1]]['val_me_best'].to_numpy()[0])\n",
    "print('Best ME test:', df0100.iloc[[1]]['test_me_best'].to_numpy()[0])\n",
    "print('Median 1D K-S test/pred-train:',df0100.iloc[[1]]['KS test-pred_train median'].to_numpy()[0])\n",
    "print('Median 1D K-S test/pred-val:',df0100.iloc[[1]]['KS test-pred_val median'].to_numpy()[0])\n",
    "print('Median 1D K-S val/pred-test:',df0100.iloc[[1]]['KS val-pred_test median'].to_numpy()[0])\n",
    "print('Frequentist mean error on tmu:',df0100.iloc[[1]]['Frequentist mean error on tmu'].to_numpy()[0])\n",
    "print('Training time:',df0100.iloc[[4]]['Training time'].to_numpy()[0])\n",
    "print('Prediction time:',df0100.iloc[[4]]['Prediction time'].to_numpy()[0]/df0100.iloc[[4]]['Nevt-val'].to_numpy()[0]*10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sortby(df0200,column_max='KS val-pred_test median',color_min='Green',color_max='Red',highlights_min=['loss_best','mse_best', 'mae_best', 'mape_best', 'me_best', 'mpe_best',\n",
    "                           'val_loss_best', 'val_mse_best', 'val_mae_best', 'val_mape_best', 'val_me_best', 'val_mpe_best',\n",
    "                           'test_loss_best', 'test_mse_best', 'test_mae_best', 'test_mape_best', 'test_me_best', 'test_mpe_best','Frequentist mean error on tmu'],highlights_max=['KS test-pred_train median',\n",
    "       'KS test-pred_val median', 'KS val-pred_test median', 'KS train-test median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortby(df0200,column_min='Frequentist mean error on tmu',color_min='Green',color_max='Red',highlights_min=['loss_best','mse_best', 'mae_best', 'mape_best', 'me_best', 'mpe_best',\n",
    "                           'val_loss_best', 'val_mse_best', 'val_mae_best', 'val_mape_best', 'val_me_best', 'val_mpe_best',\n",
    "                           'test_loss_best', 'test_mse_best', 'test_mae_best', 'test_mape_best', 'test_me_best', 'test_mpe_best','Frequentist mean error on tmu'],highlights_max=['KS test-pred_train median',\n",
    "       'KS test-pred_val median', 'KS val-pred_test median', 'KS train-test median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Name:', df0200.iloc[[0]]['Name'].to_numpy()[0])\n",
    "print('Epochs:', df0200.iloc[[0]]['Epochs'].to_numpy()[0])\n",
    "print('Best loss train:', df0200.iloc[[0]]['mse_best'].to_numpy()[0])\n",
    "print('Best loss val:', df0200.iloc[[0]]['val_mse_best'].to_numpy()[0])\n",
    "print('Best loss test:', df0200.iloc[[0]]['test_mse_best'].to_numpy()[0])\n",
    "print('Best ME train:', df0200.iloc[[0]]['me_best'].to_numpy()[0])\n",
    "print('Best ME val:', df0200.iloc[[0]]['val_me_best'].to_numpy()[0])\n",
    "print('Best ME test:', df0200.iloc[[0]]['test_me_best'].to_numpy()[0])\n",
    "print('Median 1D K-S test/pred-train:',df0200.iloc[[0]]['KS test-pred_train median'].to_numpy()[0])\n",
    "print('Median 1D K-S test/pred-val:',df0200.iloc[[0]]['KS test-pred_val median'].to_numpy()[0])\n",
    "print('Median 1D K-S val/pred-test:',df0200.iloc[[0]]['KS val-pred_test median'].to_numpy()[0])\n",
    "print('Frequentist mean error on tmu:',df0200.iloc[[0]]['Frequentist mean error on tmu'].to_numpy()[0])\n",
    "print('Training time:',df0200.iloc[[2]]['Training time'].to_numpy()[0])\n",
    "print('Prediction time:',df0200.iloc[[2]]['Prediction time'].to_numpy()[0]/df0200.iloc[[2]]['Nevt-val'].to_numpy()[0]*10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sortby(df0500,column_max='KS val-pred_test median',color_min='Green',color_max='Red',highlights_min=['loss_best','mse_best', 'mae_best', 'mape_best', 'me_best', 'mpe_best',\n",
    "                           'val_loss_best', 'val_mse_best', 'val_mae_best', 'val_mape_best', 'val_me_best', 'val_mpe_best',\n",
    "                           'test_loss_best', 'test_mse_best', 'test_mae_best', 'test_mape_best', 'test_me_best', 'test_mpe_best','Frequentist mean error on tmu'],highlights_max=['KS test-pred_train median',\n",
    "       'KS test-pred_val median', 'KS val-pred_test median', 'KS train-test median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortby(df0500,column_min='Frequentist mean error on tmu',color_min='Green',color_max='Red',highlights_min=['loss_best','mse_best', 'mae_best', 'mape_best', 'me_best', 'mpe_best',\n",
    "                           'val_loss_best', 'val_mse_best', 'val_mae_best', 'val_mape_best', 'val_me_best', 'val_mpe_best',\n",
    "                           'test_loss_best', 'test_mse_best', 'test_mae_best', 'test_mape_best', 'test_me_best', 'test_mpe_best','Frequentist mean error on tmu'],highlights_max=['KS test-pred_train median',\n",
    "       'KS test-pred_val median', 'KS val-pred_test median', 'KS train-test median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Name:', df0500.iloc[[2]]['Name'].to_numpy()[0])\n",
    "print('Epochs:', df0500.iloc[[2]]['Epochs'].to_numpy()[0])\n",
    "print('Best loss train:', df0500.iloc[[2]]['mse_best'].to_numpy()[0])\n",
    "print('Best loss val:', df0500.iloc[[2]]['val_mse_best'].to_numpy()[0])\n",
    "print('Best loss test:', df0500.iloc[[2]]['test_mse_best'].to_numpy()[0])\n",
    "print('Best ME train:', df0500.iloc[[2]]['me_best'].to_numpy()[0])\n",
    "print('Best ME val:', df0500.iloc[[2]]['val_me_best'].to_numpy()[0])\n",
    "print('Best ME test:', df0500.iloc[[2]]['test_me_best'].to_numpy()[0])\n",
    "print('Median 1D K-S test/pred-train:',df0500.iloc[[2]]['KS test-pred_train median'].to_numpy()[0])\n",
    "print('Median 1D K-S test/pred-val:',df0500.iloc[[2]]['KS test-pred_val median'].to_numpy()[0])\n",
    "print('Median 1D K-S val/pred-test:',df0500.iloc[[2]]['KS val-pred_test median'].to_numpy()[0])\n",
    "print('Frequentist mean error on tmu:',df0500.iloc[[2]]['Frequentist mean error on tmu'].to_numpy()[0])\n",
    "print('Training time:',df0500.iloc[[2]]['Training time'].to_numpy()[0])\n",
    "print('Prediction time:',df0500.iloc[[2]]['Prediction time'].to_numpy()[0]/df0500.iloc[[2]]['Nevt-val'].to_numpy()[0]*10**6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequentist Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmuexact = mydataframe.iloc[[0]]['Frequentist tmu exact']\n",
    "tmuexact = np.array([i for i in tmuexact])[0][:,[0,3]]\n",
    "tmuDNN100 = df0100.iloc[[1]]['Frequentist tmu DNN']\n",
    "tmuDNN100 = np.array([i for i in tmuDNN100])[0][:,[0,3]]\n",
    "tmuDNN200 = df0200.iloc[[0]]['Frequentist tmu DNN']\n",
    "tmuDNN200 = np.array([i for i in tmuDNN200])[0][:,[0,3]]\n",
    "tmuDNN500 = df0500.iloc[[2]]['Frequentist tmu DNN']\n",
    "tmuDNN500 = np.array([i for i in tmuDNN500])[0][:,[0,3]]\n",
    "tmuDNN1000 = df1000.iloc[[7]]['Frequentist tmu DNN']\n",
    "tmuDNN1000 = np.array([i for i in tmuDNN1000])[0][:,[0,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl68 = np.array([[-1,2],[1,1]])\n",
    "cl95 = np.array([[-1,2],[4,4]])\n",
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "plt.grid(linestyle=\"--\", dashes=(5,5),alpha=1)\n",
    "plt.plot(tmuexact[:,0],tmuexact[:,1])\n",
    "plt.plot(tmuDNN100[:,0],tmuDNN100[:,1])\n",
    "plt.plot(tmuDNN200[:,0],tmuDNN200[:,1])\n",
    "plt.plot(tmuDNN500[:,0],tmuDNN500[:,1])\n",
    "x1,x2,y1,y2 = plt.axis()\n",
    "plt.plot(cl68[0],cl68[1],linestyle=\"--\", dashes=(1,1),color='black',alpha=0.9)\n",
    "plt.plot(cl95[0],cl95[1],linestyle=\"--\", dashes=(1,1),color='black',alpha=0.9)\n",
    "plt.axis([x1, x2, y1, y2])\n",
    "plt.xlabel(r'$\\mu$')\n",
    "plt.ylabel(r'$t_{\\mu}(\\mu)$')\n",
    "plt.legend(['Numerical maximization','DNN $F_{1}$', 'DNN $F_{2}$', 'DNN $F_{3}$'],fontsize=15)\n",
    "plt.text(0.9,1.1,r\"Wilks' $68.27\\%$\",fontsize=18, ha='center',ma='center')\n",
    "plt.text(0.5,3.45,r\"Wilks' $95.45\\%$\",fontsize=18, ha='center',ma='center')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + 'tmu_DNN_best.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "plt.grid(linestyle=\"--\", dashes=(5,5),alpha=1)\n",
    "plt.plot(tmuexact[:,0],np.abs(tmuexact[:,1]-tmuexact[:,1])/tmuexact[:,1])\n",
    "plt.plot(tmuDNN100[:,0],np.abs(tmuDNN100[:,1]-tmuexact[:,1])/tmuexact[:,1], label='DNN $F_{1}$',color=colors[1])\n",
    "plt.plot(tmuDNN200[:,0],np.abs(tmuDNN200[:,1]-tmuexact[:,1])/tmuexact[:,1], label='DNN $F_{2}$',color=colors[2])\n",
    "plt.plot(tmuDNN500[:,0],np.abs(tmuDNN500[:,1]-tmuexact[:,1])/tmuexact[:,1], label='DNN $F_{3}$',color=colors[3])\n",
    "plt.plot(tmuDNN100[:,0],np.full(len(tmuDNN100),np.mean((np.abs(tmuDNN100[:,1]-tmuexact[:,1])/tmuexact[:,1])[1:])),color=colors[1],linestyle=\"--\")\n",
    "plt.plot(tmuDNN200[:,0],np.full(len(tmuDNN200),np.mean((np.abs(tmuDNN200[:,1]-tmuexact[:,1])/tmuexact[:,1])[1:])),color=colors[2],linestyle=\"--\")\n",
    "plt.plot(tmuDNN500[:,0],np.full(len(tmuDNN500),np.mean((np.abs(tmuDNN500[:,1]-tmuexact[:,1])/tmuexact[:,1])[1:])),color=colors[3],linestyle=\"--\")\n",
    "x1,x2,y1,y2 = plt.axis()\n",
    "plt.axis([0.1, x2, 0.001, 2])\n",
    "plt.yscale('log')\n",
    "plt.xlabel(r'$\\mu$')\n",
    "plt.ylabel(r'$\\Delta t_{\\mu}(\\mu)/t_{\\mu}^{\\rm{exact}}(\\mu)$')\n",
    "plt.legend(fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir + 'tmu_DNN_best_error.pdf')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1-F3 DNNLikelihoods results\n",
    "Code is present only for model F1. Repeat replacing model F1 with F2 and F3 (also in figures names!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfile = \"DNNLikelihoods/F1_model.h5\"\n",
    "with open(modelfile.replace(\"model.h5\",\"model.json\") as json_file: \n",
    "    data = json.load(json_file)\n",
    "    dict1 = {**{'Name': modelfile},**data}\n",
    "with open(modelfile.replace(\"model.h5\",\"history.json\") as json_file: \n",
    "    data = json.load(json_file)\n",
    "    dict2 = {**{'Name': modelfile},**data}\n",
    "summary_log = {**dict1,**dict2}\n",
    "summary_text = generate_summary_text_reduced(summary_log, False)\n",
    "title = generate_title_from_log_reduced(summary_log)\n",
    "print(modelfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metric = \"loss\"\n",
    "val_metric = \"val_\"+metric\n",
    "history = summary_log\n",
    "filename = \"loss_F1.pdf\"\n",
    "jtplot.reset()\n",
    "plt.style.use('matplotlib.mplstyle')\n",
    "plt.plot(history[metric])\n",
    "plt.plot(history[val_metric])\n",
    "plt.yscale(\"log\")\n",
    "plt.grid(linestyle=\"--\", dashes=(5,5))\n",
    "plt.title(r\"%s\"%title,fontsize=18)\n",
    "plt.xlabel(r\"epoch\")\n",
    "plt.ylabel(r\"loss (mse)\")\n",
    "ylable = (metric.replace(\"_\",\"-\"))\n",
    "plt.legend([r\"training\", r\"validation\"])\n",
    "plt.tight_layout()\n",
    "ax = plt.axes()\n",
    "x1,x2,y1,y2 = plt.axis()\n",
    "plt.text(0.35,0.74,r\"Model $F_{1}$\", fontsize=23, ha='right',ma='left',transform = ax.transAxes)\n",
    "plt.text(0.965,0.15,r\"%s\"%summary_text, fontsize=9, bbox=dict(facecolor=\"green\",alpha=0.15, edgecolor='black', boxstyle='round,pad=0.5'), ha='right',ma='left',transform = ax.transAxes)\n",
    "plt.savefig(r\"%s\" % (fig_dir + \"/\" + filename))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load samples and logprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples_file = \"Data_samples/likelihood_unbiased_sm_13_thinned1000_11M.pickle\"\n",
    "pickle_in = open(samples_file,'rb')\n",
    "start = timer()\n",
    "statinfo = os.stat(samples_file)\n",
    "allsamples_train = pickle.load(pickle_in)\n",
    "logprob_values_train = pickle.load(pickle_in)\n",
    "_ = pickle.load(pickle_in)\n",
    "_ = pickle.load(pickle_in)\n",
    "allsamples_test = pickle.load(pickle_in)\n",
    "logprob_values_test = pickle.load(pickle_in)\n",
    "_ = pickle.load(pickle_in)\n",
    "_ = pickle.load(pickle_in)\n",
    "end = timer()\n",
    "pickle_in.close()\n",
    "print('File loaded in ',end-start,' seconds.\\nFile size is ',statinfo.st_size,'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Inference (reweighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfile = \"DNNLikelihoods/F1_model.h5\"\n",
    "model = load_model(modelfile, custom_objects={'R2_metric': R2_metric, 'Rt_metric':Rt_metric})\n",
    "scalerX, scalerY = load_model_scaler(modelfile)\n",
    "[idx_train,idx_val,idx_test] = load_data_indices(modelfile.replace(\"model.h5\",\"samples_indices.pickle\"))\n",
    "threshold=np.min(logprob_values_train[idx_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "nnn = len(allsamples_test)\n",
    "ilist = [0,3,6,30,61,85]\n",
    "nndim = len(ilist)\n",
    "nbins = 50\n",
    "Y_true = logprob_values_test[:nnn]\n",
    "Y_pred = logprob_DNN_multi(allsamples_test[:nnn],model,scalerX,scalerY,batch_size=2048)\n",
    "weights_DNN = np.exp(Y_pred)/np.exp(Y_true)\n",
    "samp_true = allsamples_test[:nnn][:,ilist]\n",
    "samp_DNN_weights = weights_DNN/np.sum(weights_DNN)*len(samp_true)\n",
    "ranges = extend_corner_range(allsamples_test,allsamples_test,ilist,0)\n",
    "sigma_contours = [1,2,3]\n",
    "HPI_intervals1 = [HPD_intervals(samp_true[:,i], intervals = get_CI_from_sigma(sigma_contours), weights=None, nbins=nbins, print_hist=False, reduce_binning=True) for i in range(nndim)]\n",
    "HPI_intervals2 = [HPD_intervals(samp_true[:,i], intervals = get_CI_from_sigma(sigma_contours), weights=samp_DNN_weights, nbins=nbins, print_hist=False, reduce_binning=True) for i in range(nndim)]\n",
    "levels1 = np.array([[np.sort(HPD_quotas(samp_true[:,[i,j]], nbins=nbins, intervals = get_CI_from_sigma(sigma_contours))).tolist() for j in range(nndim)] for i in range(nndim)])\n",
    "levels2 = np.array([[np.sort(HPD_quotas(samp_true[:,[i,j]], nbins=nbins, intervals = get_CI_from_sigma(sigma_contours), weights=samp_DNN_weights)).tolist() for j in range(nndim)] for i in range(nndim)])\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_corners(ilist, nbins, samp_true, samp_true, w1=None, w2=samp_DNN_weights, levels1=levels1, levels2=levels2, HPI_intervals1=HPI_intervals1, HPI_intervals2=HPI_intervals2, \n",
    "             ranges=ranges, title1=\"$68\\%$ HPDI test\", title2=\"$68\\%$ HPDI DNN $F_{1}$\", color1=greens[-9], color2=reds[9], plot_title=\"DNN $F_{1}$ reweighting\", \n",
    "             legend_labels = [r\"Test set ($10^{6}$ points)\",r\"Test set reweighted with DNN $F_{1}$\",r'$68.27\\%$ HPDI', r'$95.45\\%$ HPDI', r'$99.73\\%$ HPDI'], figdir=fig_dir, figname=\"corner_toy_lik_test_vs_DNN_F1_params_reweighting.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start= timer()\n",
    "nbins = 50\n",
    "sigma_contours = [1,2,3]\n",
    "HPI_intervals1_all = HPD_intervals(samp_true[:,0], intervals = get_CI_from_sigma(sigma_contours), weights=samp_DNN_weights, nbins=nbins, print_hist=False, reduce_binning=True)\n",
    "HPI_intervals1_pos = HPD_intervals(samp_true[:,0][samp_true[:,0]>0], intervals = get_CI_from_sigma(sigma_contours), weights=samp_DNN_weights[samp_true[:,0]>0], nbins=nbins, print_hist=False, reduce_binning=True)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HPI_intervals1_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HPI_intervals1_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfile =\"DNNLikelihoods/F1_model.h5\"\n",
    "model = load_model(modelfile, custom_objects={'R2_metric': R2_metric, 'Rt_metric':Rt_metric})\n",
    "scalerX, scalerY = load_model_scaler(modelfile)\n",
    "[idx_train,idx_val,idx_test] = load_data_indices(modelfile.replace(\"model.h5\",\"samples_indices.pickle\"))\n",
    "threshold=np.min(logprob_values_train[idx_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## In my case MULTI_GPU takes a little more than a single GPU, but it may well depend on the hardware architecture\n",
    "# sampler inputs\n",
    "NEW_SAMPLING = True\n",
    "INITIALIZE_IN_BALL = False\n",
    "MULTI_GPU = False\n",
    "logprob_fn = logprob_DNN_multi\n",
    "\n",
    "ndim, nwalkers, nsteps = 95, 1024, 100000\n",
    "\n",
    "if len(K.tensorflow_backend._get_available_gpus()) <= 1:\n",
    "    MULTI_GPU = False\n",
    "\n",
    "if MULTI_GPU:\n",
    "    parallel_model = model_compile(model,model.loss,model.optimizer,model.metrics,True)\n",
    "    args = [parallel_model,scalerX,scalerY,nwalkers,threshold]\n",
    "else:\n",
    "    args = [model,scalerX,scalerY,nwalkers,threshold]\n",
    "    \n",
    "# Initialize backend\n",
    "filename = \"Data_samples/DNNLikelihood_F1_sampling.h5\"\n",
    "chainsname = 'toy_likelihood'\n",
    "backend = emcee.backends.HDFBackend(filename, name=chainsname)\n",
    "if NEW_SAMPLING:\n",
    "    # starting value of parameters\n",
    "    if INITIALIZE_IN_BALL:\n",
    "        start = timer()\n",
    "        maxlik = minimize(lambda delta: -logprob(delta), np.full(95,0),method='Powell')\n",
    "        p0 =  [maxlik['x']+0.01*np.insert(np.random.normal(0,1,94),0,np.random.uniform(-1,5)) for i in range(nwalkers)]\n",
    "        end = timer()\n",
    "        print(\"Initialization around maximum likelihood performed in\",end-start,\"s.\")\n",
    "    else:\n",
    "        p0 = [np.full(95,0)+np.insert(np.random.normal(0,1,94),0,np.random.uniform(-1,5)) for i in range(nwalkers)]\n",
    "    backend.reset(nwalkers, ndim)\n",
    "else:\n",
    "    p0 = backend.get_last_sample()\n",
    "print(\"Initial number of steps: {0}\".format(backend.iteration))\n",
    "\n",
    "moves = emcee.moves.StretchMove(1.3)\n",
    "\n",
    "start = timer()\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, logprob_fn, moves=moves, backend=backend, args=args, vectorize=True)\n",
    "sampler.run_mcmc(p0, nsteps, progress=True)\n",
    "end = timer()\n",
    "print('Done in ',end-start,'seconds')\n",
    "print(\"Final number of steps: {0}\".format(backend.iteration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract samples with thin=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Data_samples/DNNLikelihood_F1_sampling.h5\"\n",
    "chainsname = 'toy_likelihood'\n",
    "start = timer()\n",
    "backend = import_sampler(filename,chainsname)\n",
    "allsamples = backend.get_chain(discard=50000,thin=50,flat=True)\n",
    "logprob_values = backend.get_log_prob(discard=50000,thin=50,flat=True)\n",
    "end = timer()\n",
    "print(len(allsamples),\"independent samples extracted in\", end-start, \"s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logprob_values = logprob_values[allsamples[:,0]>-1][0:1000000]\n",
    "allsamples = allsamples[allsamples[:,0]>-1][0:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnn = len(allsamples)\n",
    "n_processes = psutil.cpu_count(logical=False)\n",
    "if __name__ ==  '__main__': \n",
    "    print('Running ', n_processes,' parallel processes.')\n",
    "    start = timer()\n",
    "    with Pool(n_processes) as pool:\n",
    "        logprior_values = np.array(pool.map(logprior,allsamples[0:nnn]))\n",
    "    end = timer()\n",
    "    print(end-start)\n",
    "loglik_values = logprob_values-logprior_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_file = \"Data_samples/DNNLikelihood_F1.pickle\"\n",
    "pickle_out = open(samples_file, 'wb')\n",
    "start = timer()\n",
    "pickle.dump(allsamples, pickle_out, protocol=4)\n",
    "pickle.dump(logprob_values, pickle_out, protocol=4)\n",
    "pickle.dump(loglik_values, pickle_out, protocol=4)\n",
    "pickle.dump(logprior_values, pickle_out, protocol=4)\n",
    "end = timer()\n",
    "pickle_out.close()\n",
    "statinfo = os.stat(samples_file)\n",
    "print('File saved in',end-start,'seconds.\\nFile size is',statinfo.st_size,'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Inference (resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_file = \"Data_samples/likelihood_unbiased_sm_13_thinned1000_11M.pickle\"\n",
    "pickle_in = open(samples_file,'rb')\n",
    "start = timer()\n",
    "statinfo = os.stat(samples_file)\n",
    "_ = pickle.load(pickle_in)\n",
    "_ = pickle.load(pickle_in)\n",
    "_ = pickle.load(pickle_in)\n",
    "_ = pickle.load(pickle_in)\n",
    "allsamples_test = pickle.load(pickle_in)\n",
    "logprob_values_test = pickle.load(pickle_in)\n",
    "_ = pickle.load(pickle_in)\n",
    "_ = pickle.load(pickle_in)\n",
    "end = timer()\n",
    "pickle_in.close()\n",
    "print('File loaded in ',end-start,' seconds.\\nFile size is ',statinfo.st_size,'.')\n",
    "samples_file = \"Data_samples/DNNLikelihood_F1.pickle\"\n",
    "pickle_in = open(samples_file, 'rb')\n",
    "start = timer()\n",
    "allsamples_DNN_F1 = pickle.load(pickle_in)\n",
    "logprob_values_DNN_F1 = pickle.load(pickle_in)\n",
    "end = timer()\n",
    "pickle_in.close()\n",
    "statinfo = os.stat(samples_file)\n",
    "print('File saved in ',end-start,' seconds.\\nFile size is ',statinfo.st_size,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "nnn1 = len(allsamples_test)\n",
    "nnn2 = len(allsamples_DNN_B1)\n",
    "ilist = [0,3,6,30,61,85]\n",
    "nndim = len(ilist)\n",
    "nbins = 50\n",
    "s1 = allsamples_test\n",
    "s2 = allsamples_DNN_F1\n",
    "rnd_indices_1 = np.random.choice(np.arange(len(s1)),size=nnn1,replace=False)\n",
    "rnd_indices_2 = np.random.choice(np.arange(len(s2)),size=nnn2,replace=False)\n",
    "samp_1 = s1[rnd_indices_1][:,ilist]\n",
    "samp_2 = s2[rnd_indices_2][:,ilist]\n",
    "ranges = extend_corner_range(s1,s1,ilist,0)\n",
    "sigma_contours = [1,2,3]\n",
    "HPI_intervals1 = [HPD_intervals(samp_1[:,i], intervals = get_CI_from_sigma(sigma_contours), weights=None, nbins=nbins, print_hist=False, reduce_binning=True) for i in range(nndim)]\n",
    "HPI_intervals2 = [HPD_intervals(samp_2[:,i], intervals = get_CI_from_sigma(sigma_contours), weights=None, nbins=nbins, print_hist=False, reduce_binning=True) for i in range(nndim)]\n",
    "levels1 = np.array([[np.sort(HPD_quotas(samp_1[:,[i,j]], nbins=nbins, intervals = get_CI_from_sigma(sigma_contours))).tolist() for j in range(nndim)] for i in range(nndim)])\n",
    "levels2 = np.array([[np.sort(HPD_quotas(samp_2[:,[i,j]], nbins=nbins, intervals = get_CI_from_sigma(sigma_contours), weights=None)).tolist() for j in range(nndim)] for i in range(nndim)])\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_corners(ilist, nbins, samp_1, samp_2, w1=None, w2=None, levels1=levels1, levels2=levels2, HPI_intervals1=HPI_intervals1, HPI_intervals2=HPI_intervals2, \n",
    "             ranges=ranges, title1=\"$68\\%$ HPDI test\", title2=\"$68\\%$ HPDI DNN $F_{1}$\", color1=greens[-9], color2=reds[9], plot_title=\"DNN $F_{1}$ sampling\", \n",
    "             legend_labels = [r\"Test set ($10^{6}$ points)\",r\"Sampled DNN $F_{1}$ ($10^{6}$ points)\",r'$68.27\\%$ HPDI', r'$95.45\\%$ HPDI', r'$99.73\\%$ HPDI'], figdir=fig_dir, figname=\"corner_toy_lik_test_vs_DNN_F1_params_resampling.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start= timer()\n",
    "nbins = 50\n",
    "sigma_contours = [1,2,3]\n",
    "HPI_intervals1_all = HPD_intervals(samp_2[:,0], intervals = get_CI_from_sigma(sigma_contours), weights=None, nbins=nbins, print_hist=False, reduce_binning=True)\n",
    "HPI_intervals1_pos = HPD_intervals(samp_2[:,0][samp_2[:,0]>0], intervals = get_CI_from_sigma(sigma_contours), weights=None, nbins=nbins, print_hist=False, reduce_binning=True)\n",
    "end = timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HPI_intervals1_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HPI_intervals1_pos"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:TensorFlow-GPU]",
   "language": "python",
   "name": "conda-env-TensorFlow-GPU-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "462.125px",
    "left": "335px",
    "top": "303px",
    "width": "543.763px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
